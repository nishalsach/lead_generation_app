[
    {
        "arxiv_id":"2206.04332v1",
        "predicted_newsworthiness":49.8052557778,
        "title":"Corpus Similarity Measures Remain Robust Across Diverse Languages",
        "summary":"This paper experiments with frequency-based corpus similarity measures across 39 languages using a register prediction task. The goal is to quantify (i) the distance between different corpora from the same language and (ii) the homogeneity of individual corpora. Both of these goals are essential for measuring how well corpus-based linguistic analysis generalizes from one dataset to another. The problem is that previous work has focused on Indo-European languages, raising the question of whether these measures are able to provide robust generalizations across diverse languages. This paper uses a register prediction task to evaluate competing measures across 39 languages: how well are they able to distinguish between corpora representing different contexts of production? Each experiment compares three corpora from a single language, with the same three digital registers shared across all languages: social media, web pages, and Wikipedia. Results show that measures of corpus similarity retain their validity across different language families, writing systems, and types of morphology. Further, the measures remain robust when evaluated on out-of-domain corpora, when applied to low-resource languages, and when applied to different sets of registers. These findings are significant given our need to make generalizations across the rapidly increasing number of corpora available for analysis.",
        "published":1654762636000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.04332v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Jun 09, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1726042283,
        "popularmechanics":0.1051732165,
        "scienmag":0.1426434001,
        "technologyreview":0.2102964424,
        "vox":0.1821160661,
        "newscientist":0.1543942685,
        "vice":0.1075868259,
        "statnews":0.1323862391,
        "nytimes":0.1753621611,
        "techcrunch":0.1733741218,
        "quartz":0.1757742206,
        "venturebeat":0.2002955113,
        "futurism":0.1443748164,
        "scientificamerican":0.1564838747,
        "wired":0.1907650735,
        "popsci":0.1750933701,
        "arstechnica":0.1404327512,
        "salon":0.1238267789,
        "washingtonpost":0.1809303133,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.01391v2",
        "predicted_newsworthiness":36.6972304474,
        "title":"DDL-MVS: Depth Discontinuity Learning for MVS Networks",
        "summary":"Traditional MVS methods have good accuracy but struggle with completeness, while recently developed learning-based multi-view stereo (MVS) techniques have improved completeness except accuracy being compromised. We propose depth discontinuity learning for MVS methods, which further improves accuracy while retaining the completeness of the reconstruction. Our idea is to jointly estimate the depth and boundary maps where the boundary maps are explicitly used for further refinement of the depth maps. We validate our idea and demonstrate that our strategies can be easily integrated into the existing learning-based MVS pipeline where the reconstruction depends on high-quality depth map estimation. Extensive experiments on various datasets show that our method improves reconstruction quality compared to baseline. Experiments also demonstrate that the presented model and strategies have good generalization capabilities. The source code will be available soon.",
        "published":1646252731000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.01391v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Mar 02, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0699558392,
        "popularmechanics":0.135322586,
        "scienmag":0.0933381761,
        "technologyreview":0.1654881123,
        "vox":0.0849890569,
        "newscientist":0.1106061361,
        "vice":0.1210435977,
        "statnews":0.0663491506,
        "nytimes":0.0988641352,
        "techcrunch":0.1279305106,
        "quartz":0.0831069586,
        "venturebeat":0.1646271046,
        "futurism":0.1455731385,
        "scientificamerican":0.086981846,
        "wired":0.1360271596,
        "popsci":0.1414361387,
        "arstechnica":0.091083917,
        "salon":0.0727581975,
        "washingtonpost":0.1123162247,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.01146v1",
        "predicted_newsworthiness":48.369911226,
        "title":"Controlling the Focus of Pretrained Language Generation Models",
        "summary":"The finetuning of pretrained transformer-based language generation models are typically conducted in an end-to-end manner, where the model learns to attend to relevant parts of the input by itself. However, there does not exist a mechanism to directly control the model's focus. This work aims to develop a control mechanism by which a user can select spans of context as \"highlights\" for the model to focus on, and generate relevant output. To achieve this goal, we augment a pretrained model with trainable \"focus vectors\" that are directly applied to the model's embeddings, while the model itself is kept fixed. These vectors, trained on automatic annotations derived from attribution methods, act as indicators for context importance. We test our approach on two core generation tasks: dialogue response generation and abstractive summarization. We also collect evaluation data where the highlight-generation pairs are annotated by humans. Our experiments show that the trained focus vectors are effective in steering the model to generate outputs that are relevant to user-selected highlights.",
        "published":1646232374000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.01146v1",
        "arxiv_primary_category":"cs.ai",
        "published_hr":"Mar 02, 2022",
        "arxiv_primary_category_hr":"Artificial Intelligence",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0916062588,
        "popularmechanics":0.1028666022,
        "scienmag":0.096944281,
        "technologyreview":0.2080282881,
        "vox":0.1298956851,
        "newscientist":0.1173462774,
        "vice":0.1018940789,
        "statnews":0.1381247978,
        "nytimes":0.1225947032,
        "techcrunch":0.153125088,
        "quartz":0.1120944863,
        "venturebeat":0.2150722593,
        "futurism":0.1401282982,
        "scientificamerican":0.112989751,
        "wired":0.1713402702,
        "popsci":0.1461131066,
        "arstechnica":0.0956365865,
        "salon":0.0801173139,
        "washingtonpost":0.1178519565,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.12943v2",
        "predicted_newsworthiness":58.5725843874,
        "title":"Unique in what sense? Heterogeneous relationships between multiple types of uniqueness and popularity in music",
        "summary":"How does our society appreciate the uniqueness of cultural products? This fundamental puzzle has intrigued scholars in many fields, including psychology, sociology, anthropology, and marketing. It has been theorized that cultural products that balance familiarity and novelty are more likely to become popular. However, a cultural product's novelty is typically multifaceted. This paper uses songs as a case study to study the multiple facets of uniqueness and their relationship with success. We first unpack the multiple facets of a song's novelty or uniqueness and, next, measure its impact on a song's popularity. We employ a series of statistical models to study the relationship between a song's popularity and novelty associated with its lyrics, chord progressions, or audio properties. Our analyses performed on a dataset of over fifty thousand songs find a consistently negative association between all types of song novelty and popularity. Overall we found a song's lyrics uniqueness to have the most significant association with its popularity. However, audio uniqueness was the strongest predictor of a song's popularity, conditional on the song's genre. We further found the theme and repetitiveness of a song's lyrics to mediate the relationship between the song's popularity and novelty. Broadly, our results contradict the \"optimal distinctiveness theory\" (balance between novelty and familiarity) and call for an investigation into the multiple dimensions along which a cultural product's uniqueness could manifest.",
        "published":1658846998000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.12943v2",
        "arxiv_primary_category":"cs.cy",
        "published_hr":"Jul 26, 2022",
        "arxiv_primary_category_hr":"Computers and Society",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.22744626,
        "popularmechanics":0.1623515377,
        "scienmag":0.1659239304,
        "technologyreview":0.2229907708,
        "vox":0.2587305727,
        "newscientist":0.1907814736,
        "vice":0.1540839163,
        "statnews":0.1690998913,
        "nytimes":0.2335916496,
        "techcrunch":0.2560630425,
        "quartz":0.2579796925,
        "venturebeat":0.2604363637,
        "futurism":0.1810190447,
        "scientificamerican":0.2325062941,
        "wired":0.2645114718,
        "popsci":0.2456131781,
        "arstechnica":0.1754545981,
        "salon":0.1812476936,
        "washingtonpost":0.2412853499,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.00871v1",
        "predicted_newsworthiness":46.1603373355,
        "title":"Power to the springs: Passive elements are sufficient to drive push-off in human walking",
        "summary":"For the impulsive ankle push-off (APO) observed in human walking two muscle-tendon-units (MTUs) spanning the ankle joint play an important role: Gastrocnemius (GAS) and Soleus (SOL). GAS and SOL load the Achilles tendon to store elastic energy during stance followed by a rapid energy release during APO. We use a neuromuscular simulation (NMS) and a bipedal robot to investigate the role of GAS and SOL on the APO. We optimize the simulation for a robust gait and then sequentially replace the MTUs of (1) GAS, (2) SOL and (3) GAS and SOL by linear springs. To validate the simulation, we implement NMS-3 on a bipedal robot. Simulation and robot walk steady for all trials showing an impulsive APO. Our results imply that the elastic MTU properties shape the impulsive APO. For prosthesis or robot design that is, no complex ankle actuation is needed to obtain an impulsive APO, if more mechanical intelligence is incorporated in the design.",
        "published":1651244738000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.00871v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Apr 29, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0905181143,
        "popularmechanics":0.1623713436,
        "scienmag":0.1505345667,
        "technologyreview":0.1525555869,
        "vox":0.0742571725,
        "newscientist":0.1537215857,
        "vice":0.1346616713,
        "statnews":0.0958942117,
        "nytimes":0.1154036881,
        "techcrunch":0.1110006436,
        "quartz":0.0894894415,
        "venturebeat":0.1177061855,
        "futurism":0.1761090495,
        "scientificamerican":0.1357105166,
        "wired":0.1351969633,
        "popsci":0.2014049271,
        "arstechnica":0.1015259767,
        "salon":0.0929674916,
        "washingtonpost":0.1263341716,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.13395v2",
        "predicted_newsworthiness":43.0930975787,
        "title":"Neural Collaborative Filtering Bandits via Meta Learning",
        "summary":"Contextual multi-armed bandits provide powerful tools to solve the exploitation-exploration dilemma in decision making, with direct applications in the personalized recommendation. In fact, collaborative effects among users carry the significant potential to improve the recommendation. In this paper, we introduce and study the problem by exploring `Neural Collaborative Filtering Bandits', where the rewards can be non-linear functions and groups are formed dynamically given different specific contents. To solve this problem, inspired by meta-learning, we propose Meta-Ban (meta-bandits), where a meta-learner is designed to represent and rapidly adapt to dynamic groups, along with a UCB-based exploration strategy. Furthermore, we analyze that Meta-Ban can achieve the regret bound of $\\mathcal{O}(\\sqrt{T \\log T})$, improving a multiplicative factor $\\sqrt{\\log T}$ over state-of-the-art related works. In the end, we conduct extensive experiments showing that Meta-Ban significantly outperforms six strong baselines.",
        "published":1643652054000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.13395v2",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jan 31, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1029259413,
        "popularmechanics":0.1221784547,
        "scienmag":0.1370884882,
        "technologyreview":0.2322425471,
        "vox":0.1542124041,
        "newscientist":0.1426782704,
        "vice":0.0994076312,
        "statnews":0.1909353792,
        "nytimes":0.1483956584,
        "techcrunch":0.1906135101,
        "quartz":0.1384853361,
        "venturebeat":0.2338616709,
        "futurism":0.1666414717,
        "scientificamerican":0.135347157,
        "wired":0.1865462934,
        "popsci":0.1677678186,
        "arstechnica":0.1297886155,
        "salon":0.1012995427,
        "washingtonpost":0.1505498374,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.02163v1",
        "predicted_newsworthiness":37.321959022,
        "title":"Leveraging Equivariant Features for Absolute Pose Regression",
        "summary":"While end-to-end approaches have achieved state-of-the-art performance in many perception tasks, they are not yet able to compete with 3D geometry-based methods in pose estimation. Moreover, absolute pose regression has been shown to be more related to image retrieval. As a result, we hypothesize that the statistical features learned by classical Convolutional Neural Networks do not carry enough geometric information to reliably solve this inherently geometric task. In this paper, we demonstrate how a translation and rotation equivariant Convolutional Neural Network directly induces representations of camera motions into the feature space. We then show that this geometric property allows for implicitly augmenting the training data under a whole group of image plane-preserving transformations. Therefore, we argue that directly learning equivariant features is preferable than learning data-intensive intermediate representations. Comprehensive experimental validation demonstrates that our lightweight model outperforms existing ones on standard datasets.",
        "published":1649162660000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.02163v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Apr 05, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0859661517,
        "popularmechanics":0.1233744851,
        "scienmag":0.0931833187,
        "technologyreview":0.1917127822,
        "vox":0.0940962483,
        "newscientist":0.1176738787,
        "vice":0.0922995843,
        "statnews":0.1042398256,
        "nytimes":0.1169108393,
        "techcrunch":0.131386471,
        "quartz":0.1015575395,
        "venturebeat":0.1803306246,
        "futurism":0.1422989049,
        "scientificamerican":0.0901377529,
        "wired":0.1513091523,
        "popsci":0.155092327,
        "arstechnica":0.089449213,
        "salon":0.07526322,
        "washingtonpost":0.1220056263,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.07255v1",
        "predicted_newsworthiness":48.05271428,
        "title":"Enhancing Cross-lingual Prompting with Mask Token Augmentation",
        "summary":"Prompting shows promising results in few-shot scenarios. However, its strength for multilingual\/cross-lingual problems has not been fully exploited. Zhao and Sch\\\"utze (2021) made initial explorations in this direction by presenting that cross-lingual prompting outperforms cross-lingual finetuning. In this paper, we conduct empirical analysis on the effect of each component in cross-lingual prompting and derive Universal Prompting across languages, which helps alleviate the discrepancies between source-language training and target-language inference. Based on this, we propose a mask token augmentation framework to further improve the performance of prompt-based cross-lingual transfer. Notably, for XNLI, our method achieves 46.54% with only 16 English training examples per class, significantly better than 34.99% of finetuning.",
        "published":1644915854000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.07255v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Feb 15, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0990528307,
        "popularmechanics":0.1151916457,
        "scienmag":0.1021505746,
        "technologyreview":0.2196875739,
        "vox":0.1144454203,
        "newscientist":0.119402892,
        "vice":0.0911406912,
        "statnews":0.1364677471,
        "nytimes":0.1323493978,
        "techcrunch":0.1550723176,
        "quartz":0.1295483689,
        "venturebeat":0.2216870609,
        "futurism":0.1499513248,
        "scientificamerican":0.1182121902,
        "wired":0.1449129854,
        "popsci":0.1654595598,
        "arstechnica":0.1114125908,
        "salon":0.0869373799,
        "washingtonpost":0.126982013,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.09630v1",
        "predicted_newsworthiness":43.29035796,
        "title":"Acceptability Judgements via Examining the Topology of Attention Maps",
        "summary":"The role of the attention mechanism in encoding linguistic knowledge has received special interest in NLP. However, the ability of the attention heads to judge the grammatical acceptability of a sentence has been underexplored. This paper approaches the paradigm of acceptability judgments with topological data analysis (TDA), showing that the geometric properties of the attention graph can be efficiently exploited for two standard practices in linguistics: binary judgments and linguistic minimal pairs. Topological features enhance the BERT-based acceptability classifier scores by $8$%-$24$% on CoLA in three languages (English, Italian, and Swedish). By revealing the topological discrepancy between attention maps of minimal pairs, we achieve the human-level performance on the BLiMP benchmark, outperforming nine statistical and Transformer LM baselines. At the same time, TDA provides the foundation for analyzing the linguistic functions of attention heads and interpreting the correspondence between the graph features and grammatical phenomena.",
        "published":1652975112000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.09630v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"May 19, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1175756195,
        "popularmechanics":0.1110690345,
        "scienmag":0.1447773778,
        "technologyreview":0.2170233516,
        "vox":0.1201425535,
        "newscientist":0.1539925281,
        "vice":0.121892613,
        "statnews":0.1890583602,
        "nytimes":0.1362301505,
        "techcrunch":0.1297126038,
        "quartz":0.1195062376,
        "venturebeat":0.1974778128,
        "futurism":0.1525191649,
        "scientificamerican":0.1473652295,
        "wired":0.1643044277,
        "popsci":0.1581863081,
        "arstechnica":0.114871555,
        "salon":0.109156369,
        "washingtonpost":0.1299968933,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.09318v1",
        "predicted_newsworthiness":66.1535373535,
        "title":"On Demographic Bias in Fingerprint Recognition",
        "summary":"Fingerprint recognition systems have been deployed globally in numerous applications including personal devices, forensics, law enforcement, banking, and national identity systems. For these systems to be socially acceptable and trustworthy, it is critical that they perform equally well across different demographic groups. In this work, we propose a formal statistical framework to test for the existence of bias (demographic differentials) in fingerprint recognition across four major demographic groups (white male, white female, black male, and black female) for two state-of-the-art (SOTA) fingerprint matchers operating in verification and identification modes. Experiments on two different fingerprint databases (with 15,468 and 1,014 subjects) show that demographic differentials in SOTA fingerprint recognition systems decrease as the matcher accuracy increases and any small bias that may be evident is likely due to certain outlier, low-quality fingerprint images.",
        "published":1652933459000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.09318v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 18, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2173656299,
        "popularmechanics":0.1599142719,
        "scienmag":0.2247166395,
        "technologyreview":0.2810919835,
        "vox":0.2191674971,
        "newscientist":0.2210531008,
        "vice":0.1633268814,
        "statnews":0.2228425576,
        "nytimes":0.2491932634,
        "techcrunch":0.2079189474,
        "quartz":0.2218737697,
        "venturebeat":0.2268462169,
        "futurism":0.2164535363,
        "scientificamerican":0.2234845433,
        "wired":0.2135528323,
        "popsci":0.2120059542,
        "arstechnica":0.2190487072,
        "salon":0.1976408866,
        "washingtonpost":0.2393889979,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.05533v1",
        "predicted_newsworthiness":62.0146560577,
        "title":"GaVe: A Webcam-Based Gaze Vending Interface Using One-Point Calibration",
        "summary":"Even before the Covid-19 pandemic, beneficial use cases for hygienic, touchless human-machine interaction have been explored. Gaze input, i.e., information input via eye-movements of users, represents a promising method for contact-free interaction in human-machine systems. In this paper, we present the GazeVending interface (GaVe), which lets users control actions on a display with their eyes. The interface works on a regular webcam, available on most of today's laptops, and only requires a one-point calibration before use. GaVe is designed in a hierarchical structure, presenting broad item cluster to users first and subsequently guiding them through another selection round, which allows the presentation of a large number of items. Cluster\/item selection in GaVe is based on the dwell time of fixations, i.e., the time duration that users look at a given Cluster\/item. A user study (N=22) was conducted to test optimal dwell time thresholds and comfortable human-to-display distances. Users' perception of the system, as well as error rates and task completion time were registered. We found that all participants were able to use the system with a short time training, and showed good performance during system usage, selecting a target item within a group of 12 items in 6.76 seconds on average. Participants were able to quickly understand and know how to interact with the interface. We provide design guidelines for GaVe and discuss the potentials of the system.",
        "published":1642176303000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.05533v1",
        "arxiv_primary_category":"cs.hc",
        "published_hr":"Jan 14, 2022",
        "arxiv_primary_category_hr":"Human-Computer Interaction",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1744350471,
        "popularmechanics":0.2470749745,
        "scienmag":0.2107048107,
        "technologyreview":0.3002070191,
        "vox":0.2146296696,
        "newscientist":0.2366519956,
        "vice":0.1495963097,
        "statnews":0.2555656565,
        "nytimes":0.2435844262,
        "techcrunch":0.2859743046,
        "quartz":0.2088427179,
        "venturebeat":0.3188259774,
        "futurism":0.2830930255,
        "scientificamerican":0.2107638657,
        "wired":0.3047886733,
        "popsci":0.338430134,
        "arstechnica":0.1855022796,
        "salon":0.1746854279,
        "washingtonpost":0.2675880042,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.00871v1",
        "predicted_newsworthiness":40.5231190663,
        "title":"Dense Voxel Fusion for 3D Object Detection",
        "summary":"Camera and LiDAR sensor modalities provide complementary appearance and geometric information useful for detecting 3D objects for autonomous vehicle applications. However, current fusion models underperform state-of-art LiDAR-only methods on 3D object detection benchmarks. Our proposed solution, Dense Voxel Fusion (DVF) is a sequential fusion method that generates multi-scale multi-modal dense voxel feature representations, improving expressiveness in low point density regions. To enhance multi-modal learning, we train directly with ground truth 2D bounding box labels, avoiding noisy, detector-specific, 2D predictions. Additionally, we use LiDAR ground truth sampling to simulate missed 2D detections and to accelerate training convergence. Both DVF and the multi-modal training approaches can be applied to any voxel-based LiDAR backbone without introducing additional learnable parameters. DVF outperforms existing sparse fusion detectors, ranking $1^{st}$ among all published fusion methods on KITTI's 3D car detection benchmark at the time of submission and significantly improves 3D vehicle detection performance of voxel-based methods on the Waymo Open Dataset. We also show that our proposed multi-modal training strategy results in better generalization compared to training using erroneous 2D predictions.",
        "published":1646196691000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.00871v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Mar 01, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0904510569,
        "popularmechanics":0.1984393849,
        "scienmag":0.130685149,
        "technologyreview":0.2362271487,
        "vox":0.1434754162,
        "newscientist":0.1481472351,
        "vice":0.1489086321,
        "statnews":0.1044965021,
        "nytimes":0.1346822929,
        "techcrunch":0.2011625596,
        "quartz":0.1249479331,
        "venturebeat":0.2265848745,
        "futurism":0.2173930233,
        "scientificamerican":0.1239941448,
        "wired":0.1985698582,
        "popsci":0.2259754114,
        "arstechnica":0.1501339884,
        "salon":0.1033274884,
        "washingtonpost":0.1641941018,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.14798v1",
        "predicted_newsworthiness":51.264560743,
        "title":"Personalized Promotion Decision Making Based on Direct and Enduring Effect Predictions",
        "summary":"Promotions have been trending in the e-commerce marketplace to build up customer relationships and guide customers towards the desired actions. Since incentives are effective to engage customers and customers have different preferences for different types of incentives, the demand for personalized promotion decision making is increasing over time. However, research on promotion decision making has focused specifically on purchase conversion during the promotion period (the direct effect), while generally disregarding the enduring effect in the post promotion period. To achieve a better lift return on investment (lift ROI) on the enduring effect of the promotion and improve customer retention and loyalty, we propose a framework of multiple treatment promotion decision making by modeling each customer's direct and enduring response. First, we propose a customer direct and enduring effect (CDEE) model which predicts the customer direct and enduring response. With the help of the predictions of the CDEE, we personalize incentive allocation to optimize the enduring effect while keeping the cost under the budget. To estimate the effect of decision making, we apply an unbiased evaluation approach of business metrics with randomized control trial (RCT) data. We compare our method with benchmarks using two promotions in Mercari and achieve significantly better results.",
        "published":1658560437000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.14798v1",
        "arxiv_primary_category":"cs.ir",
        "published_hr":"Jul 23, 2022",
        "arxiv_primary_category_hr":"Information Retrieval",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1668100658,
        "popularmechanics":0.1487448541,
        "scienmag":0.1822129379,
        "technologyreview":0.2216382102,
        "vox":0.2278894097,
        "newscientist":0.1508793091,
        "vice":0.1013347443,
        "statnews":0.2243624279,
        "nytimes":0.1879255929,
        "techcrunch":0.2922887673,
        "quartz":0.2264878598,
        "venturebeat":0.2993651441,
        "futurism":0.1816435966,
        "scientificamerican":0.1569722411,
        "wired":0.1898735059,
        "popsci":0.1929196073,
        "arstechnica":0.1883675896,
        "salon":0.1521739715,
        "washingtonpost":0.1990749836,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.00129v1",
        "predicted_newsworthiness":64.9231709923,
        "title":"Fairness Transferability Subject to Bounded Distribution Shift",
        "summary":"Given an algorithmic predictor that is \"fair\" on some source distribution, will it still be fair on an unknown target distribution that differs from the source within some bound? In this paper, we study the transferability of statistical group fairness for machine learning predictors (i.e., classifiers or regressors) subject to bounded distribution shift, a phenomenon frequently caused by user adaptation to a deployed model or a dynamic environment. Herein, we develop a bound characterizing such transferability, flagging potentially inappropriate deployments of machine learning for socially consequential tasks. We first develop a framework for bounding violations of statistical fairness subject to distribution shift, formulating a generic upper bound for transferred fairness violation as our primary result. We then develop bounds for specific worked examples, adopting two commonly used fairness definitions (i.e., demographic parity and equalized odds) for two classes of distribution shift (i.e., covariate shift and label shift). Finally, we compare our theoretical bounds to deterministic models of distribution shift as well as real-world data.",
        "published":1654035404000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.00129v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"May 31, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2142908238,
        "popularmechanics":0.138827485,
        "scienmag":0.2129294401,
        "technologyreview":0.3101092009,
        "vox":0.2502296747,
        "newscientist":0.1982308414,
        "vice":0.1511990311,
        "statnews":0.274058807,
        "nytimes":0.2457459272,
        "techcrunch":0.233070567,
        "quartz":0.2276899998,
        "venturebeat":0.2704992994,
        "futurism":0.2254645365,
        "scientificamerican":0.2140755451,
        "wired":0.2403590364,
        "popsci":0.2122291649,
        "arstechnica":0.2186542369,
        "salon":0.2022936946,
        "washingtonpost":0.2479391221,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.04927v1",
        "predicted_newsworthiness":42.6578874577,
        "title":"Ego2HandsPose: A Dataset for Egocentric Two-hand 3D Global Pose Estimation",
        "summary":"Color-based two-hand 3D pose estimation in the global coordinate system is essential in many applications. However, there are very few datasets dedicated to this task and no existing dataset supports estimation in a non-laboratory environment. This is largely attributed to the sophisticated data collection process required for 3D hand pose annotations, which also leads to difficulty in obtaining instances with the level of visual diversity needed for estimation in the wild. Progressing towards this goal, a large-scale dataset Ego2Hands was recently proposed to address the task of two-hand segmentation and detection in the wild. The proposed composition-based data generation technique can create two-hand instances with quality, quantity and diversity that generalize well to unseen domains. In this work, we present Ego2HandsPose, an extension of Ego2Hands that contains 3D hand pose annotation and is the first dataset that enables color-based two-hand 3D tracking in unseen domains. To this end, we develop a set of parametric fitting algorithms to enable 1) 3D hand pose annotation using a single image, 2) automatic conversion from 2D to 3D hand poses and 3) accurate two-hand tracking with temporal consistency. We provide incremental quantitative analysis on the multi-stage pipeline and show that training on our dataset achieves state-of-the-art results that significantly outperforms other datasets for the task of egocentric two-hand global 3D pose estimation.",
        "published":1654847445000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.04927v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jun 10, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0858627589,
        "popularmechanics":0.1353073299,
        "scienmag":0.1101081325,
        "technologyreview":0.1946727702,
        "vox":0.0949458472,
        "newscientist":0.1384999547,
        "vice":0.1086744912,
        "statnews":0.1051038201,
        "nytimes":0.1251743131,
        "techcrunch":0.1434101337,
        "quartz":0.1074645886,
        "venturebeat":0.1934647206,
        "futurism":0.1627694569,
        "scientificamerican":0.1011280886,
        "wired":0.1539781514,
        "popsci":0.1639595837,
        "arstechnica":0.0919066572,
        "salon":0.0841708356,
        "washingtonpost":0.1320469477,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.05323v1",
        "predicted_newsworthiness":54.8933739662,
        "title":"Exploiting the Potential of Datasets: A Data-Centric Approach for Model Robustness",
        "summary":"Robustness of deep neural networks (DNNs) to malicious perturbations is a hot topic in trustworthy AI. Existing techniques obtain robust models given fixed datasets, either by modifying model structures, or by optimizing the process of inference or training. While significant improvements have been made, the possibility of constructing a high-quality dataset for model robustness remain unexplored. Follow the campaign of data-centric AI launched by Andrew Ng, we propose a novel algorithm for dataset enhancement that works well for many existing DNN models to improve robustness. Transferable adversarial examples and 14 kinds of common corruptions are included in our optimized dataset. In the data-centric robust learning competition hosted by Alibaba Group and Tsinghua University, our algorithm came third out of more than 3000 competitors in the first stage while we ranked fourth in the second stage. Our code is available at \\url{https:\/\/github.com\/hncszyq\/tianchi_challenge}.",
        "published":1646914592000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.05323v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Mar 10, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1406275431,
        "popularmechanics":0.1901697627,
        "scienmag":0.1668434818,
        "technologyreview":0.3677969322,
        "vox":0.2247949079,
        "newscientist":0.2054882758,
        "vice":0.155672599,
        "statnews":0.282123357,
        "nytimes":0.217054501,
        "techcrunch":0.2409587746,
        "quartz":0.1819718059,
        "venturebeat":0.3243630162,
        "futurism":0.2639494752,
        "scientificamerican":0.1556385788,
        "wired":0.260671631,
        "popsci":0.2522379841,
        "arstechnica":0.2223711208,
        "salon":0.1414009909,
        "washingtonpost":0.2459238027,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.04759v1",
        "predicted_newsworthiness":46.5027032437,
        "title":"WG-VITON: Wearing-Guide Virtual Try-On for Top and Bottom Clothes",
        "summary":"Studies of virtual try-on (VITON) have been shown their effectiveness in utilizing the generative neural network for virtually exploring fashion products, and some of recent researches of VITON attempted to synthesize human image wearing given multiple types of garments (e.g., top and bottom clothes). However, when replacing the top and bottom clothes of the target human, numerous wearing styles are possible with a certain combination of the clothes. In this paper, we address the problem of variation in wearing style when simultaneously replacing the top and bottom clothes of the model. We introduce Wearing-Guide VITON (i.e., WG-VITON) which utilizes an additional input binary mask to control the wearing styles of the generated image. Our experiments show that WG-VITON effectively generates an image of the model wearing given top and bottom clothes, and create complicated wearing styles such as partly tucking in the top to the bottom",
        "published":1652173742000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.04759v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 10, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1005701813,
        "popularmechanics":0.1590264156,
        "scienmag":0.1173272586,
        "technologyreview":0.199300204,
        "vox":0.1061097829,
        "newscientist":0.1516175234,
        "vice":0.0921330098,
        "statnews":0.1041225296,
        "nytimes":0.1519080494,
        "techcrunch":0.1436842511,
        "quartz":0.1485843238,
        "venturebeat":0.1965490694,
        "futurism":0.1763406592,
        "scientificamerican":0.1105263163,
        "wired":0.1837938272,
        "popsci":0.1864035933,
        "arstechnica":0.0932427563,
        "salon":0.0850912548,
        "washingtonpost":0.1363021757,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.04676v3",
        "predicted_newsworthiness":38.2512956372,
        "title":"UniFormer: Unified Transformer for Efficient Spatiotemporal Representation Learning",
        "summary":"It is a challenging task to learn rich and multi-scale spatiotemporal semantics from high-dimensional videos, due to large local redundancy and complex global dependency between video frames. The recent advances in this research have been mainly driven by 3D convolutional neural networks and vision transformers. Although 3D convolution can efficiently aggregate local context to suppress local redundancy from a small 3D neighborhood, it lacks the capability to capture global dependency because of the limited receptive field. Alternatively, vision transformers can effectively capture long-range dependency by self-attention mechanism, while having the limitation on reducing local redundancy with blind similarity comparison among all the tokens in each layer. Based on these observations, we propose a novel Unified transFormer (UniFormer) which seamlessly integrates merits of 3D convolution and spatiotemporal self-attention in a concise transformer format, and achieves a preferable balance between computation and accuracy. Different from traditional transformers, our relation aggregator can tackle both spatiotemporal redundancy and dependency, by learning local and global token affinity respectively in shallow and deep layers. We conduct extensive experiments on the popular video benchmarks, e.g., Kinetics-400, Kinetics-600, and Something-Something V1&V2. With only ImageNet-1K pretraining, our UniFormer achieves 82.9%\/84.8% top-1 accuracy on Kinetics-400\/Kinetics-600, while requiring 10x fewer GFLOPs than other state-of-the-art methods. For Something-Something V1 and V2, our UniFormer achieves new state-of-the-art performances of 60.9% and 71.2% top-1 accuracy respectively. Code is available at https:\/\/github.com\/Sense-X\/UniFormer.",
        "published":1642017752000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.04676v3",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jan 12, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1054349466,
        "popularmechanics":0.1273709061,
        "scienmag":0.1075282575,
        "technologyreview":0.1951001243,
        "vox":0.1315338903,
        "newscientist":0.1293549884,
        "vice":0.1043784376,
        "statnews":0.1154141624,
        "nytimes":0.130653285,
        "techcrunch":0.140740884,
        "quartz":0.1212400248,
        "venturebeat":0.1838641139,
        "futurism":0.1391112176,
        "scientificamerican":0.1088617764,
        "wired":0.165074153,
        "popsci":0.1577970528,
        "arstechnica":0.1028255738,
        "salon":0.1082066247,
        "washingtonpost":0.1318034457,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.12175v1",
        "predicted_newsworthiness":52.540658124,
        "title":"Safe Policy Improvement Approaches on Discrete Markov Decision Processes",
        "summary":"Safe Policy Improvement (SPI) aims at provable guarantees that a learned policy is at least approximately as good as a given baseline policy. Building on SPI with Soft Baseline Bootstrapping (Soft-SPIBB) by Nadjahi et al., we identify theoretical issues in their approach, provide a corrected theory, and derive a new algorithm that is provably safe on finite Markov Decision Processes (MDP). Additionally, we provide a heuristic algorithm that exhibits the best performance among many state of the art SPI algorithms on two different benchmarks. Furthermore, we introduce a taxonomy of SPI algorithms and empirically show an interesting property of two classes of SPI algorithms: while the mean performance of algorithms that incorporate the uncertainty as a penalty on the action-value is higher, actively restricting the set of policies more consistently produces good policies and is, thus, safer.",
        "published":1643383014000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.12175v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jan 28, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.120447046,
        "popularmechanics":0.1330716039,
        "scienmag":0.1259386555,
        "technologyreview":0.2207003568,
        "vox":0.1412619862,
        "newscientist":0.1338916562,
        "vice":0.1006510646,
        "statnews":0.1980478167,
        "nytimes":0.1484329257,
        "techcrunch":0.1630794242,
        "quartz":0.1326995763,
        "venturebeat":0.2117871637,
        "futurism":0.1648386623,
        "scientificamerican":0.1185394581,
        "wired":0.1680828934,
        "popsci":0.1667098524,
        "arstechnica":0.1450727991,
        "salon":0.134894141,
        "washingtonpost":0.134629808,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.02617v1",
        "predicted_newsworthiness":48.8024906846,
        "title":"Adaptive Fine-Tuning of Transformer-Based Language Models for Named Entity Recognition",
        "summary":"The current standard approach for fine-tuning transformer-based language models includes a fixed number of training epochs and a linear learning rate schedule. In order to obtain a near-optimal model for the given downstream task, a search in optimization hyperparameter space is usually required. In particular, the number of training epochs needs to be adjusted to the dataset size. In this paper, we introduce adaptive fine-tuning, which is an alternative approach that uses early stopping and a custom learning rate schedule to dynamically adjust the number of training epochs to the dataset size. For the example use case of named entity recognition, we show that our approach not only makes hyperparameter search with respect to the number of training epochs redundant, but also leads to improved results in terms of performance, stability and efficiency. This holds true especially for small datasets, where we outperform the state-of-the-art fine-tuning method by a large margin.",
        "published":1644088803000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.02617v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Feb 05, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0798094865,
        "popularmechanics":0.1181708676,
        "scienmag":0.1028252343,
        "technologyreview":0.1950251219,
        "vox":0.1270792347,
        "newscientist":0.0987056199,
        "vice":0.0836551006,
        "statnews":0.1463925511,
        "nytimes":0.114933187,
        "techcrunch":0.1585875466,
        "quartz":0.1121436921,
        "venturebeat":0.2088118202,
        "futurism":0.140346495,
        "scientificamerican":0.0923191207,
        "wired":0.1460061768,
        "popsci":0.149082763,
        "arstechnica":0.1178587663,
        "salon":0.0841747829,
        "washingtonpost":0.1229397355,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.03799v2",
        "predicted_newsworthiness":39.1068455715,
        "title":"Dyna-DM: Dynamic Object-aware Self-supervised Monocular Depth Maps",
        "summary":"Self-supervised monocular depth estimation has been a subject of intense study in recent years, because of its applications in robotics and autonomous driving. Much of the recent work focuses on improving depth estimation by increasing architecture complexity. This paper shows that state-of-the-art performance can also be achieved by improving the learning process rather than increasing model complexity. More specifically, we propose (i) only using invariant pose loss for the first few epochs during training, (ii) disregarding small potentially dynamic objects when training, and (iii) employing an appearance-based approach to separately estimate object pose for truly dynamic objects. We demonstrate that these simplifications reduce GPU memory usage by 29% and result in qualitatively and quantitatively improved depth maps. The code is available at https:\/\/github.com\/kieran514\/Dyna-DM.",
        "published":1654684951000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.03799v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jun 08, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0850879123,
        "popularmechanics":0.1568329676,
        "scienmag":0.0974338042,
        "technologyreview":0.215664575,
        "vox":0.114523554,
        "newscientist":0.1313499461,
        "vice":0.1207537816,
        "statnews":0.0729372811,
        "nytimes":0.1181165851,
        "techcrunch":0.1695554008,
        "quartz":0.1078430824,
        "venturebeat":0.2167313024,
        "futurism":0.1778670394,
        "scientificamerican":0.1021578344,
        "wired":0.1803916534,
        "popsci":0.1892653932,
        "arstechnica":0.1013984596,
        "salon":0.0865424191,
        "washingtonpost":0.1278977393,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.05165v1",
        "predicted_newsworthiness":44.452206083,
        "title":"Multifidelity Reinforcement Learning with Control Variates",
        "summary":"In many computational science and engineering applications, the output of a system of interest corresponding to a given input can be queried at different levels of fidelity with different costs. Typically, low-fidelity data is cheap and abundant, while high-fidelity data is expensive and scarce. In this work we study the reinforcement learning (RL) problem in the presence of multiple environments with different levels of fidelity for a given control task. We focus on improving the RL agent's performance with multifidelity data. Specifically, a multifidelity estimator that exploits the cross-correlations between the low- and high-fidelity returns is proposed to reduce the variance in the estimation of the state-action value function. The proposed estimator, which is based on the method of control variates, is used to design a multifidelity Monte Carlo RL (MFMCRL) algorithm that improves the learning of the agent in the high-fidelity environment. The impacts of variance reduction on policy evaluation and policy improvement are theoretically analyzed by using probability bounds. Our theoretical analysis and numerical experiments demonstrate that for a finite budget of high-fidelity data samples, our proposed MFMCRL agent attains superior performance compared with that of a standard RL agent that uses only the high-fidelity environment data for learning the optimal policy.",
        "published":1654873297000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.05165v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jun 10, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.091035428,
        "popularmechanics":0.1268179867,
        "scienmag":0.1208399132,
        "technologyreview":0.2049256953,
        "vox":0.1009361388,
        "newscientist":0.1173634793,
        "vice":0.0992898218,
        "statnews":0.1406833464,
        "nytimes":0.1248114802,
        "techcrunch":0.1263980832,
        "quartz":0.1062132012,
        "venturebeat":0.1720242397,
        "futurism":0.1566819959,
        "scientificamerican":0.1062928277,
        "wired":0.1307174219,
        "popsci":0.1482334016,
        "arstechnica":0.1157361705,
        "salon":0.088846056,
        "washingtonpost":0.1082742992,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.02925v1",
        "predicted_newsworthiness":42.8321541691,
        "title":"Benchmarking Deep Models for Salient Object Detection",
        "summary":"In recent years, deep network-based methods have continuously refreshed state-of-the-art performance on Salient Object Detection (SOD) task. However, the performance discrepancy caused by different implementation details may conceal the real progress in this task. Making an impartial comparison is required for future researches. To meet this need, we construct a general SALient Object Detection (SALOD) benchmark to conduct a comprehensive comparison among several representative SOD methods. Specifically, we re-implement 14 representative SOD methods by using consistent settings for training. Moreover, two additional protocols are set up in our benchmark to investigate the robustness of existing methods in some limited conditions. In the first protocol, we enlarge the difference between objectness distributions of train and test sets to evaluate the robustness of these SOD methods. In the second protocol, we build multiple train subsets with different scales to validate whether these methods can extract discriminative features from only a few samples. In the above experiments, we find that existing loss functions usually specialized in some metrics but reported inferior results on the others. Therefore, we propose a novel Edge-Aware (EA) loss that promotes deep networks to learn more discriminative features by integrating both pixel- and image-level supervision signals. Experiments prove that our EA loss reports more robust performances compared to existing losses.",
        "published":1644205396000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.02925v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Feb 06, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0893886369,
        "popularmechanics":0.1364406607,
        "scienmag":0.1163953989,
        "technologyreview":0.2191052875,
        "vox":0.1204816024,
        "newscientist":0.1343593846,
        "vice":0.1124924146,
        "statnews":0.1321294913,
        "nytimes":0.1232686018,
        "techcrunch":0.1528471885,
        "quartz":0.1160240092,
        "venturebeat":0.2024388189,
        "futurism":0.1578583407,
        "scientificamerican":0.1175245367,
        "wired":0.1644257367,
        "popsci":0.1694279789,
        "arstechnica":0.100567041,
        "salon":0.0827951019,
        "washingtonpost":0.1353412779,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.08387v2",
        "predicted_newsworthiness":60.7607572426,
        "title":"Understanding and Detecting Hateful Content using Contrastive Learning",
        "summary":"The spread of hate speech and hateful imagery on the Web is a significant problem that needs to be mitigated to improve our Web experience. This work contributes to research efforts to detect and understand hateful content on the Web by undertaking a multimodal analysis of Antisemitism and Islamophobia on 4chan's \/pol\/ using OpenAI's CLIP. This large pre-trained model uses the Contrastive Learning paradigm. We devise a methodology to identify a set of Antisemitic and Islamophobic hateful textual phrases using Google's Perspective API and manual annotations. Then, we use OpenAI's CLIP to identify images that are highly similar to our Antisemitic\/Islamophobic textual phrases. By running our methodology on a dataset that includes 66M posts and 5.8M images shared on 4chan's \/pol\/ for 18 months, we detect 173K posts containing 21K Antisemitic\/Islamophobic images and 246K posts that include 420 hateful phrases. Among other things, we find that we can use OpenAI's CLIP model to detect hateful content with an accuracy score of 0.81 (F1 score = 0.54). By comparing CLIP with two baselines proposed by the literature, we find that CLIP outperforms them, in terms of accuracy, precision, and F1 score, in detecting Antisemitic\/Islamophobic images. Also, we find that Antisemitic\/Islamophobic imagery is shared in a similar number of posts on 4chan's \/pol\/ compared to Antisemitic\/Islamophobic textual phrases, highlighting the need to design more tools for detecting hateful imagery. Finally, we make available (upon request) a dataset of 246K posts containing 420 Antisemitic\/Islamophobic phrases and 21K likely Antisemitic\/Islamophobic images (automatically detected by CLIP) that can assist researchers in further understanding Antisemitism and Islamophobia.",
        "published":1642789349000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.08387v2",
        "arxiv_primary_category":"cs.si",
        "published_hr":"Jan 21, 2022",
        "arxiv_primary_category_hr":"Social and Information Networks",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2549867867,
        "popularmechanics":0.1456996593,
        "scienmag":0.1842983788,
        "technologyreview":0.3492988536,
        "vox":0.3039464288,
        "newscientist":0.2106767948,
        "vice":0.1455939994,
        "statnews":0.252854864,
        "nytimes":0.2611141967,
        "techcrunch":0.2368437228,
        "quartz":0.2503186308,
        "venturebeat":0.2866997021,
        "futurism":0.2449273398,
        "scientificamerican":0.1942150682,
        "wired":0.3163578896,
        "popsci":0.2424597361,
        "arstechnica":0.2477971018,
        "salon":0.2210746841,
        "washingtonpost":0.3633739633,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.03811v2",
        "predicted_newsworthiness":36.7366598295,
        "title":"Data-Free Adversarial Knowledge Distillation for Graph Neural Networks",
        "summary":"Graph neural networks (GNNs) have been widely used in modeling graph structured data, owing to its impressive performance in a wide range of practical applications. Recently, knowledge distillation (KD) for GNNs has enabled remarkable progress in graph model compression and knowledge transfer. However, most of the existing KD methods require a large volume of real data, which are not readily available in practice, and may preclude their applicability in scenarios where the teacher model is trained on rare or hard to acquire datasets. To address this problem, we propose the first end-to-end framework for data-free adversarial knowledge distillation on graph structured data (DFAD-GNN). To be specific, our DFAD-GNN employs a generative adversarial network, which mainly consists of three components: a pre-trained teacher model and a student model are regarded as two discriminators, and a generator is utilized for deriving training graphs to distill knowledge from the teacher model into the student model. Extensive experiments on various benchmark models and six representative datasets demonstrate that our DFAD-GNN significantly surpasses state-of-the-art data-free baselines in the graph classification task.",
        "published":1651997980000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.03811v2",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"May 08, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1012439637,
        "popularmechanics":0.1093358544,
        "scienmag":0.1268545205,
        "technologyreview":0.2282196641,
        "vox":0.1594361093,
        "newscientist":0.1303317921,
        "vice":0.0971063162,
        "statnews":0.1752996609,
        "nytimes":0.138083619,
        "techcrunch":0.1417906787,
        "quartz":0.1187576931,
        "venturebeat":0.199791981,
        "futurism":0.1530317472,
        "scientificamerican":0.1134300582,
        "wired":0.1545494513,
        "popsci":0.1542140571,
        "arstechnica":0.1323763323,
        "salon":0.1061598605,
        "washingtonpost":0.1759431208,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.06946v2",
        "predicted_newsworthiness":54.9171443332,
        "title":"Visualization for Epidemiological Modelling: Challenges, Solutions, Reflections & Recommendations",
        "summary":"We report on an ongoing collaboration between epidemiological modellers and visualization researchers by documenting and reflecting upon knowledge constructs -- a series of ideas, approaches and methods taken from existing visualization research and practice -- deployed and developed to support modelling of the COVID-19 pandemic. Structured independent commentary on these efforts is synthesized through iterative reflection to develop: evidence of the effectiveness and value of visualization in this context; open problems upon which the research communities may focus; guidance for future activity of this type; and recommendations to safeguard the achievements and promote, advance, secure and prepare for future collaborations of this kind. In describing and comparing a series of related projects that were undertaken in unprecedented conditions, our hope is that this unique report, and its rich interactive supplementary materials, will guide the scientific community in embracing visualization in its observation, analysis and modelling of data as well as in disseminating findings. Equally we hope to encourage the visualization community to engage with impactful science in addressing its emerging data challenges. If we are successful, this showcase of activity may stimulate mutually beneficial engagement between communities with complementary expertise to address problems of significance in epidemiology and beyond. https:\/\/ramp-vis.github.io\/RAMPVIS-PhilTransA-Supplement\/",
        "published":1649942305000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.06946v2",
        "arxiv_primary_category":"cs.hc",
        "published_hr":"Apr 14, 2022",
        "arxiv_primary_category_hr":"Human-Computer Interaction",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.3300828032,
        "popularmechanics":0.1869130567,
        "scienmag":0.3352577499,
        "technologyreview":0.3205578546,
        "vox":0.3360898167,
        "newscientist":0.3160075376,
        "vice":0.2587634478,
        "statnews":0.3969612589,
        "nytimes":0.3096753389,
        "techcrunch":0.2100967696,
        "quartz":0.2472437385,
        "venturebeat":0.2239869192,
        "futurism":0.2714460784,
        "scientificamerican":0.339050225,
        "wired":0.2388077504,
        "popsci":0.2552875675,
        "arstechnica":0.2903850402,
        "salon":0.3718845856,
        "washingtonpost":0.2696923924,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.05541v1",
        "predicted_newsworthiness":55.4395836025,
        "title":"Not always about you: Prioritizing community needs when developing endangered language technology",
        "summary":"Languages are classified as low-resource when they lack the quantity of data necessary for training statistical and machine learning tools and models. Causes of resource scarcity vary but can include poor access to technology for developing these resources, a relatively small population of speakers, or a lack of urgency for collecting such resources in bilingual populations where the second language is high-resource. As a result, the languages described as low-resource in the literature are as different as Finnish on the one hand, with millions of speakers using it in every imaginable domain, and Seneca, with only a small-handful of fluent speakers using the language primarily in a restricted domain. While issues stemming from the lack of resources necessary to train models unite this disparate group of languages, many other issues cut across the divide between widely-spoken low resource languages and endangered languages. In this position paper, we discuss the unique technological, cultural, practical, and ethical challenges that researchers and indigenous speech community members face when working together to develop language technology to support endangered language documentation and revitalization. We report the perspectives of language teachers, Master Speakers and elders from indigenous communities, as well as the point of view of academics. We describe an ongoing fruitful collaboration and make recommendations for future partnerships between academic researchers and language community stakeholders.",
        "published":1649743179000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.05541v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Apr 12, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2606981073,
        "popularmechanics":0.1476212472,
        "scienmag":0.2168925424,
        "technologyreview":0.2599850291,
        "vox":0.214415231,
        "newscientist":0.2165139077,
        "vice":0.2137004468,
        "statnews":0.213948337,
        "nytimes":0.2345327145,
        "techcrunch":0.2066928816,
        "quartz":0.2126570141,
        "venturebeat":0.231022237,
        "futurism":0.194933523,
        "scientificamerican":0.2797454761,
        "wired":0.2331100199,
        "popsci":0.2061131808,
        "arstechnica":0.1892096833,
        "salon":0.2298190984,
        "washingtonpost":0.215868705,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.01029v2",
        "predicted_newsworthiness":46.4289992793,
        "title":"Weakly-supervised continual learning for class-incremental segmentation",
        "summary":"Transfer learning is a powerful way to adapt existing deep learning models to new emerging use-cases in remote sensing. Starting from a neural network already trained for semantic segmentation, we propose to modify its label space to swiftly adapt it to new classes under weak supervision. To alleviate the background shift and the catastrophic forgetting problems inherent to this form of continual learning, we compare different regularization terms and leverage a pseudo-label strategy. We experimentally show the relevance of our approach on three public remote sensing datasets. Code is open-source and released in this repository: https:\/\/github.com\/alteia-ai\/ICSS}{https:\/\/github.com\/alteia-ai\/ICSS.",
        "published":1641284039000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.01029v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jan 04, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1102406291,
        "popularmechanics":0.141638855,
        "scienmag":0.1512555816,
        "technologyreview":0.166250347,
        "vox":0.1060854144,
        "newscientist":0.1500258448,
        "vice":0.1671288661,
        "statnews":0.1052474603,
        "nytimes":0.1249909918,
        "techcrunch":0.1077869473,
        "quartz":0.0940180577,
        "venturebeat":0.1422050266,
        "futurism":0.1420332753,
        "scientificamerican":0.1610740216,
        "wired":0.1415180046,
        "popsci":0.143842924,
        "arstechnica":0.1312961103,
        "salon":0.1343180771,
        "washingtonpost":0.1282232984,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.07788v2",
        "predicted_newsworthiness":36.9064522926,
        "title":"ConDor: Self-Supervised Canonicalization of 3D Pose for Partial Shapes",
        "summary":"Progress in 3D object understanding has relied on manually canonicalized shape datasets that contain instances with consistent position and orientation (3D pose). This has made it hard to generalize these methods to in-the-wild shapes, eg., from internet model collections or depth sensors. ConDor is a self-supervised method that learns to Canonicalize the 3D orientation and position for full and partial 3D point clouds. We build on top of Tensor Field Networks (TFNs), a class of permutation- and rotation-equivariant, and translation-invariant 3D networks. During inference, our method takes an unseen full or partial 3D point cloud at an arbitrary pose and outputs an equivariant canonical pose. During training, this network uses self-supervision losses to learn the canonical pose from an un-canonicalized collection of full and partial 3D point clouds. ConDor can also learn to consistently co-segment object parts without any supervision. Extensive quantitative results on four new metrics show that our approach outperforms existing methods while enabling new applications such as operation on depth images and annotation transfer.",
        "published":1642618641000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.07788v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jan 19, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0806518801,
        "popularmechanics":0.1228955821,
        "scienmag":0.1047165427,
        "technologyreview":0.1798837857,
        "vox":0.096373841,
        "newscientist":0.1133565578,
        "vice":0.1022292891,
        "statnews":0.0987879279,
        "nytimes":0.1045320444,
        "techcrunch":0.13461545,
        "quartz":0.094962142,
        "venturebeat":0.175678572,
        "futurism":0.1354841954,
        "scientificamerican":0.0865819656,
        "wired":0.1382761733,
        "popsci":0.1387408613,
        "arstechnica":0.0948845749,
        "salon":0.076443235,
        "washingtonpost":0.1107884204,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.12690v1",
        "predicted_newsworthiness":46.2004798881,
        "title":"On Modality Bias Recognition and Reduction",
        "summary":"Making each modality in multi-modal data contribute is of vital importance to learning a versatile multi-modal model. Existing methods, however, are often dominated by one or few of modalities during model training, resulting in sub-optimal performance. In this paper, we refer to this problem as modality bias and attempt to study it in the context of multi-modal classification systematically and comprehensively. After stepping into several empirical analysis, we recognize that one modality affects the model prediction more just because this modality has a spurious correlation with instance labels. In order to primarily facilitate the evaluation on the modality bias problem, we construct two datasets respectively for the colored digit recognition and video action recognition tasks in line with the Out-of-Distribution (OoD) protocol. Collaborating with the benchmarks in the visual question answering task, we empirically justify the performance degradation of the existing methods on these OoD datasets, which serves as evidence to justify the modality bias learning. In addition, to overcome this problem, we propose a plug-and-play loss function method, whereby the feature space for each label is adaptively learned according to the training set statistics. Thereafter, we apply this method on eight baselines in total to test its effectiveness. From the results on four datasets regarding the above three tasks, our method yields remarkable performance improvements compared with the baselines, demonstrating its superiority on reducing the modality bias problem.",
        "published":1645796829000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.12690v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Feb 25, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1077350862,
        "popularmechanics":0.1270901548,
        "scienmag":0.1250153081,
        "technologyreview":0.2289040267,
        "vox":0.1293843296,
        "newscientist":0.1382748582,
        "vice":0.0866713735,
        "statnews":0.1564152403,
        "nytimes":0.1286653069,
        "techcrunch":0.1399793723,
        "quartz":0.1176568833,
        "venturebeat":0.2071898623,
        "futurism":0.1565662879,
        "scientificamerican":0.1216577481,
        "wired":0.1581064487,
        "popsci":0.1686501605,
        "arstechnica":0.1144070103,
        "salon":0.0902723296,
        "washingtonpost":0.1434425294,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.16778v1",
        "predicted_newsworthiness":43.2717998666,
        "title":"ViSTA: Vision and Scene Text Aggregation for Cross-Modal Retrieval",
        "summary":"Visual appearance is considered to be the most important cue to understand images for cross-modal retrieval, while sometimes the scene text appearing in images can provide valuable information to understand the visual semantics. Most of existing cross-modal retrieval approaches ignore the usage of scene text information and directly adding this information may lead to performance degradation in scene text free scenarios. To address this issue, we propose a full transformer architecture to unify these cross-modal retrieval scenarios in a single $\\textbf{Vi}$sion and $\\textbf{S}$cene $\\textbf{T}$ext $\\textbf{A}$ggregation framework (ViSTA). Specifically, ViSTA utilizes transformer blocks to directly encode image patches and fuse scene text embedding to learn an aggregated visual representation for cross-modal retrieval. To tackle the modality missing problem of scene text, we propose a novel fusion token based transformer aggregation approach to exchange the necessary scene text information only through the fusion token and concentrate on the most important features in each modality. To further strengthen the visual modality, we develop dual contrastive learning losses to embed both image-text pairs and fusion-text pairs into a common cross-modal space. Compared to existing methods, ViSTA enables to aggregate relevant scene text semantics with visual appearance, and hence improve results under both scene text free and scene text aware scenarios. Experimental results show that ViSTA outperforms other methods by at least $\\bf{8.4}\\%$ at Recall@1 for scene text aware retrieval task. Compared with state-of-the-art scene text free retrieval methods, ViSTA can achieve better accuracy on Flicker30K and MSCOCO while running at least three times faster during the inference stage, which validates the effectiveness of the proposed framework.",
        "published":1648698021000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.16778v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Mar 30, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0837181475,
        "popularmechanics":0.1487217569,
        "scienmag":0.1105827196,
        "technologyreview":0.2149584258,
        "vox":0.1260696678,
        "newscientist":0.1247221645,
        "vice":0.1071201045,
        "statnews":0.0877842518,
        "nytimes":0.1254373485,
        "techcrunch":0.1723575506,
        "quartz":0.1149040055,
        "venturebeat":0.2219199831,
        "futurism":0.1697769811,
        "scientificamerican":0.1064985916,
        "wired":0.1788588536,
        "popsci":0.1939546868,
        "arstechnica":0.1266248316,
        "salon":0.0726478528,
        "washingtonpost":0.150523194,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.03436v1",
        "predicted_newsworthiness":47.4424118028,
        "title":"EdgeViTs: Competing Light-weight CNNs on Mobile Devices with Vision Transformers",
        "summary":"Self-attention based models such as vision transformers (ViTs) have emerged as a very competitive architecture alternative to convolutional neural networks (CNNs) in computer vision. Despite increasingly stronger variants with ever-higher recognition accuracies, due to the quadratic complexity of self-attention, existing ViTs are typically demanding in computation and model size. Although several successful design choices (e.g., the convolutions and hierarchical multi-stage structure) of prior CNNs have been reintroduced into recent ViTs, they are still not sufficient to meet the limited resource requirements of mobile devices. This motivates a very recent attempt to develop light ViTs based on the state-of-the-art MobileNet-v2, but still leaves a performance gap behind. In this work, pushing further along this under-studied direction we introduce EdgeViTs, a new family of light-weight ViTs that, for the first time, enable attention-based vision models to compete with the best light-weight CNNs in the tradeoff between accuracy and on-device efficiency. This is realized by introducing a highly cost-effective local-global-local (LGL) information exchange bottleneck based on optimal integration of self-attention and convolutions. For device-dedicated evaluation, rather than relying on inaccurate proxies like the number of FLOPs or parameters, we adopt a practical approach of focusing directly on on-device latency and, for the first time, energy efficiency. Specifically, we show that our models are Pareto-optimal when both accuracy-latency and accuracy-energy trade-offs are considered, achieving strict dominance over other ViTs in almost all cases and competing with the most efficient CNNs.",
        "published":1651861039000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.03436v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 06, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0841957437,
        "popularmechanics":0.1724540558,
        "scienmag":0.138017647,
        "technologyreview":0.2460270856,
        "vox":0.1530030335,
        "newscientist":0.1473112437,
        "vice":0.1032174797,
        "statnews":0.1582856262,
        "nytimes":0.1436092273,
        "techcrunch":0.2100207668,
        "quartz":0.1342750229,
        "venturebeat":0.2622621322,
        "futurism":0.1918997839,
        "scientificamerican":0.1246003486,
        "wired":0.2271243591,
        "popsci":0.2342034076,
        "arstechnica":0.1400865073,
        "salon":0.0914112227,
        "washingtonpost":0.1825485799,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.05496v1",
        "predicted_newsworthiness":46.1711620133,
        "title":"An Evaluation of OCR on Egocentric Data",
        "summary":"In this paper, we evaluate state-of-the-art OCR methods on Egocentric data. We annotate text in EPIC-KITCHENS images, and demonstrate that existing OCR methods struggle with rotated text, which is frequently observed on objects being handled. We introduce a simple rotate-and-merge procedure which can be applied to pre-trained OCR models that halves the normalized edit distance error. This suggests that future OCR attempts should incorporate rotation into model design and training procedures.",
        "published":1654943840000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.05496v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jun 11, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0958809298,
        "popularmechanics":0.146197968,
        "scienmag":0.1171772617,
        "technologyreview":0.2058472067,
        "vox":0.1102274359,
        "newscientist":0.1498160392,
        "vice":0.1108030364,
        "statnews":0.1374143432,
        "nytimes":0.141923888,
        "techcrunch":0.16696824,
        "quartz":0.1203446141,
        "venturebeat":0.2074271101,
        "futurism":0.1650781365,
        "scientificamerican":0.1235203198,
        "wired":0.1888469896,
        "popsci":0.1942782546,
        "arstechnica":0.0998136184,
        "salon":0.0855226666,
        "washingtonpost":0.1494692287,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.06322v1",
        "predicted_newsworthiness":37.573700313,
        "title":"Tackling Multiple Tasks with One Single Learning Framework",
        "summary":"Deep Multi-Task Learning (DMTL) has been widely studied in the machine learning community and applied to a broad range of real-world applications. Searching for the optimal knowledge sharing in DMTL is more challenging for sequential learning problems, as the task relationship will change in the temporal dimension. In this paper, we propose a flexible and efficient framework called HierarchicalTemporal Activation Network (HTAN) to simultaneously explore the optimal sharing of the neural network hierarchy (hierarchical axis) and the time-variant task relationship (temporal axis). HTAN learns a set of time-variant activation functions to encode the task relation. A functional regularization implemented by a modulated SPDNet and adversarial learning is further proposed to enhance the DMTL performance. Comprehensive experiments on several challenging applications demonstrate that our HTAN-SPD framework outperforms SOTA methods significantly in sequential DMTL.",
        "published":1653848699000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.06322v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"May 29, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0943620498,
        "popularmechanics":0.139721363,
        "scienmag":0.1466829157,
        "technologyreview":0.2598050954,
        "vox":0.1215794805,
        "newscientist":0.1442160348,
        "vice":0.1088202375,
        "statnews":0.2035827715,
        "nytimes":0.1374962432,
        "techcrunch":0.1626866397,
        "quartz":0.1167088865,
        "venturebeat":0.2404778627,
        "futurism":0.1832089397,
        "scientificamerican":0.119087617,
        "wired":0.1699813998,
        "popsci":0.1814966924,
        "arstechnica":0.1237114819,
        "salon":0.0972551929,
        "washingtonpost":0.1346716648,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.13765v1",
        "predicted_newsworthiness":42.9834359136,
        "title":"Probabilistic Permutation Graph Search: Black-Box Optimization for Fairness in Ranking",
        "summary":"There are several measures for fairness in ranking, based on different underlying assumptions and perspectives. PL optimization with the REINFORCE algorithm can be used for optimizing black-box objective functions over permutations. In particular, it can be used for optimizing fairness measures. However, though effective for queries with a moderate number of repeating sessions, PL optimization has room for improvement for queries with a small number of repeating sessions. In this paper, we present a novel way of representing permutation distributions, based on the notion of permutation graphs. Similar to PL, our distribution representation, called PPG, can be used for black-box optimization of fairness. Different from PL, where pointwise logits are used as the distribution parameters, in PPG pairwise inversion probabilities together with a reference permutation construct the distribution. As such, the reference permutation can be set to the best sampled permutation regarding the objective function, making PPG suitable for both deterministic and stochastic rankings. Our experiments show that PPG, while comparable to PL for larger session repetitions (i.e., stochastic ranking), improves over PL for optimizing fairness metrics for queries with one session (i.e., deterministic ranking). Additionally, when accurate utility estimations are available, e.g., in tabular models, the performance of PPG in fairness optimization is significantly boosted compared to lower quality utility estimations from a learning to rank model, leading to a large performance gap with PL. Finally, the pairwise probabilities make it possible to impose pairwise constraints such as \"item $d_1$ should always be ranked higher than item $d_2$.\" Such constraints can be used to simultaneously optimize the fairness metric and control another objective such as ranking performance.",
        "published":1651178314000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.13765v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Apr 28, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1032142843,
        "popularmechanics":0.0932156115,
        "scienmag":0.1227808375,
        "technologyreview":0.190629117,
        "vox":0.1594978259,
        "newscientist":0.1124972678,
        "vice":0.0719835201,
        "statnews":0.1533633422,
        "nytimes":0.1417656823,
        "techcrunch":0.1697528399,
        "quartz":0.1366336952,
        "venturebeat":0.1986528088,
        "futurism":0.126481181,
        "scientificamerican":0.1030735886,
        "wired":0.1544397191,
        "popsci":0.1429882729,
        "arstechnica":0.1346338648,
        "salon":0.0838757342,
        "washingtonpost":0.1533910468,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.04835v1",
        "predicted_newsworthiness":41.6879060461,
        "title":"Communication Efficient Distributed Learning for Kernelized Contextual Bandits",
        "summary":"We tackle the communication efficiency challenge of learning kernelized contextual bandits in a distributed setting. Despite the recent advances in communication-efficient distributed bandit learning, existing solutions are restricted to simple models like multi-armed bandits and linear bandits, which hamper their practical utility. In this paper, instead of assuming the existence of a linear reward mapping from the features to the expected rewards, we consider non-linear reward mappings, by letting agents collaboratively search in a reproducing kernel Hilbert space (RKHS). This introduces significant challenges in communication efficiency as distributed kernel learning requires the transfer of raw data, leading to a communication cost that grows linearly w.r.t. time horizon $T$. We addresses this issue by equipping all agents to communicate via a common Nystr\\\"{o}m embedding that gets updated adaptively as more data points are collected. We rigorously proved that our algorithm can attain sub-linear rate in both regret and communication cost.",
        "published":1654825155000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.04835v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jun 09, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1001541937,
        "popularmechanics":0.127957561,
        "scienmag":0.1302653392,
        "technologyreview":0.2167465644,
        "vox":0.1482474673,
        "newscientist":0.1380205175,
        "vice":0.1025193718,
        "statnews":0.1631541766,
        "nytimes":0.147714635,
        "techcrunch":0.1889757876,
        "quartz":0.1296411246,
        "venturebeat":0.215660162,
        "futurism":0.1574878658,
        "scientificamerican":0.143116972,
        "wired":0.1782096743,
        "popsci":0.1636921041,
        "arstechnica":0.1321210826,
        "salon":0.0932850255,
        "washingtonpost":0.1435600278,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.00531v2",
        "predicted_newsworthiness":41.7859121811,
        "title":"PRIMA: Planner-Reasoner Inside a Multi-task Reasoning Agent",
        "summary":"We consider the problem of multi-task reasoning (MTR), where an agent can solve multiple tasks via (first-order) logic reasoning. This capability is essential for human-like intelligence due to its strong generalizability and simplicity for handling multiple tasks. However, a major challenge in developing effective MTR is the intrinsic conflict between reasoning capability and efficiency. An MTR-capable agent must master a large set of \"skills\" to tackle diverse tasks, but executing a particular task at the inference stage requires only a small subset of immediately relevant skills. How can we maintain broad reasoning capability and also efficient specific-task performance? To address this problem, we propose a Planner-Reasoner framework capable of state-of-the-art MTR capability and high efficiency. The Reasoner models shareable (first-order) logic deduction rules, from which the Planner selects a subset to compose into efficient reasoning paths. The entire model is trained in an end-to-end manner using deep reinforcement learning, and experimental studies over a variety of domains validate its effectiveness.",
        "published":1643732539000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.00531v2",
        "arxiv_primary_category":"cs.ai",
        "published_hr":"Feb 01, 2022",
        "arxiv_primary_category_hr":"Artificial Intelligence",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0956932571,
        "popularmechanics":0.1274616601,
        "scienmag":0.108166375,
        "technologyreview":0.2816822485,
        "vox":0.1384456416,
        "newscientist":0.1369194417,
        "vice":0.1101040741,
        "statnews":0.2196255245,
        "nytimes":0.1428866675,
        "techcrunch":0.1781642974,
        "quartz":0.1261283299,
        "venturebeat":0.2677019686,
        "futurism":0.186353465,
        "scientificamerican":0.1002524166,
        "wired":0.1751792164,
        "popsci":0.1789402937,
        "arstechnica":0.1305705665,
        "salon":0.0956900597,
        "washingtonpost":0.1361734593,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.11770v1",
        "predicted_newsworthiness":41.4469066094,
        "title":"Learning Dynamic Facial Radiance Fields for Few-Shot Talking Head Synthesis",
        "summary":"Talking head synthesis is an emerging technology with wide applications in film dubbing, virtual avatars and online education. Recent NeRF-based methods generate more natural talking videos, as they better capture the 3D structural information of faces. However, a specific model needs to be trained for each identity with a large dataset. In this paper, we propose Dynamic Facial Radiance Fields (DFRF) for few-shot talking head synthesis, which can rapidly generalize to an unseen identity with few training data. Different from the existing NeRF-based methods which directly encode the 3D geometry and appearance of a specific person into the network, our DFRF conditions face radiance field on 2D appearance images to learn the face prior. Thus the facial radiance field can be flexibly adjusted to the new identity with few reference images. Additionally, for better modeling of the facial deformations, we propose a differentiable face warping module conditioned on audio signals to deform all reference images to the query space. Extensive experiments show that with only tens of seconds of training clip available, our proposed DFRF can synthesize natural and high-quality audio-driven talking head videos for novel identities with only 40k iterations. We highly recommend readers view our supplementary video for intuitive comparisons. Code is available in https:\/\/sstzal.github.io\/DFRF\/.",
        "published":1658681163000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.11770v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 24, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1059962437,
        "popularmechanics":0.1477101929,
        "scienmag":0.1126636743,
        "technologyreview":0.2327722864,
        "vox":0.1323731827,
        "newscientist":0.1507476222,
        "vice":0.0994846303,
        "statnews":0.1049996786,
        "nytimes":0.1432074308,
        "techcrunch":0.1670563984,
        "quartz":0.1348204717,
        "venturebeat":0.2326908226,
        "futurism":0.1883710208,
        "scientificamerican":0.1287038128,
        "wired":0.20661125,
        "popsci":0.1889416441,
        "arstechnica":0.1107823139,
        "salon":0.0974392381,
        "washingtonpost":0.1701752299,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.05084v2",
        "predicted_newsworthiness":43.759001459,
        "title":"XMP-Font: Self-Supervised Cross-Modality Pre-training for Few-Shot Font Generation",
        "summary":"Generating a new font library is a very labor-intensive and time-consuming job for glyph-rich scripts. Few-shot font generation is thus required, as it requires only a few glyph references without fine-tuning during test. Existing methods follow the style-content disentanglement paradigm and expect novel fonts to be produced by combining the style codes of the reference glyphs and the content representations of the source. However, these few-shot font generation methods either fail to capture content-independent style representations, or employ localized component-wise style representations, which is insufficient to model many Chinese font styles that involve hyper-component features such as inter-component spacing and \"connected-stroke\". To resolve these drawbacks and make the style representations more reliable, we propose a self-supervised cross-modality pre-training strategy and a cross-modality transformer-based encoder that is conditioned jointly on the glyph image and the corresponding stroke labels. The cross-modality encoder is pre-trained in a self-supervised manner to allow effective capture of cross- and intra-modality correlations, which facilitates the content-style disentanglement and modeling style representations of all scales (stroke-level, component-level and character-level). The pre-trained encoder is then applied to the downstream font generation task without fine-tuning. Experimental comparisons of our method with state-of-the-art methods demonstrate our method successfully transfers styles of all scales. In addition, it only requires one reference glyph and achieves the lowest rate of bad cases in the few-shot font generation task 28% lower than the second best",
        "published":1649684080000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.05084v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Apr 11, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0930714217,
        "popularmechanics":0.1290703299,
        "scienmag":0.1101289101,
        "technologyreview":0.1793696197,
        "vox":0.1000211614,
        "newscientist":0.116180775,
        "vice":0.0844355133,
        "statnews":0.1022744337,
        "nytimes":0.1257651488,
        "techcrunch":0.1365144554,
        "quartz":0.133687756,
        "venturebeat":0.1785394594,
        "futurism":0.1310444449,
        "scientificamerican":0.11308897,
        "wired":0.1570691092,
        "popsci":0.1542337305,
        "arstechnica":0.1064770376,
        "salon":0.0856672192,
        "washingtonpost":0.1298771061,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.13451v2",
        "predicted_newsworthiness":47.7571838548,
        "title":"Cumulative Stay-time Representation for Electronic Health Records in Medical Event Time Prediction",
        "summary":"We address the problem of predicting when a disease will develop, i.e., medical event time (MET), from a patient's electronic health record (EHR). The MET of non-communicable diseases like diabetes is highly correlated to cumulative health conditions, more specifically, how much time the patient spent with specific health conditions in the past. The common time-series representation is indirect in extracting such information from EHR because it focuses on detailed dependencies between values in successive observations, not cumulative information. We propose a novel data representation for EHR called cumulative stay-time representation (CTR), which directly models such cumulative health conditions. We derive a trainable construction of CTR based on neural networks that has the flexibility to fit the target data and scalability to handle high-dimensional EHR. Numerical experiments using synthetic and real-world datasets demonstrate that CTR alone achieves a high prediction performance, and it enhances the performance of existing models when combined with them.",
        "published":1651149281000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.13451v2",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Apr 28, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1777815848,
        "popularmechanics":0.1346890373,
        "scienmag":0.25566533,
        "technologyreview":0.2555736676,
        "vox":0.1922469899,
        "newscientist":0.1968240415,
        "vice":0.1247946454,
        "statnews":0.3928901092,
        "nytimes":0.1975880911,
        "techcrunch":0.190907019,
        "quartz":0.1620677982,
        "venturebeat":0.2512664871,
        "futurism":0.1999405858,
        "scientificamerican":0.1967706254,
        "wired":0.1821164178,
        "popsci":0.2006020317,
        "arstechnica":0.1664159965,
        "salon":0.2233758424,
        "washingtonpost":0.1787864022,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.09381v2",
        "predicted_newsworthiness":39.9915846482,
        "title":"vCLIMB: A Novel Video Class Incremental Learning Benchmark",
        "summary":"Continual learning (CL) is under-explored in the video domain. The few existing works contain splits with imbalanced class distributions over the tasks, or study the problem in unsuitable datasets. We introduce vCLIMB, a novel video continual learning benchmark. vCLIMB is a standardized test-bed to analyze catastrophic forgetting of deep models in video continual learning. In contrast to previous work, we focus on class incremental continual learning with models trained on a sequence of disjoint tasks, and distribute the number of classes uniformly across the tasks. We perform in-depth evaluations of existing CL methods in vCLIMB, and observe two unique challenges in video data. The selection of instances to store in episodic memory is performed at the frame level. Second, untrimmed training data influences the effectiveness of frame sampling strategies. We address these two challenges by proposing a temporal consistency regularization that can be applied on top of memory-based continual learning methods. Our approach significantly improves the baseline, by up to 24% on the untrimmed continual learning task.",
        "published":1642976057000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.09381v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jan 23, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0855375722,
        "popularmechanics":0.1145000248,
        "scienmag":0.1045639722,
        "technologyreview":0.180289891,
        "vox":0.0926657641,
        "newscientist":0.1139207834,
        "vice":0.0903572865,
        "statnews":0.1141061977,
        "nytimes":0.1108214739,
        "techcrunch":0.1196021923,
        "quartz":0.0988042318,
        "venturebeat":0.167010001,
        "futurism":0.1327926452,
        "scientificamerican":0.0976075017,
        "wired":0.135956799,
        "popsci":0.1372449156,
        "arstechnica":0.0932013235,
        "salon":0.0801815225,
        "washingtonpost":0.105329019,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.02320v4",
        "predicted_newsworthiness":47.840508282,
        "title":"Learning Generalizable Dexterous Manipulation from Human Grasp Affordance",
        "summary":"Dexterous manipulation with a multi-finger hand is one of the most challenging problems in robotics. While recent progress in imitation learning has largely improved the sample efficiency compared to Reinforcement Learning, the learned policy can hardly generalize to manipulate novel objects, given limited expert demonstrations. In this paper, we propose to learn dexterous manipulation using large-scale demonstrations with diverse 3D objects in a category, which are generated from a human grasp affordance model. This generalizes the policy to novel object instances within the same category. To train the policy, we propose a novel imitation learning objective jointly with a geometric representation learning objective using our demonstrations. By experimenting with relocating diverse objects in simulation, we show that our approach outperforms baselines with a large margin when manipulating novel objects. We also ablate the importance on 3D object representation learning for manipulation. We include videos, code, and additional information on the project website - https:\/\/kristery.github.io\/ILAD\/ .",
        "published":1649175982000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.02320v4",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Apr 05, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0793784898,
        "popularmechanics":0.1636497243,
        "scienmag":0.1192382905,
        "technologyreview":0.2224377857,
        "vox":0.092059648,
        "newscientist":0.1429299303,
        "vice":0.1199932326,
        "statnews":0.0962430716,
        "nytimes":0.1299674888,
        "techcrunch":0.1444902501,
        "quartz":0.0998451214,
        "venturebeat":0.1827711964,
        "futurism":0.1788976969,
        "scientificamerican":0.1087358166,
        "wired":0.1632984803,
        "popsci":0.1868479582,
        "arstechnica":0.0969513542,
        "salon":0.0763932627,
        "washingtonpost":0.1231760745,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.13844v1",
        "predicted_newsworthiness":50.9317531702,
        "title":"User-controllable Recommendation Against Filter Bubbles",
        "summary":"Recommender systems usually face the issue of filter bubbles: overrecommending homogeneous items based on user features and historical interactions. Filter bubbles will grow along the feedback loop and inadvertently narrow user interests. Existing work usually mitigates filter bubbles by incorporating objectives apart from accuracy such as diversity and fairness. However, they typically sacrifice accuracy, hurting model fidelity and user experience. Worse still, users have to passively accept the recommendation strategy and influence the system in an inefficient manner with high latency, e.g., keeping providing feedback (e.g., like and dislike) until the system recognizes the user intention. This work proposes a new recommender prototype called UserControllable Recommender System (UCRS), which enables users to actively control the mitigation of filter bubbles. Functionally, 1) UCRS can alert users if they are deeply stuck in filter bubbles. 2) UCRS supports four kinds of control commands for users to mitigate the bubbles at different granularities. 3) UCRS can respond to the controls and adjust the recommendations on the fly. The key to adjusting lies in blocking the effect of out-of-date user representations on recommendations, which contains historical information inconsistent with the control commands. As such, we develop a causality-enhanced User-Controllable Inference (UCI) framework, which can quickly revise the recommendations based on user controls in the inference stage and utilize counterfactual inference to mitigate the effect of out-of-date user representations. Experiments on three datasets validate that the UCI framework can effectively recommend more desired items based on user controls, showing promising performance w.r.t. both accuracy and diversity.",
        "published":1651196816000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.13844v1",
        "arxiv_primary_category":"cs.ir",
        "published_hr":"Apr 28, 2022",
        "arxiv_primary_category_hr":"Information Retrieval",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1673930278,
        "popularmechanics":0.1555299341,
        "scienmag":0.1797009602,
        "technologyreview":0.2821029378,
        "vox":0.2543210305,
        "newscientist":0.1843822285,
        "vice":0.1302524629,
        "statnews":0.2614004493,
        "nytimes":0.2250865285,
        "techcrunch":0.2550935952,
        "quartz":0.2076186341,
        "venturebeat":0.2886469814,
        "futurism":0.2150644866,
        "scientificamerican":0.1832900669,
        "wired":0.2654100137,
        "popsci":0.2498809505,
        "arstechnica":0.1998263704,
        "salon":0.172570988,
        "washingtonpost":0.2551309726,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.07603v1",
        "predicted_newsworthiness":61.6791878265,
        "title":"Fairness Indicators for Systematic Assessments of Visual Feature Extractors",
        "summary":"Does everyone equally benefit from computer vision systems? Answers to this question become more and more important as computer vision systems are deployed at large scale, and can spark major concerns when they exhibit vast performance discrepancies between people from various demographic and social backgrounds. Systematic diagnosis of fairness, harms, and biases of computer vision systems is an important step towards building socially responsible systems. To initiate an effort towards standardized fairness audits, we propose three fairness indicators, which aim at quantifying harms and biases of visual systems. Our indicators use existing publicly available datasets collected for fairness evaluations, and focus on three main types of harms and bias identified in the literature, namely harmful label associations, disparity in learned representations of social and demographic traits, and biased performance on geographically diverse images from across the world.We define precise experimental protocols applicable to a wide range of computer vision models. These indicators are part of an ever-evolving suite of fairness probes and are not intended to be a substitute for a thorough analysis of the broader impact of the new computer vision technologies. Yet, we believe it is a necessary first step towards (1) facilitating the widespread adoption and mandate of the fairness assessments in computer vision research, and (2) tracking progress towards building socially responsible models. To study the practical effectiveness and broad applicability of our proposed indicators to any visual system, we apply them to off-the-shelf models built using widely adopted model training paradigms which vary in their ability to whether they can predict labels on a given image or only produce the embeddings. We also systematically study the effect of data domain and model size.",
        "published":1644947133000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.07603v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Feb 15, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2390098004,
        "popularmechanics":0.1763291157,
        "scienmag":0.2338106153,
        "technologyreview":0.3711506352,
        "vox":0.2611003707,
        "newscientist":0.2432540183,
        "vice":0.186210883,
        "statnews":0.2836634466,
        "nytimes":0.258740088,
        "techcrunch":0.2502220351,
        "quartz":0.2454527764,
        "venturebeat":0.301108567,
        "futurism":0.2784154373,
        "scientificamerican":0.2455380597,
        "wired":0.2680452623,
        "popsci":0.2633499343,
        "arstechnica":0.2226852188,
        "salon":0.2164559423,
        "washingtonpost":0.2790824601,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.03216v2",
        "predicted_newsworthiness":49.5019149482,
        "title":"USTC-NELSLIP at SemEval-2022 Task 11: Gazetteer-Adapted Integration Network for Multilingual Complex Named Entity Recognition",
        "summary":"This paper describes the system developed by the USTC-NELSLIP team for SemEval-2022 Task 11 Multilingual Complex Named Entity Recognition (MultiCoNER). We propose a gazetteer-adapted integration network (GAIN) to improve the performance of language models for recognizing complex named entities. The method first adapts the representations of gazetteer networks to those of language models by minimizing the KL divergence between them. After adaptation, these two networks are then integrated for backend supervised named entity recognition (NER) training. The proposed method is applied to several state-of-the-art Transformer-based NER models with a gazetteer built from Wikidata, and shows great generalization ability across them. The final predictions are derived from an ensemble of these trained models. Experimental results and detailed analysis verify the effectiveness of the proposed method. The official results show that our system ranked 1st on three tracks (Chinese, Code-mixed and Bangla) and 2nd on the other ten tracks in this task.",
        "published":1646643937000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.03216v2",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Mar 07, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1136793299,
        "popularmechanics":0.1155558643,
        "scienmag":0.1230271022,
        "technologyreview":0.2073654062,
        "vox":0.1501867169,
        "newscientist":0.1160662177,
        "vice":0.0983215562,
        "statnews":0.1588665596,
        "nytimes":0.1395972015,
        "techcrunch":0.1739334188,
        "quartz":0.141587486,
        "venturebeat":0.2149971975,
        "futurism":0.1441391819,
        "scientificamerican":0.1034787418,
        "wired":0.160953781,
        "popsci":0.1576731037,
        "arstechnica":0.1335293268,
        "salon":0.0911021639,
        "washingtonpost":0.1500547134,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.08126v2",
        "predicted_newsworthiness":48.5532328329,
        "title":"Channel Importance Matters in Few-Shot Image Classification",
        "summary":"Few-Shot Learning (FSL) requires vision models to quickly adapt to brand-new classification tasks with a shift in task distribution. Understanding the difficulties posed by this task distribution shift is central to FSL. In this paper, we show that a simple channel-wise feature transformation may be the key to unraveling this secret from a channel perspective. When facing novel few-shot tasks in the test-time datasets, this transformation can greatly improve the generalization ability of learned image representations, while being agnostic to the choice of training algorithms and datasets. Through an in-depth analysis of this transformation, we find that the difficulty of representation transfer in FSL stems from the severe channel bias problem of image representations: channels may have different importance in different tasks, while convolutional neural networks are likely to be insensitive, or respond incorrectly to such a shift. This points out a core problem of the generalization ability of modern vision systems and needs further attention in the future. Our code is available at https:\/\/github.com\/Frankluox\/Channel_Importance_FSL.",
        "published":1655383125000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.08126v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jun 16, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1096457158,
        "popularmechanics":0.1482257534,
        "scienmag":0.1413559319,
        "technologyreview":0.2643458581,
        "vox":0.1440483968,
        "newscientist":0.1558649875,
        "vice":0.1129531889,
        "statnews":0.1719782034,
        "nytimes":0.150461619,
        "techcrunch":0.1695469383,
        "quartz":0.1342319963,
        "venturebeat":0.2327881255,
        "futurism":0.1815026548,
        "scientificamerican":0.1339264751,
        "wired":0.1936917797,
        "popsci":0.1983426817,
        "arstechnica":0.1282303268,
        "salon":0.0993041317,
        "washingtonpost":0.1592053556,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.09107v1",
        "predicted_newsworthiness":52.3985694517,
        "title":"MONet: Multi-scale Overlap Network for Duplication Detection in Biomedical Images",
        "summary":"Manipulation of biomedical images to misrepresent experimental results has plagued the biomedical community for a while. Recent interest in the problem led to the curation of a dataset and associated tasks to promote the development of biomedical forensic methods. Of these, the largest manipulation detection task focuses on the detection of duplicated regions between images. Traditional computer-vision based forensic models trained on natural images are not designed to overcome the challenges presented by biomedical images. We propose a multi-scale overlap detection model to detect duplicated image regions. Our model is structured to find duplication hierarchically, so as to reduce the number of patch operations. It achieves state-of-the-art performance overall and on multiple biomedical image categories.",
        "published":1658215543000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.09107v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 19, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1231898676,
        "popularmechanics":0.1500563543,
        "scienmag":0.2026250786,
        "technologyreview":0.2329942669,
        "vox":0.1283514115,
        "newscientist":0.1774962975,
        "vice":0.1752330797,
        "statnews":0.2244198944,
        "nytimes":0.1721072742,
        "techcrunch":0.129449519,
        "quartz":0.1199737481,
        "venturebeat":0.1734900169,
        "futurism":0.1892630564,
        "scientificamerican":0.1599776328,
        "wired":0.1597710435,
        "popsci":0.1645420474,
        "arstechnica":0.165890046,
        "salon":0.143927404,
        "washingtonpost":0.1660675991,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.00329v1",
        "predicted_newsworthiness":67.5109684666,
        "title":"A Systematic Literature Review on Persuasive Technology at the Workplace",
        "summary":"Employees face decisions every day - in the absence of supervision. The outcome of these decisions can be influenced by digital workplace design through the power of persuasive technology. This paper provides a structured literature review based on recent research on persuasive technology in the workplace. It examines the design and use of persuasive systems from a variety of disciplinary perspectives and theories. The reviewed studies were categorized into the research streams of technology design, user-centered research, and gamification. The purpose of the studies is categorized using a modified definition of the persuasive systems design model. A number of experimental studies show that alignment of the employee's behavior with the employer's agenda can be achieved. A robust finding is the key role of interactivity in granting employees a subjective experience of rapid and meaningful feedback when using the interface.",
        "published":1641118058000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.00329v1",
        "arxiv_primary_category":"cs.hc",
        "published_hr":"Jan 02, 2022",
        "arxiv_primary_category_hr":"Human-Computer Interaction",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2213804018,
        "popularmechanics":0.1840556478,
        "scienmag":0.2102528131,
        "technologyreview":0.294628498,
        "vox":0.2491435047,
        "newscientist":0.204868021,
        "vice":0.1260529056,
        "statnews":0.2845771867,
        "nytimes":0.2572518477,
        "techcrunch":0.2754072461,
        "quartz":0.2484489583,
        "venturebeat":0.2990671731,
        "futurism":0.2358841812,
        "scientificamerican":0.2113726295,
        "wired":0.274025893,
        "popsci":0.2583268094,
        "arstechnica":0.1985729866,
        "salon":0.2044026245,
        "washingtonpost":0.2684651,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.02958v1",
        "predicted_newsworthiness":38.8306499281,
        "title":"LEAD: Self-Supervised Landmark Estimation by Aligning Distributions of Feature Similarity",
        "summary":"In this work, we introduce LEAD, an approach to discover landmarks from an unannotated collection of category-specific images. Existing works in self-supervised landmark detection are based on learning dense (pixel-level) feature representations from an image, which are further used to learn landmarks in a semi-supervised manner. While there have been advances in self-supervised learning of image features for instance-level tasks like classification, these methods do not ensure dense equivariant representations. The property of equivariance is of interest for dense prediction tasks like landmark estimation. In this work, we introduce an approach to enhance the learning of dense equivariant representations in a self-supervised fashion. We follow a two-stage training approach: first, we train a network using the BYOL objective which operates at an instance level. The correspondences obtained through this network are further used to train a dense and compact representation of the image using a lightweight network. We show that having such a prior in the feature extractor helps in landmark detection, even under drastically limited number of annotations while also improving generalization across scale variations.",
        "published":1649267298000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.02958v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Apr 06, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0903995524,
        "popularmechanics":0.1308348467,
        "scienmag":0.1023760873,
        "technologyreview":0.203332232,
        "vox":0.0997930559,
        "newscientist":0.128843219,
        "vice":0.1140339668,
        "statnews":0.1194777288,
        "nytimes":0.1245921408,
        "techcrunch":0.135238537,
        "quartz":0.107808424,
        "venturebeat":0.18077699,
        "futurism":0.1467622246,
        "scientificamerican":0.1052004009,
        "wired":0.1599587098,
        "popsci":0.1618771026,
        "arstechnica":0.083747275,
        "salon":0.082761238,
        "washingtonpost":0.1232022335,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.09055v1",
        "predicted_newsworthiness":40.8551745975,
        "title":"Box-supervised Instance Segmentation with Level Set Evolution",
        "summary":"In contrast to the fully supervised methods using pixel-wise mask labels, box-supervised instance segmentation takes advantage of the simple box annotations, which has recently attracted a lot of research attentions. In this paper, we propose a novel single-shot box-supervised instance segmentation approach, which integrates the classical level set model with deep neural network delicately. Specifically, our proposed method iteratively learns a series of level sets through a continuous Chan-Vese energy-based function in an end-to-end fashion. A simple mask supervised SOLOv2 model is adapted to predict the instance-aware mask map as the level set for each instance. Both the input image and its deep features are employed as the input data to evolve the level set curves, where a box projection function is employed to obtain the initial boundary. By minimizing the fully differentiable energy function, the level set for each instance is iteratively optimized within its corresponding bounding box annotation. The experimental results on four challenging benchmarks demonstrate the leading performance of our proposed approach to robust instance segmentation in various scenarios. The code is available at: https:\/\/github.com\/LiWentomng\/boxlevelset.",
        "published":1658203184000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.09055v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 18, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0797952442,
        "popularmechanics":0.136936253,
        "scienmag":0.1289531676,
        "technologyreview":0.1997839685,
        "vox":0.0924268182,
        "newscientist":0.1396352328,
        "vice":0.1341696532,
        "statnews":0.112157482,
        "nytimes":0.1133752365,
        "techcrunch":0.1328138185,
        "quartz":0.0984536949,
        "venturebeat":0.1714228993,
        "futurism":0.151417782,
        "scientificamerican":0.1168268186,
        "wired":0.145180782,
        "popsci":0.1536605198,
        "arstechnica":0.0997258592,
        "salon":0.0968035752,
        "washingtonpost":0.1211811306,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.01600v1",
        "predicted_newsworthiness":42.7904441437,
        "title":"CRFormer: A Cross-Region Transformer for Shadow Removal",
        "summary":"Aiming to restore the original intensity of shadow regions in an image and make them compatible with the remaining non-shadow regions without a trace, shadow removal is a very challenging problem that benefits many downstream image\/video-related tasks. Recently, transformers have shown their strong capability in various applications by capturing global pixel interactions and this capability is highly desirable in shadow removal. However, applying transformers to promote shadow removal is non-trivial for the following two reasons: 1) The patchify operation is not suitable for shadow removal due to irregular shadow shapes; 2) shadow removal only needs one-way interaction from the non-shadow region to the shadow region instead of the common two-way interactions among all pixels in the image. In this paper, we propose a novel cross-region transformer, namely CRFormer, for shadow removal which differs from existing transformers by only considering the pixel interactions from the non-shadow region to the shadow region without splitting images into patches. This is achieved by a carefully designed region-aware cross-attention operation that can aggregate the recovered shadow region features conditioned on the non-shadow region features. Extensive experiments on ISTD, AISTD, SRD, and Video Shadow Removal datasets demonstrate the superiority of our method compared to other state-of-the-art methods.",
        "published":1656955982000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.01600v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 04, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0917957027,
        "popularmechanics":0.1126187489,
        "scienmag":0.1007796845,
        "technologyreview":0.1552294226,
        "vox":0.1013328421,
        "newscientist":0.1181119959,
        "vice":0.1074253918,
        "statnews":0.0715893279,
        "nytimes":0.1035432852,
        "techcrunch":0.1074828995,
        "quartz":0.0998133798,
        "venturebeat":0.1439890813,
        "futurism":0.1217033525,
        "scientificamerican":0.1021928786,
        "wired":0.1214869014,
        "popsci":0.1283787653,
        "arstechnica":0.0917163074,
        "salon":0.0955994359,
        "washingtonpost":0.1250226952,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.14034v1",
        "predicted_newsworthiness":43.6595362089,
        "title":"Attribute Descent: Simulating Object-Centric Datasets on the Content Level and Beyond",
        "summary":"This article aims to use graphic engines to simulate a large number of training data that have free annotations and possibly strongly resemble to real-world data. Between synthetic and real, a two-level domain gap exists, involving content level and appearance level. While the latter is concerned with appearance style, the former problem arises from a different mechanism, i.e., content mismatch in attributes such as camera viewpoint, object placement and lighting conditions. In contrast to the widely-studied appearance-level gap, the content-level discrepancy has not been broadly studied. To address the content-level misalignment, we propose an attribute descent approach that automatically optimizes engine attributes to enable synthetic data to approximate real-world data. We verify our method on object-centric tasks, wherein an object takes up a major portion of an image. In these tasks, the search space is relatively small, and the optimization of each attribute yields sufficiently obvious supervision signals. We collect a new synthetic asset VehicleX, and reformat and reuse existing the synthetic assets ObjectX and PersonX. Extensive experiments on image classification and object re-identification confirm that adapted synthetic data can be effectively used in three scenarios: training with synthetic data only, training data augmentation and numerically understanding dataset content.",
        "published":1646074685000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.14034v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Feb 28, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1034735399,
        "popularmechanics":0.1783694457,
        "scienmag":0.1266432655,
        "technologyreview":0.2753814134,
        "vox":0.1272374349,
        "newscientist":0.1598360295,
        "vice":0.1175169085,
        "statnews":0.1466658145,
        "nytimes":0.1552731398,
        "techcrunch":0.1736442841,
        "quartz":0.13381947,
        "venturebeat":0.2495851938,
        "futurism":0.2030691973,
        "scientificamerican":0.1173307115,
        "wired":0.209318967,
        "popsci":0.2159754066,
        "arstechnica":0.1209847872,
        "salon":0.0871168721,
        "washingtonpost":0.1591216197,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.04226v1",
        "predicted_newsworthiness":67.9892347823,
        "title":"Understanding how people consume low quality and extreme news using web traffic data",
        "summary":"To mitigate the spread of fake news, researchers need to understand who visit fake new sites, what brings people to those sites, where visitors come from, and what content they prefer to consume. In this paper, we analyze web traffic data from The Gateway Pundit (TGP), a popular far-right website that is known for repeatedly sharing false information that has made its web traffic available to the general public. We collect data on 68 million web traffic visits to the site over a month period and analyze how people consume news via multiple features. Our traffic analysis shows that search engines and social media platforms are main drivers of traffic; our geo-location analysis reveals that TGP is more popular in counties that voted for Trump in 2020; and our topic analysis shows that conspiratorial articles receive more visits than factual articles. Due to the inability to observe direct website traffic, existing research uses alternative data source such as engagement signals from social media posts. To validate if social media engagement signals correlate with actual web visit counts, we collect all Facebook and Twitter posts with URLs from TGP during the same time period. We show that all engagement signals positively correlate with web visit counts, but with varying correlation strengths. Metrics based on Facebook posts correlate better than metrics based on Twitter. Our unique web traffic data set and insights can help researchers to better measure the impact of far-right and fake news URLs on social media platforms.",
        "published":1641941493000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.04226v1",
        "arxiv_primary_category":"cs.si",
        "published_hr":"Jan 11, 2022",
        "arxiv_primary_category_hr":"Social and Information Networks",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2912733754,
        "popularmechanics":0.1846960975,
        "scienmag":0.1939892817,
        "technologyreview":0.3995430557,
        "vox":0.4491071808,
        "newscientist":0.2253421858,
        "vice":0.1688565006,
        "statnews":0.253340899,
        "nytimes":0.3390305647,
        "techcrunch":0.3358529642,
        "quartz":0.3278049859,
        "venturebeat":0.3231924935,
        "futurism":0.2738488685,
        "scientificamerican":0.250721012,
        "wired":0.4246188245,
        "popsci":0.3144410666,
        "arstechnica":0.3585139186,
        "salon":0.2628645584,
        "washingtonpost":0.4912419826,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.06187v2",
        "predicted_newsworthiness":46.431449038,
        "title":"On the Convergence of Clustered Federated Learning",
        "summary":"Knowledge sharing and model personalization are essential components to tackle the non-IID challenge in federated learning (FL). Most existing FL methods focus on two extremes: 1) to learn a shared model to serve all clients with non-IID data, and 2) to learn personalized models for each client, namely personalized FL. There is a trade-off solution, namely clustered FL or cluster-wise personalized FL, which aims to cluster similar clients into one cluster, and then learn a shared model for all clients within a cluster. This paper is to revisit the research of clustered FL by formulating them into a bi-level optimization framework that could unify existing methods. We propose a new theoretical analysis framework to prove the convergence by considering the clusterability among clients. In addition, we embody this framework in an algorithm, named Weighted Clustered Federated Learning (WeCFL). Empirical analysis verifies the theoretical results and demonstrates the effectiveness of the proposed WeCFL under the proposed cluster-wise non-IID settings.",
        "published":1644719959000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.06187v2",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Feb 12, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0801798506,
        "popularmechanics":0.0871160228,
        "scienmag":0.1103422556,
        "technologyreview":0.1924041785,
        "vox":0.1055122396,
        "newscientist":0.1007846677,
        "vice":0.0599040986,
        "statnews":0.1640570471,
        "nytimes":0.1134735389,
        "techcrunch":0.1595259492,
        "quartz":0.0911913025,
        "venturebeat":0.2058525053,
        "futurism":0.1248717647,
        "scientificamerican":0.0930405235,
        "wired":0.1269025228,
        "popsci":0.1266328915,
        "arstechnica":0.0875708286,
        "salon":0.069175292,
        "washingtonpost":0.1149466126,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.09682v1",
        "predicted_newsworthiness":42.1860172098,
        "title":"Quantized Training of Gradient Boosting Decision Trees",
        "summary":"Recent years have witnessed significant success in Gradient Boosting Decision Trees (GBDT) for a wide range of machine learning applications. Generally, a consensus about GBDT's training algorithms is gradients and statistics are computed based on high-precision floating points. In this paper, we investigate an essentially important question which has been largely ignored by the previous literature: how many bits are needed for representing gradients in training GBDT? To solve this mystery, we propose to quantize all the high-precision gradients in a very simple yet effective way in the GBDT's training algorithm. Surprisingly, both our theoretical analysis and empirical studies show that the necessary precisions of gradients without hurting any performance can be quite low, e.g., 2 or 3 bits. With low-precision gradients, most arithmetic operations in GBDT training can be replaced by integer operations of 8, 16, or 32 bits. Promisingly, these findings may pave the way for much more efficient training of GBDT from several aspects: (1) speeding up the computation of gradient statistics in histograms; (2) compressing the communication cost of high-precision statistical information during distributed training; (3) the inspiration of utilization and development of hardware architectures which well support low-precision computation for GBDT training. Benchmarked on CPU, GPU, and distributed clusters, we observe up to 2$\\times$ speedup of our simple quantization strategy compared with SOTA GBDT systems on extensive datasets, demonstrating the effectiveness and potential of the low-precision training of GBDT. The code will be released to the official repository of LightGBM.",
        "published":1658298426000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.09682v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jul 20, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0831282589,
        "popularmechanics":0.1339892999,
        "scienmag":0.1396208968,
        "technologyreview":0.239400426,
        "vox":0.1266797619,
        "newscientist":0.1338892804,
        "vice":0.1090518432,
        "statnews":0.1906190275,
        "nytimes":0.1291975329,
        "techcrunch":0.1765913368,
        "quartz":0.1161184271,
        "venturebeat":0.2470222845,
        "futurism":0.1640220134,
        "scientificamerican":0.1099028832,
        "wired":0.1579146648,
        "popsci":0.1776200714,
        "arstechnica":0.1175604067,
        "salon":0.0848720646,
        "washingtonpost":0.13513746,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.03763v1",
        "predicted_newsworthiness":70.7579455922,
        "title":"Enabling and Assessing Trust when Cooperating with Robots in Disaster Response (EASIER)",
        "summary":"This paper presents a conceptual overview of the EASIER project and its scope. EASIER focuses on supporting emergency forces in disaster response scenarios with a semi-autonomous mobile manipulator. Specifically, we examine the operator's trust in the system and his\/her cognitive load generated by its use. We plan to address different research topics, exploring how shared autonomy, interaction design, and transparency relate to trust and cognitive load. Another goal is to develop non-invasive methods to continuously measure trust and cognitive load in the context of disaster response using a multilevel approach. This project is conducted by multiple academic partners specializing in artificial intelligence, interaction design, and psychology, as well as an industrial partner for disaster response equipment and end-users for framing the project and the experiments in real use-cases.",
        "published":1657271214000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.03763v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Jul 08, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2221774408,
        "popularmechanics":0.2537062143,
        "scienmag":0.2271762372,
        "technologyreview":0.3521726361,
        "vox":0.2428895416,
        "newscientist":0.2417373303,
        "vice":0.2121376612,
        "statnews":0.2755619677,
        "nytimes":0.2596017604,
        "techcrunch":0.2788160008,
        "quartz":0.2227202352,
        "venturebeat":0.3155778905,
        "futurism":0.3056946582,
        "scientificamerican":0.2377219876,
        "wired":0.290497543,
        "popsci":0.3228989702,
        "arstechnica":0.2129580175,
        "salon":0.2143064491,
        "washingtonpost":0.2752434156,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.07232v1",
        "predicted_newsworthiness":44.5139180077,
        "title":"Lipschitz Bound Analysis of Neural Networks",
        "summary":"Lipschitz Bound Estimation is an effective method of regularizing deep neural networks to make them robust against adversarial attacks. This is useful in a variety of applications ranging from reinforcement learning to autonomous systems. In this paper, we highlight the significant gap in obtaining a non-trivial Lipschitz bound certificate for Convolutional Neural Networks (CNNs) and empirically support it with extensive graphical analysis. We also show that unrolling Convolutional layers or Toeplitz matrices can be employed to convert Convolutional Neural Networks (CNNs) to a Fully Connected Network. Further, we propose a simple algorithm to show the existing 20x-50x gap in a particular data distribution between the actual lipschitz constant and the obtained tight bound. We also ran sets of thorough experiments on various network architectures and benchmark them on datasets like MNIST and CIFAR-10. All these proposals are supported by extensive testing, graphs, histograms and comparative analysis.",
        "published":1657842022000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.07232v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jul 14, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1256536525,
        "popularmechanics":0.1785732787,
        "scienmag":0.1646419572,
        "technologyreview":0.3203909312,
        "vox":0.2006698736,
        "newscientist":0.1906706365,
        "vice":0.1404082967,
        "statnews":0.219436313,
        "nytimes":0.1928651713,
        "techcrunch":0.2119506152,
        "quartz":0.1633528942,
        "venturebeat":0.2853553139,
        "futurism":0.2404305944,
        "scientificamerican":0.1391421905,
        "wired":0.2287616142,
        "popsci":0.2171738304,
        "arstechnica":0.1947358579,
        "salon":0.1138258813,
        "washingtonpost":0.218328407,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.13569v2",
        "predicted_newsworthiness":47.463467005,
        "title":"Life is not Always Depressing: Exploring the Happy Moments of People Diagnosed with Depression",
        "summary":"In this work, we explore the relationship between depression and manifestations of happiness in social media. While the majority of works surrounding depression focus on symptoms, psychological research shows that there is a strong link between seeking happiness and being diagnosed with depression. We make use of Positive-Unlabeled learning paradigm to automatically extract happy moments from social media posts of both controls and users diagnosed with depression, and qualitatively analyze them with linguistic tools such as LIWC and keyness information. We show that the life of depressed individuals is not always bleak, with positive events related to friends and family being more noteworthy to their lives compared to the more mundane happy events reported by control users.",
        "published":1651159924000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.13569v2",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Apr 28, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.225189802,
        "popularmechanics":0.1326939774,
        "scienmag":0.2295359543,
        "technologyreview":0.2751052877,
        "vox":0.2650194741,
        "newscientist":0.2224562707,
        "vice":0.1405353203,
        "statnews":0.2754617014,
        "nytimes":0.2437768084,
        "techcrunch":0.2305591883,
        "quartz":0.2340307569,
        "venturebeat":0.2548750653,
        "futurism":0.2102119342,
        "scientificamerican":0.2222936896,
        "wired":0.2887654346,
        "popsci":0.2526713734,
        "arstechnica":0.1900944383,
        "salon":0.2741121617,
        "washingtonpost":0.2599355037,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2208.01482v1",
        "predicted_newsworthiness":42.6742433803,
        "title":"Folding Knots Using a Team of Aerial Robots",
        "summary":"From ancient times, humans have been using cables and ropes to tie, carry, and manipulate objects by folding knots. However, automating knot folding is challenging because it requires dexterity to move a cable over and under itself. In this paper, we propose a method to fold knots in midair using a team of aerial vehicles. We take advantage of the fact that vehicles are able to fly in between cable segments without any re-grasping. So the team grasps the cable from the floor, and releases it once the knot is folded. Based on a composition of catenary curves, we simplify the complexity of dealing with an infinite-dimensional configuration space of the cable, and formally propose a new knot representation. Such representation allows us to design a trajectory that can be used to fold knots using a leader-follower approach. We show that our method works for different types of knots in simulations. Additionally, we show that our solution is also computationally efficient and can be executed in real-time.",
        "published":1659450690000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2208.01482v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Aug 02, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0916883003,
        "popularmechanics":0.2327494529,
        "scienmag":0.1421646847,
        "technologyreview":0.2089339734,
        "vox":0.1002106287,
        "newscientist":0.1747515988,
        "vice":0.1788499302,
        "statnews":0.0807597977,
        "nytimes":0.1574410697,
        "techcrunch":0.1678046168,
        "quartz":0.1083869362,
        "venturebeat":0.1768101781,
        "futurism":0.208476043,
        "scientificamerican":0.1466293115,
        "wired":0.214600821,
        "popsci":0.2724086634,
        "arstechnica":0.148205995,
        "salon":0.081265692,
        "washingtonpost":0.1601274368,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.00987v1",
        "predicted_newsworthiness":37.8842470288,
        "title":"BinsFormer: Revisiting Adaptive Bins for Monocular Depth Estimation",
        "summary":"Monocular depth estimation is a fundamental task in computer vision and has drawn increasing attention. Recently, some methods reformulate it as a classification-regression task to boost the model performance, where continuous depth is estimated via a linear combination of predicted probability distributions and discrete bins. In this paper, we present a novel framework called BinsFormer, tailored for the classification-regression-based depth estimation. It mainly focuses on two crucial components in the specific task: 1) proper generation of adaptive bins and 2) sufficient interaction between probability distribution and bins predictions. To specify, we employ the Transformer decoder to generate bins, novelly viewing it as a direct set-to-set prediction problem. We further integrate a multi-scale decoder structure to achieve a comprehensive understanding of spatial geometry information and estimate depth maps in a coarse-to-fine manner. Moreover, an extra scene understanding query is proposed to improve the estimation accuracy, which turns out that models can implicitly learn useful information from an auxiliary environment classification task. Extensive experiments on the KITTI, NYU, and SUN RGB-D datasets demonstrate that BinsFormer surpasses state-of-the-art monocular depth estimation methods with prominent margins. Code and pretrained models will be made publicly available at \\url{https:\/\/github.com\/zhyever\/Monocular-Depth-Estimation-Toolbox}.",
        "published":1648960682000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.00987v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Apr 02, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0762635838,
        "popularmechanics":0.1442653975,
        "scienmag":0.1024792511,
        "technologyreview":0.1843280822,
        "vox":0.0935774143,
        "newscientist":0.1267944509,
        "vice":0.1208098339,
        "statnews":0.0787874027,
        "nytimes":0.1093749878,
        "techcrunch":0.1392129222,
        "quartz":0.0922667632,
        "venturebeat":0.1885710806,
        "futurism":0.1527379124,
        "scientificamerican":0.1054464346,
        "wired":0.1520822647,
        "popsci":0.1640519964,
        "arstechnica":0.1024008847,
        "salon":0.0801168627,
        "washingtonpost":0.1155295636,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2208.01159v2",
        "predicted_newsworthiness":40.3061762442,
        "title":"BATMAN: Bilateral Attention Transformer in Motion-Appearance Neighboring Space for Video Object Segmentation",
        "summary":"Video Object Segmentation (VOS) is fundamental to video understanding. Transformer-based methods show significant performance improvement on semi-supervised VOS. However, existing work faces challenges segmenting visually similar objects in close proximity of each other. In this paper, we propose a novel Bilateral Attention Transformer in Motion-Appearance Neighboring space (BATMAN) for semi-supervised VOS. It captures object motion in the video via a novel optical flow calibration module that fuses the segmentation mask with optical flow estimation to improve within-object optical flow smoothness and reduce noise at object boundaries. This calibrated optical flow is then employed in our novel bilateral attention, which computes the correspondence between the query and reference frames in the neighboring bilateral space considering both motion and appearance. Extensive experiments validate the effectiveness of BATMAN architecture by outperforming all existing state-of-the-art on all four popular VOS benchmarks: Youtube-VOS 2019 (85.0%), Youtube-VOS 2018 (85.3%), DAVIS 2017Val\/Testdev (86.2%\/82.2%), and DAVIS 2016 (92.5%).",
        "published":1659392494000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2208.01159v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Aug 01, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0717593275,
        "popularmechanics":0.1300020501,
        "scienmag":0.1001910494,
        "technologyreview":0.1701071764,
        "vox":0.1059062703,
        "newscientist":0.1250207676,
        "vice":0.1149136382,
        "statnews":0.07729417,
        "nytimes":0.1111086843,
        "techcrunch":0.1406011972,
        "quartz":0.0980563056,
        "venturebeat":0.1784341391,
        "futurism":0.1379499601,
        "scientificamerican":0.1040758617,
        "wired":0.1533157875,
        "popsci":0.162715666,
        "arstechnica":0.0803907735,
        "salon":0.0709280914,
        "washingtonpost":0.1227334505,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.01254v1",
        "predicted_newsworthiness":56.5459395945,
        "title":"Which Explanation Should I Choose? A Function Approximation Perspective to Characterizing Post hoc Explanations",
        "summary":"Despite the plethora of post hoc model explanation methods, the basic properties and behavior of these methods and the conditions under which each one is effective are not well understood. In this work, we bridge these gaps and address a fundamental question: Which explanation method should one use in a given situation? To this end, we adopt a function approximation perspective and formalize the local function approximation (LFA) framework. We show that popular explanation methods are instances of this framework, performing function approximations of the underlying model in different neighborhoods using different loss functions. We introduce a no free lunch theorem for explanation methods which demonstrates that no single method can perform optimally across all neighbourhoods and calls for choosing among methods. To choose among methods, we set forth a guiding principle based on the function approximation perspective, considering a method to be effective if it recovers the underlying model when the model is a member of the explanation function class. Then, we analyze the conditions under which popular explanation methods are effective and provide recommendations for choosing among explanation methods and creating new ones. Lastly, we empirically validate our theoretical results using various real world datasets, model classes, and prediction tasks. By providing a principled mathematical framework which unifies diverse explanation methods, our work characterizes the behaviour of these methods and their relation to one another, guides the choice of explanation methods, and paves the way for the creation of new ones.",
        "published":1654196970000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.01254v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jun 02, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1543852702,
        "popularmechanics":0.1471809897,
        "scienmag":0.2041230174,
        "technologyreview":0.2874463841,
        "vox":0.1736899442,
        "newscientist":0.18952408,
        "vice":0.1771706945,
        "statnews":0.3026567965,
        "nytimes":0.1852119523,
        "techcrunch":0.1736830636,
        "quartz":0.1499889233,
        "venturebeat":0.2527424829,
        "futurism":0.1939874867,
        "scientificamerican":0.1964003749,
        "wired":0.2056549914,
        "popsci":0.195689583,
        "arstechnica":0.1689848365,
        "salon":0.1670454962,
        "washingtonpost":0.1750212426,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.10221v1",
        "predicted_newsworthiness":49.4359813585,
        "title":"A Graphical Workflow Exploration Environment For Visual Analytics",
        "summary":"Graphical history mechanisms have been widely utilized in many domains to support humans' limited working memory, error recovery, collaboration, and presentation in visual analysis. Yet, there are aspects that remain under-explored in designing graphical history systems for visual analytics systems to help analysts who have complicated workflows. In this paper we report on our design study performed with domain experts, where we characterize domain tasks and designed a visual graphical workflow management environment. Our environment allows analysts to efficiently review, edit, navigate, and explore their complex workflows with their colleagues. In order to evaluate the environment, we present a case study and user study. In the case study, we explore how two domain experts perform collaborative review, communication, and training with our environment; while in the user study with the car data, we reveal that how our environment helps users and how the history mechanism affects users' visual problem-solving behaviors.",
        "published":1650556561000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.10221v1",
        "arxiv_primary_category":"cs.hc",
        "published_hr":"Apr 21, 2022",
        "arxiv_primary_category_hr":"Human-Computer Interaction",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.129019681,
        "popularmechanics":0.1449739264,
        "scienmag":0.1660214301,
        "technologyreview":0.2324232994,
        "vox":0.1449751306,
        "newscientist":0.1521645261,
        "vice":0.1383336719,
        "statnews":0.241754094,
        "nytimes":0.1821826201,
        "techcrunch":0.2279482533,
        "quartz":0.1520565683,
        "venturebeat":0.265359358,
        "futurism":0.1595363617,
        "scientificamerican":0.1382812782,
        "wired":0.197780666,
        "popsci":0.1865814949,
        "arstechnica":0.1337388615,
        "salon":0.121883511,
        "washingtonpost":0.1568918898,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.03761v2",
        "predicted_newsworthiness":53.158241358,
        "title":"A Survey on the Fairness of Recommender Systems",
        "summary":"Recommender systems are an essential tool to relieve the information overload challenge and play an important role in people's daily lives. Since recommendations involve allocations of social resources (e.g., job recommendation), an important issue is whether recommendations are fair. Unfair recommendations are not only unethical but also harm the long-term interests of the recommender system itself. As a result, fairness issues in recommender systems have recently attracted increasing attention. However, due to multiple complex resource allocation processes and various fairness definitions, the research on fairness in recommendation is scattered. To fill this gap, we review over 60 papers published in top conferences\/journals, including TOIS, SIGIR, and WWW. First, we summarize fairness definitions in the recommendation and provide several views to classify fairness issues. Then, we review recommendation datasets and measurements in fairness studies and provide an elaborate taxonomy of fairness methods in the recommendation. Finally, we conclude this survey by outlining some promising future directions.",
        "published":1654679708000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.03761v2",
        "arxiv_primary_category":"cs.ir",
        "published_hr":"Jun 08, 2022",
        "arxiv_primary_category_hr":"Information Retrieval",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1928786294,
        "popularmechanics":0.1160247172,
        "scienmag":0.1727843511,
        "technologyreview":0.2772156791,
        "vox":0.2644068676,
        "newscientist":0.1639673311,
        "vice":0.1119759348,
        "statnews":0.2268474293,
        "nytimes":0.2223194271,
        "techcrunch":0.2598314039,
        "quartz":0.2311782013,
        "venturebeat":0.2656905935,
        "futurism":0.2009131092,
        "scientificamerican":0.1811550896,
        "wired":0.2466185457,
        "popsci":0.2058818115,
        "arstechnica":0.2214664131,
        "salon":0.1672752115,
        "washingtonpost":0.2539310892,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.04502v1",
        "predicted_newsworthiness":34.6087889758,
        "title":"Multiview Stereo with Cascaded Epipolar RAFT",
        "summary":"We address multiview stereo (MVS), an important 3D vision task that reconstructs a 3D model such as a dense point cloud from multiple calibrated images. We propose CER-MVS (Cascaded Epipolar RAFT Multiview Stereo), a new approach based on the RAFT (Recurrent All-Pairs Field Transforms) architecture developed for optical flow. CER-MVS introduces five new changes to RAFT: epipolar cost volumes, cost volume cascading, multiview fusion of cost volumes, dynamic supervision, and multiresolution fusion of depth maps. CER-MVS is significantly different from prior work in multiview stereo. Unlike prior work, which operates by updating a 3D cost volume, CER-MVS operates by updating a disparity field. Furthermore, we propose an adaptive thresholding method to balance the completeness and accuracy of the reconstructed point clouds. Experiments show that our approach achieves competitive performance on DTU (the second best among known results) and state-of-the-art performance on the Tanks-and-Temples benchmark (both the intermediate and advanced set). Code is available at https:\/\/github.com\/princeton-vl\/CER-MVS",
        "published":1652120225000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.04502v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 09, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0740779242,
        "popularmechanics":0.1395902713,
        "scienmag":0.1180646882,
        "technologyreview":0.1539626019,
        "vox":0.0929149698,
        "newscientist":0.1206873367,
        "vice":0.1438234846,
        "statnews":0.0922920597,
        "nytimes":0.1094304574,
        "techcrunch":0.1373146631,
        "quartz":0.0824879792,
        "venturebeat":0.173226796,
        "futurism":0.144391039,
        "scientificamerican":0.1086359999,
        "wired":0.147090129,
        "popsci":0.1473205562,
        "arstechnica":0.1064862587,
        "salon":0.0913847097,
        "washingtonpost":0.1163594842,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.02314v1",
        "predicted_newsworthiness":33.4348963834,
        "title":"Towards To-a-T Spatio-Temporal Focus for Skeleton-Based Action Recognition",
        "summary":"Graph Convolutional Networks (GCNs) have been widely used to model the high-order dynamic dependencies for skeleton-based action recognition. Most existing approaches do not explicitly embed the high-order spatio-temporal importance to joints' spatial connection topology and intensity, and they do not have direct objectives on their attention module to jointly learn when and where to focus on in the action sequence. To address these problems, we propose the To-a-T Spatio-Temporal Focus (STF), a skeleton-based action recognition framework that utilizes the spatio-temporal gradient to focus on relevant spatio-temporal features. We first propose the STF modules with learnable gradient-enforced and instance-dependent adjacency matrices to model the high-order spatio-temporal dynamics. Second, we propose three loss terms defined on the gradient-based spatio-temporal focus to explicitly guide the classifier when and where to look at, distinguish confusing classes, and optimize the stacked STF modules. STF outperforms the state-of-the-art methods on the NTU RGB+D 60, NTU RGB+D 120, and Kinetics Skeleton 400 datasets in all 15 settings over different views, subjects, setups, and input modalities, and STF also shows better accuracy on scarce data and dataset shifting settings.",
        "published":1644000749000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.02314v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Feb 04, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0867772978,
        "popularmechanics":0.1098573945,
        "scienmag":0.1126009131,
        "technologyreview":0.1375189689,
        "vox":0.0842092107,
        "newscientist":0.1173543813,
        "vice":0.107006218,
        "statnews":0.0904926865,
        "nytimes":0.1077605536,
        "techcrunch":0.1048121276,
        "quartz":0.0904578315,
        "venturebeat":0.1381678378,
        "futurism":0.1104240267,
        "scientificamerican":0.0969810069,
        "wired":0.1228762162,
        "popsci":0.1198325605,
        "arstechnica":0.0873656397,
        "salon":0.0788263228,
        "washingtonpost":0.099100407,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.04978v1",
        "predicted_newsworthiness":39.8532344219,
        "title":"Wave-ViT: Unifying Wavelet and Transformers for Visual Representation Learning",
        "summary":"Multi-scale Vision Transformer (ViT) has emerged as a powerful backbone for computer vision tasks, while the self-attention computation in Transformer scales quadratically w.r.t. the input patch number. Thus, existing solutions commonly employ down-sampling operations (e.g., average pooling) over keys\/values to dramatically reduce the computational cost. In this work, we argue that such over-aggressive down-sampling design is not invertible and inevitably causes information dropping especially for high-frequency components in objects (e.g., texture details). Motivated by the wavelet theory, we construct a new Wavelet Vision Transformer (\\textbf{Wave-ViT}) that formulates the invertible down-sampling with wavelet transforms and self-attention learning in a unified way. This proposal enables self-attention learning with lossless down-sampling over keys\/values, facilitating the pursuing of a better efficiency-vs-accuracy trade-off. Furthermore, inverse wavelet transforms are leveraged to strengthen self-attention outputs by aggregating local contexts with enlarged receptive field. We validate the superiority of Wave-ViT through extensive experiments over multiple vision tasks (e.g., image recognition, object detection and instance segmentation). Its performances surpass state-of-the-art ViT backbones with comparable FLOPs. Source code is available at \\url{https:\/\/github.com\/YehLi\/ImageNetModel}.",
        "published":1657555431000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.04978v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 11, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0865869786,
        "popularmechanics":0.1290041233,
        "scienmag":0.1318881594,
        "technologyreview":0.2120004103,
        "vox":0.1042700143,
        "newscientist":0.1408728468,
        "vice":0.1106285375,
        "statnews":0.1142201433,
        "nytimes":0.1195615251,
        "techcrunch":0.1346818667,
        "quartz":0.1050783959,
        "venturebeat":0.1914815506,
        "futurism":0.1517877913,
        "scientificamerican":0.1216305706,
        "wired":0.1515422198,
        "popsci":0.1575487618,
        "arstechnica":0.1009667324,
        "salon":0.0818607355,
        "washingtonpost":0.1321036041,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.02550v1",
        "predicted_newsworthiness":42.3931289346,
        "title":"LUNA: Learning Slot-Turn Alignment for Dialogue State Tracking",
        "summary":"Dialogue state tracking (DST) aims to predict the current dialogue state given the dialogue history. Existing methods generally exploit the utterances of all dialogue turns to assign value for each slot. This could lead to suboptimal results due to the information introduced from irrelevant utterances in the dialogue history, which may be useless and can even cause confusion. To address this problem, we propose LUNA, a sLot-tUrN Alignment enhanced approach. It first explicitly aligns each slot with its most relevant utterance, then further predicts the corresponding value based on this aligned utterance instead of all dialogue utterances. Furthermore, we design a slot ranking auxiliary task to learn the temporal correlation among slots which could facilitate the alignment. Comprehensive experiments are conducted on multi-domain task-oriented dialogue datasets, i.e., MultiWOZ 2.0, MultiWOZ 2.1, and MultiWOZ 2.2. The results show that LUNA achieves new state-of-the-art results on these datasets.",
        "published":1651745903000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.02550v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"May 05, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.100528625,
        "popularmechanics":0.1121081719,
        "scienmag":0.0876745584,
        "technologyreview":0.2008137842,
        "vox":0.1648874883,
        "newscientist":0.1112779902,
        "vice":0.0938532042,
        "statnews":0.1254004774,
        "nytimes":0.1401745316,
        "techcrunch":0.1758648876,
        "quartz":0.1418630242,
        "venturebeat":0.2311283264,
        "futurism":0.1494054323,
        "scientificamerican":0.1038998604,
        "wired":0.1914847212,
        "popsci":0.172253627,
        "arstechnica":0.1252331424,
        "salon":0.0909404475,
        "washingtonpost":0.1383974081,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.09660v1",
        "predicted_newsworthiness":62.0400695573,
        "title":"Medical Dataset Classification for Kurdish Short Text over Social Media",
        "summary":"The Facebook application is used as a resource for collecting the comments of this dataset, The dataset consists of 6756 comments to create a Medical Kurdish Dataset (MKD). The samples are comments of users, which are gathered from different posts of pages (Medical, News, Economy, Education, and Sport). Six steps as a preprocessing technique are performed on the raw dataset to clean and remove noise in the comments by replacing characters. The comments (short text) are labeled for positive class (medical comment) and negative class (non-medical comment) as text classification. The percentage ratio of the negative class is 55% while the positive class is 45%.",
        "published":1648332685000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.09660v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Mar 26, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2153900833,
        "popularmechanics":0.1357601296,
        "scienmag":0.2269420644,
        "technologyreview":0.2855968172,
        "vox":0.2454513548,
        "newscientist":0.1961417593,
        "vice":0.1300687588,
        "statnews":0.3267124371,
        "nytimes":0.2319711108,
        "techcrunch":0.2215460599,
        "quartz":0.2164743845,
        "venturebeat":0.2536693875,
        "futurism":0.2012484542,
        "scientificamerican":0.1933902694,
        "wired":0.2449408337,
        "popsci":0.2194008967,
        "arstechnica":0.2128029758,
        "salon":0.2147776891,
        "washingtonpost":0.2810080657,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.01807v1",
        "predicted_newsworthiness":37.6476400704,
        "title":"Quadrotor Formation Flying Resilient to Abrupt Vehicle Failures via a Fluid Flow Navigation Function",
        "summary":"This paper develops and experimentally evaluates a navigation function for quadrotor formation flight that is resilient to abrupt quadrotor failures and other obstacles. The navigation function is based on modeling healthy quadrotors as particles in an ideal fluid flow. We provide three key contributions: (i) A Containment Exclusion Mode (CEM) safety theorem and proof which guarantees safety and formally specifies a minimum safe distance between quadrotors in formation, (ii) A real-time, computationally efficient CEM navigation algorithm, (iii) Simulation and experimental algorithm validation. Simulations were first performed with a team of six virtual quadrotors to demonstrate velocity tracking via dynamic slide speed, maintaining sufficient inter-agent distances, and operating in real-time. Flight tests with a team of two custom quadrotors were performed in an indoor motion capture flight facility, successfully validating that the navigation algorithm can handle non-trivial bounded tracking errors while guaranteeing safety.",
        "published":1646324423000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.01807v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Mar 03, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1071556552,
        "popularmechanics":0.2722246212,
        "scienmag":0.1478211465,
        "technologyreview":0.205205132,
        "vox":0.1261925457,
        "newscientist":0.1634902071,
        "vice":0.1844297782,
        "statnews":0.1349164261,
        "nytimes":0.1618505969,
        "techcrunch":0.1854071423,
        "quartz":0.114775455,
        "venturebeat":0.2096148521,
        "futurism":0.2272303399,
        "scientificamerican":0.1502798013,
        "wired":0.2067581044,
        "popsci":0.3283733877,
        "arstechnica":0.1777771264,
        "salon":0.1214820805,
        "washingtonpost":0.1810874297,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.05715v1",
        "predicted_newsworthiness":34.1024267599,
        "title":"Taylor-Lagrange Neural Ordinary Differential Equations: Toward Fast Training and Evaluation of Neural ODEs",
        "summary":"Neural ordinary differential equations (NODEs) -- parametrizations of differential equations using neural networks -- have shown tremendous promise in learning models of unknown continuous-time dynamical systems from data. However, every forward evaluation of a NODE requires numerical integration of the neural network used to capture the system dynamics, making their training prohibitively expensive. Existing works rely on off-the-shelf adaptive step-size numerical integration schemes, which often require an excessive number of evaluations of the underlying dynamics network to obtain sufficient accuracy for training. By contrast, we accelerate the evaluation and the training of NODEs by proposing a data-driven approach to their numerical integration. The proposed Taylor-Lagrange NODEs (TL-NODEs) use a fixed-order Taylor expansion for numerical integration, while also learning to estimate the expansion's approximation error. As a result, the proposed approach achieves the same accuracy as adaptive step-size schemes while employing only low-order Taylor expansions, thus greatly reducing the computational cost necessary to integrate the NODE. A suite of numerical experiments, including modeling dynamical systems, image classification, and density estimation, demonstrate that TL-NODEs can be trained more than an order of magnitude faster than state-of-the-art approaches, without any loss in performance.",
        "published":1642204579000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.05715v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jan 14, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.078831138,
        "popularmechanics":0.1343209214,
        "scienmag":0.1644866112,
        "technologyreview":0.2257263296,
        "vox":0.0911747839,
        "newscientist":0.138651152,
        "vice":0.1220125174,
        "statnews":0.1775163153,
        "nytimes":0.1208205717,
        "techcrunch":0.1327602558,
        "quartz":0.086186588,
        "venturebeat":0.2009431418,
        "futurism":0.1657669704,
        "scientificamerican":0.1245161871,
        "wired":0.1483129023,
        "popsci":0.1541672969,
        "arstechnica":0.1048821518,
        "salon":0.0831594753,
        "washingtonpost":0.1183047923,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.08242v1",
        "predicted_newsworthiness":48.3510660108,
        "title":"Catastrophic overfitting is a bug but also a feature",
        "summary":"Despite clear computational advantages in building robust neural networks, adversarial training (AT) using single-step methods is unstable as it suffers from catastrophic overfitting (CO): Networks gain non-trivial robustness during the first stages of adversarial training, but suddenly reach a breaking point where they quickly lose all robustness in just a few iterations. Although some works have succeeded at preventing CO, the different mechanisms that lead to this remarkable failure mode are still poorly understood. In this work, however, we find that the interplay between the structure of the data and the dynamics of AT plays a fundamental role in CO. Specifically, through active interventions on typical datasets of natural images, we establish a causal link between the structure of the data and the onset of CO in single-step AT methods. This new perspective provides important insights into the mechanisms that lead to CO and paves the way towards a better understanding of the general dynamics of robust model construction. The code to reproduce the experiments of this paper can be found at https:\/\/github.com\/gortizji\/co_features .",
        "published":1655392959000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.08242v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jun 16, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1365390861,
        "popularmechanics":0.1755171219,
        "scienmag":0.1851077826,
        "technologyreview":0.3164569066,
        "vox":0.1760767008,
        "newscientist":0.1903874691,
        "vice":0.1741157673,
        "statnews":0.2340345289,
        "nytimes":0.1809695011,
        "techcrunch":0.1829227083,
        "quartz":0.1556885003,
        "venturebeat":0.2555392342,
        "futurism":0.228053072,
        "scientificamerican":0.1778092694,
        "wired":0.2122145727,
        "popsci":0.209503212,
        "arstechnica":0.1823304796,
        "salon":0.1540412588,
        "washingtonpost":0.1870194561,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.03946v1",
        "predicted_newsworthiness":37.8435327507,
        "title":"Probabilistic Representations for Video Contrastive Learning",
        "summary":"This paper presents Probabilistic Video Contrastive Learning, a self-supervised representation learning method that bridges contrastive learning with probabilistic representation. We hypothesize that the clips composing the video have different distributions in short-term duration, but can represent the complicated and sophisticated video distribution through combination in a common embedding space. Thus, the proposed method represents video clips as normal distributions and combines them into a Mixture of Gaussians to model the whole video distribution. By sampling embeddings from the whole video distribution, we can circumvent the careful sampling strategy or transformations to generate augmented views of the clips, unlike previous deterministic methods that have mainly focused on such sample generation strategies for contrastive learning. We further propose a stochastic contrastive loss to learn proper video distributions and handle the inherent uncertainty from the nature of the raw video. Experimental results verify that our probabilistic embedding stands as a state-of-the-art video representation learning for action recognition and video retrieval on the most popular benchmarks, including UCF101 and HMDB51.",
        "published":1649408970000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.03946v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Apr 08, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0935315182,
        "popularmechanics":0.1129008219,
        "scienmag":0.0993661611,
        "technologyreview":0.1892509275,
        "vox":0.1036099777,
        "newscientist":0.1211639915,
        "vice":0.0880914661,
        "statnews":0.108815784,
        "nytimes":0.1204085391,
        "techcrunch":0.1216612221,
        "quartz":0.1060295649,
        "venturebeat":0.1644400217,
        "futurism":0.1304855921,
        "scientificamerican":0.0958693257,
        "wired":0.1583326285,
        "popsci":0.1457454762,
        "arstechnica":0.0939216704,
        "salon":0.0783379131,
        "washingtonpost":0.1265056899,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.00289v1",
        "predicted_newsworthiness":52.7067507727,
        "title":"Selecting task with optimal transport self-supervised learning for few-shot classification",
        "summary":"Few-Shot classification aims at solving problems that only a few samples are available in the training process. Due to the lack of samples, researchers generally employ a set of training tasks from other domains to assist the target task, where the distribution between assistant tasks and the target task is usually different. To reduce the distribution gap, several lines of methods have been proposed, such as data augmentation and domain alignment. However, one common drawback of these algorithms is that they ignore the similarity task selection before training. The fundamental problem is to push the auxiliary tasks close to the target task. In this paper, we propose a novel task selecting algorithm, named Optimal Transport Task Selecting (OTTS), to construct a training set by selecting similar tasks for Few-Shot learning. Specifically, the OTTS measures the task similarity by calculating the optimal transport distance and completes the model training via a self-supervised strategy. By utilizing the selected tasks with OTTS, the training process of Few-Shot learning become more stable and effective. Other proposed methods including data augmentation and domain alignment can be used in the meantime with OTTS. We conduct extensive experiments on a variety of datasets, including MiniImageNet, CIFAR, CUB, Cars, and Places, to evaluate the effectiveness of OTTS. Experimental results validate that our OTTS outperforms the typical baselines, i.e., MAML, matchingnet, protonet, by a large margin (averagely 1.72\\% accuracy improvement).",
        "published":1648802729000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.00289v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Apr 01, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0976358779,
        "popularmechanics":0.163302775,
        "scienmag":0.1421670084,
        "technologyreview":0.253450993,
        "vox":0.1281243507,
        "newscientist":0.1489188986,
        "vice":0.1011625501,
        "statnews":0.1847093337,
        "nytimes":0.1407799981,
        "techcrunch":0.1879336001,
        "quartz":0.1266408807,
        "venturebeat":0.2475293173,
        "futurism":0.1928859846,
        "scientificamerican":0.1214975631,
        "wired":0.1892192179,
        "popsci":0.2042839931,
        "arstechnica":0.1156592767,
        "salon":0.0932969354,
        "washingtonpost":0.1598458542,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.12888v1",
        "predicted_newsworthiness":45.192683695,
        "title":"A Dataset for Medical Instructional Video Classification and Question Answering",
        "summary":"This paper introduces a new challenge and datasets to foster research toward designing systems that can understand medical videos and provide visual answers to natural language questions. We believe medical videos may provide the best possible answers to many first aids, medical emergency, and medical education questions. Toward this, we created the MedVidCL and MedVidQA datasets and introduce the tasks of Medical Video Classification (MVC) and Medical Visual Answer Localization (MVAL), two tasks that focus on cross-modal (medical language and medical video) understanding. The proposed tasks and datasets have the potential to support the development of sophisticated downstream applications that can benefit the public and medical practitioners. Our datasets consist of 6,117 annotated videos for the MVC task and 3,010 annotated questions and answers timestamps from 899 videos for the MVAL task. These datasets have been verified and corrected by medical informatics experts. We have also benchmarked each task with the created MedVidCL and MedVidQA datasets and proposed the multimodal learning methods that set competitive baselines for future research.",
        "published":1643565991000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.12888v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jan 30, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1425385792,
        "popularmechanics":0.1412463986,
        "scienmag":0.1973094044,
        "technologyreview":0.2535792973,
        "vox":0.1591728536,
        "newscientist":0.1722492747,
        "vice":0.118525847,
        "statnews":0.3085073383,
        "nytimes":0.1788913961,
        "techcrunch":0.1828638379,
        "quartz":0.1407769751,
        "venturebeat":0.243149142,
        "futurism":0.1862270901,
        "scientificamerican":0.1567138808,
        "wired":0.1903843828,
        "popsci":0.1997205118,
        "arstechnica":0.1430366118,
        "salon":0.1657646746,
        "washingtonpost":0.1790899288,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.07316v3",
        "predicted_newsworthiness":51.0995666316,
        "title":"Privacy-Preserving Face Recognition with Learnable Privacy Budgets in Frequency Domain",
        "summary":"Face recognition technology has been used in many fields due to its high recognition accuracy, including the face unlocking of mobile devices, community access control systems, and city surveillance. As the current high accuracy is guaranteed by very deep network structures, facial images often need to be transmitted to third-party servers with high computational power for inference. However, facial images visually reveal the user's identity information. In this process, both untrusted service providers and malicious users can significantly increase the risk of a personal privacy breach. Current privacy-preserving approaches to face recognition are often accompanied by many side effects, such as a significant increase in inference time or a noticeable decrease in recognition accuracy. This paper proposes a privacy-preserving face recognition method using differential privacy in the frequency domain. Due to the utilization of differential privacy, it offers a guarantee of privacy in theory. Meanwhile, the loss of accuracy is very slight. This method first converts the original image to the frequency domain and removes the direct component termed DC. Then a privacy budget allocation method can be learned based on the loss of the back-end face recognition network within the differential privacy framework. Finally, it adds the corresponding noise to the frequency domain features. Our method performs very well with several classical face recognition test sets according to the extensive experiments.",
        "published":1657869336000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.07316v3",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 15, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1243560191,
        "popularmechanics":0.1384940456,
        "scienmag":0.1213383328,
        "technologyreview":0.2585210567,
        "vox":0.1828324078,
        "newscientist":0.1554364168,
        "vice":0.0965409272,
        "statnews":0.1665080884,
        "nytimes":0.1725225939,
        "techcrunch":0.1879502524,
        "quartz":0.1452915568,
        "venturebeat":0.2214762701,
        "futurism":0.1955005103,
        "scientificamerican":0.118030571,
        "wired":0.2062265941,
        "popsci":0.200940275,
        "arstechnica":0.1867233164,
        "salon":0.1068349281,
        "washingtonpost":0.2271878955,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.07372v1",
        "predicted_newsworthiness":56.6846680667,
        "title":"Enhancing crowd flow prediction in various spatial and temporal granularities",
        "summary":"Thanks to the diffusion of the Internet of Things, nowadays it is possible to sense human mobility almost in real time using unconventional methods (e.g., number of bikes in a bike station). Due to the diffusion of such technologies, the last years have witnessed a significant growth of human mobility studies, motivated by their importance in a wide range of applications, from traffic management to public security and computational epidemiology. A mobility task that is becoming prominent is crowd flow prediction, i.e., forecasting aggregated incoming and outgoing flows in the locations of a geographic region. Although several deep learning approaches have been proposed to solve this problem, their usage is limited to specific types of spatial tessellations and cannot provide sufficient explanations of their predictions. We propose CrowdNet, a solution to crowd flow prediction based on graph convolutional networks. Compared with state-of-the-art solutions, CrowdNet can be used with regions of irregular shapes and provide meaningful explanations of the predicted crowd flows. We conduct experiments on public data varying the spatio-temporal granularity of crowd flows to show the superiority of our model with respect to existing methods, and we investigate CrowdNet's reliability to missing or noisy input data. Our model is a step forward in the design of reliable deep learning models to predict and explain human displacements in urban environments.",
        "published":1647086627000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.07372v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Mar 12, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1869185393,
        "popularmechanics":0.1683553468,
        "scienmag":0.2000919492,
        "technologyreview":0.2676534091,
        "vox":0.2016627799,
        "newscientist":0.2022748897,
        "vice":0.1580883738,
        "statnews":0.2191129916,
        "nytimes":0.1917116531,
        "techcrunch":0.2099913316,
        "quartz":0.1794443196,
        "venturebeat":0.2460991686,
        "futurism":0.2124560301,
        "scientificamerican":0.1975562615,
        "wired":0.2217079085,
        "popsci":0.2255047947,
        "arstechnica":0.17202894,
        "salon":0.1934530222,
        "washingtonpost":0.2097683987,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.04125v1",
        "predicted_newsworthiness":46.979969377,
        "title":"Towards Self-supervised and Weight-preserving Neural Architecture Search",
        "summary":"Neural architecture search (NAS) algorithms save tremendous labor from human experts. Recent advancements further reduce the computational overhead to an affordable level. However, it is still cumbersome to deploy the NAS techniques in real-world applications due to the fussy procedures and the supervised learning paradigm. In this work, we propose the self-supervised and weight-preserving neural architecture search (SSWP-NAS) as an extension of the current NAS framework by allowing the self-supervision and retaining the concomitant weights discovered during the search stage. As such, we simplify the workflow of NAS to a one-stage and proxy-free procedure. Experiments show that the architectures searched by the proposed framework achieve state-of-the-art accuracy on CIFAR-10, CIFAR-100, and ImageNet datasets without using manual labels. Moreover, we show that employing the concomitant weights as initialization consistently outperforms the random initialization and the two-stage weight pre-training method by a clear margin under semi-supervised learning scenarios. Codes are publicly available at https:\/\/github.com\/LzVv123456\/SSWP-NAS.",
        "published":1654714085000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.04125v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jun 08, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0781655065,
        "popularmechanics":0.1305038083,
        "scienmag":0.1463816177,
        "technologyreview":0.2470724647,
        "vox":0.0934616273,
        "newscientist":0.1359313176,
        "vice":0.1145813121,
        "statnews":0.1875426427,
        "nytimes":0.1181178173,
        "techcrunch":0.1484318348,
        "quartz":0.0968590134,
        "venturebeat":0.2258534346,
        "futurism":0.1658459757,
        "scientificamerican":0.1098563174,
        "wired":0.1466980492,
        "popsci":0.1587579428,
        "arstechnica":0.1007835954,
        "salon":0.0716305268,
        "washingtonpost":0.1250842978,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.05186v1",
        "predicted_newsworthiness":49.5052915314,
        "title":"Correcting Robot Plans with Natural Language Feedback",
        "summary":"When humans design cost or goal specifications for robots, they often produce specifications that are ambiguous, underspecified, or beyond planners' ability to solve. In these cases, corrections provide a valuable tool for human-in-the-loop robot control. Corrections might take the form of new goal specifications, new constraints (e.g. to avoid specific objects), or hints for planning algorithms (e.g. to visit specific waypoints). Existing correction methods (e.g. using a joystick or direct manipulation of an end effector) require full teleoperation or real-time interaction. In this paper, we explore natural language as an expressive and flexible tool for robot correction. We describe how to map from natural language sentences to transformations of cost functions. We show that these transformations enable users to correct goals, update robot motions to accommodate additional user preferences, and recover from planning errors. These corrections can be leveraged to get 81% and 93% success rates on tasks where the original planner failed, with either one or two language corrections. Our method makes it possible to compose multiple constraints and generalizes to unseen scenes, objects, and sentences in simulated environments and real-world environments.",
        "published":1649690563000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.05186v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Apr 11, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.126599044,
        "popularmechanics":0.1864045901,
        "scienmag":0.1364392062,
        "technologyreview":0.3087629666,
        "vox":0.1603310416,
        "newscientist":0.1925629843,
        "vice":0.1551272792,
        "statnews":0.2100755585,
        "nytimes":0.1913177883,
        "techcrunch":0.2159083094,
        "quartz":0.1514193213,
        "venturebeat":0.2815820605,
        "futurism":0.2507530026,
        "scientificamerican":0.1401548789,
        "wired":0.2447280525,
        "popsci":0.2476308782,
        "arstechnica":0.1586166187,
        "salon":0.1318253925,
        "washingtonpost":0.1958867619,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.07633v2",
        "predicted_newsworthiness":41.3750142841,
        "title":"Taming Continuous Posteriors for Latent Variational Dialogue Policies",
        "summary":"Utilizing amortized variational inference for latent-action reinforcement learning (RL) has been shown to be an effective approach in Task-oriented Dialogue (ToD) systems for optimizing dialogue success. Until now, categorical posteriors have been argued to be one of the main drivers of performance. In this work we revisit Gaussian variational posteriors for latent-action RL and show that they can yield even better performance than categoricals. We achieve this by simplifying the training procedure and propose ways to regularize the latent dialogue policy to retain good response coherence. Using continuous latent representations our model achieves state of the art dialogue success rate on the MultiWOZ benchmark, and also compares well to categorical latent methods in response coherence.",
        "published":1652705432000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.07633v2",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"May 16, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1097714644,
        "popularmechanics":0.1193459629,
        "scienmag":0.0982236634,
        "technologyreview":0.2256842986,
        "vox":0.1486303019,
        "newscientist":0.1179986389,
        "vice":0.0985925321,
        "statnews":0.1498386708,
        "nytimes":0.1405854816,
        "techcrunch":0.1636428386,
        "quartz":0.1334435927,
        "venturebeat":0.2284652549,
        "futurism":0.1600612097,
        "scientificamerican":0.1203897385,
        "wired":0.1845223523,
        "popsci":0.1571380349,
        "arstechnica":0.1303203485,
        "salon":0.1082437535,
        "washingtonpost":0.1270672288,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.08046v3",
        "predicted_newsworthiness":49.5353916176,
        "title":"MDM:Visual Explanations for Neural Networks via Multiple Dynamic Mask",
        "summary":"The Class Activation Maps(CAM) lookup of a neural network can tell us what regions the neural network is focusing on when making a decision.We propose an algorithm Multiple Dynamic Mask (MDM), which is a general saliency graph query method with interpretability of inference process. The algorithm is based on an assumption: when a picture is input into a trained neural network, only the activation features related to classification will affect the classification results of the neural network, and the features unrelated to classification will hardly affect the classification results of the network. MDM: A learning-based end-to-end algorithm for finding regions of interest for neural network classification.It has the following advantages: 1. It has the interpretability of the reasoning process, and the reasoning process conforms to human cognition. 2. It is universal, it can be used for any neural network and does not depend on the internal structure of the neural network. 3. The search performance is better. The algorithm is based on learning and has the ability to adapt to different data and networks. The performance is better than the method proposed in the previous paper. For the MDM saliency map search algorithm, we experimentally compared ResNet and DenseNet as the trained neural network. The recent advanced saliency map search method and the results of MDM on the performance indicators of each search effect item, the performance of MDM has reached the state of the art. We applied the MDM method to the interpretable neural network ProtoPNet and XProtoNet, which improved the model's interpretability prototype search performance. And we visualize the effect of convolutional neural architecture and Transformer architecture in saliency map search, illustrating the interpretability and generality of MDM.",
        "published":1658017516000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.08046v3",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 16, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1147902557,
        "popularmechanics":0.1596539978,
        "scienmag":0.174942816,
        "technologyreview":0.3015326369,
        "vox":0.1351324265,
        "newscientist":0.1807454584,
        "vice":0.1525478669,
        "statnews":0.2381990553,
        "nytimes":0.1616888847,
        "techcrunch":0.1773967348,
        "quartz":0.1285779129,
        "venturebeat":0.2649605521,
        "futurism":0.202842871,
        "scientificamerican":0.1477654969,
        "wired":0.1943717434,
        "popsci":0.2017820862,
        "arstechnica":0.1359910912,
        "salon":0.1136770406,
        "washingtonpost":0.1540057376,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2208.00223v1",
        "predicted_newsworthiness":42.9871787138,
        "title":"PolarMix: A General Data Augmentation Technique for LiDAR Point Clouds",
        "summary":"LiDAR point clouds, which are usually scanned by rotating LiDAR sensors continuously, capture precise geometry of the surrounding environment and are crucial to many autonomous detection and navigation tasks. Though many 3D deep architectures have been developed, efficient collection and annotation of large amounts of point clouds remain one major challenge in the analytic and understanding of point cloud data. This paper presents PolarMix, a point cloud augmentation technique that is simple and generic but can mitigate the data constraint effectively across different perception tasks and scenarios. PolarMix enriches point cloud distributions and preserves point cloud fidelity via two cross-scan augmentation strategies that cut, edit, and mix point clouds along the scanning direction. The first is scene-level swapping which exchanges point cloud sectors of two LiDAR scans that are cut along the azimuth axis. The second is instance-level rotation and paste which crops point instances from one LiDAR scan, rotates them by multiple angles (to create multiple copies), and paste the rotated point instances into other scans. Extensive experiments show that PolarMix achieves superior performance consistently across different perception tasks and scenarios. In addition, it can work as plug-and-play for various 3D deep architectures and also performs well for unsupervised domain adaptation.",
        "published":1659189139000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2208.00223v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 30, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1091247525,
        "popularmechanics":0.1889843889,
        "scienmag":0.1620521141,
        "technologyreview":0.2388396318,
        "vox":0.1430427387,
        "newscientist":0.1653659385,
        "vice":0.1811522734,
        "statnews":0.1343907481,
        "nytimes":0.1514518879,
        "techcrunch":0.2039523839,
        "quartz":0.1252800001,
        "venturebeat":0.239554523,
        "futurism":0.202756121,
        "scientificamerican":0.1478868013,
        "wired":0.2029911871,
        "popsci":0.2142204347,
        "arstechnica":0.151589012,
        "salon":0.131009376,
        "washingtonpost":0.1641891416,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.08256v1",
        "predicted_newsworthiness":44.2596760509,
        "title":"Letters From the Past: Modeling Historical Sound Change Through Diachronic Character Embeddings",
        "summary":"While a great deal of work has been done on NLP approaches to lexical semantic change detection, other aspects of language change have received less attention from the NLP community. In this paper, we address the detection of sound change through historical spelling. We propose that a sound change can be captured by comparing the relative distance through time between their distributions using PPMI character embeddings. We verify this hypothesis in synthetic data and then test the method's ability to trace the well-known historical change of lenition of plosives in Danish historical sources. We show that the models are able to identify several of the changes under consideration and to uncover meaningful contexts in which they appeared. The methodology has the potential to contribute to the study of open questions such as the relative chronology of sound shifts and their geographical distribution.",
        "published":1652788637000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.08256v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"May 17, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.14196827,
        "popularmechanics":0.1154268019,
        "scienmag":0.1286761944,
        "technologyreview":0.1600736031,
        "vox":0.1117243243,
        "newscientist":0.1459237267,
        "vice":0.148349334,
        "statnews":0.1197192957,
        "nytimes":0.1427267009,
        "techcrunch":0.1284893412,
        "quartz":0.1152055946,
        "venturebeat":0.1558182335,
        "futurism":0.1111890494,
        "scientificamerican":0.1760914827,
        "wired":0.1535644412,
        "popsci":0.1656799305,
        "arstechnica":0.119574663,
        "salon":0.098458763,
        "washingtonpost":0.1178095648,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.04173v1",
        "predicted_newsworthiness":50.0687133206,
        "title":"Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models",
        "summary":"Pre-trained language models (LMs) are shown to easily generate toxic language. In this work, we systematically explore domain-adaptive training to reduce the toxicity of language models. We conduct this study on three dimensions: training corpus, model size, and parameter efficiency. For the training corpus, we propose to leverage the generative power of LMs and generate nontoxic datasets for domain-adaptive training, which mitigates the exposure bias and is shown to be more data-efficient than using a curated pre-training corpus. We demonstrate that the self-generation method consistently outperforms the existing baselines across various model sizes on both automatic and human evaluations, even when it uses a 1\/3 smaller training corpus. We then comprehensively study detoxifying LMs with parameter sizes ranging from 126M up to 530B (3x larger than GPT-3), a scale that has never been studied before. We find that i) large LMs have similar toxicity levels as smaller ones given the same pre-training corpus, and ii) large LMs require more endeavor to detoxify. We also explore parameter-efficient training methods for detoxification. We demonstrate that adding and training adapter-only layers in LMs not only saves a lot of parameters but also achieves a better trade-off between toxicity and perplexity than whole model adaptation for the large-scale models.",
        "published":1644358240000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.04173v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Feb 08, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1477301785,
        "popularmechanics":0.1484593943,
        "scienmag":0.1589490259,
        "technologyreview":0.2992018602,
        "vox":0.1970336148,
        "newscientist":0.1825336179,
        "vice":0.1353321994,
        "statnews":0.2412366522,
        "nytimes":0.1799434162,
        "techcrunch":0.1889426676,
        "quartz":0.167496636,
        "venturebeat":0.275404437,
        "futurism":0.2167570906,
        "scientificamerican":0.1674516068,
        "wired":0.2229985938,
        "popsci":0.2087684381,
        "arstechnica":0.1715587929,
        "salon":0.1670823767,
        "washingtonpost":0.2113113323,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.06308v2",
        "predicted_newsworthiness":40.0209478381,
        "title":"Knowledge Graph Construction and Its Application in Automatic Radiology Report Generation from Radiologist's Dictation",
        "summary":"Conventionally, the radiologist prepares the diagnosis notes and shares them with the transcriptionist. Then the transcriptionist prepares a preliminary formatted report referring to the notes, and finally, the radiologist reviews the report, corrects the errors, and signs off. This workflow causes significant delays and errors in the report. In current research work, we focus on applications of NLP techniques like Information Extraction (IE) and domain-specific Knowledge Graph (KG) to automatically generate radiology reports from radiologist's dictation. This paper focuses on KG construction for each organ by extracting information from an existing large corpus of free-text radiology reports. We develop an information extraction pipeline that combines rule-based, pattern-based, and dictionary-based techniques with lexical-semantic features to extract entities and relations. Missing information in short dictation can be accessed from the KGs to generate pathological descriptions and hence the radiology report. Generated pathological descriptions evaluated using semantic similarity metrics, which shows 97% similarity with gold standard pathological descriptions. Also, our analysis shows that our IE module is performing better than the OpenIE tool for the radiology domain. Furthermore, we include a manual qualitative analysis from radiologists, which shows that 80-85% of the generated reports are correctly written, and the remaining are partially correct.",
        "published":1655138814000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.06308v2",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Jun 13, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1345613702,
        "popularmechanics":0.1143564473,
        "scienmag":0.2049584371,
        "technologyreview":0.2192153918,
        "vox":0.1415099564,
        "newscientist":0.1510490221,
        "vice":0.1084417631,
        "statnews":0.3250930074,
        "nytimes":0.1701275974,
        "techcrunch":0.162379092,
        "quartz":0.1266409014,
        "venturebeat":0.2130106128,
        "futurism":0.1558422243,
        "scientificamerican":0.1522103775,
        "wired":0.161808129,
        "popsci":0.1639930441,
        "arstechnica":0.140426758,
        "salon":0.1644613403,
        "washingtonpost":0.1330317891,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.02863v6",
        "predicted_newsworthiness":47.9144978657,
        "title":"PocketNN: Integer-only Training and Inference of Neural Networks via Direct Feedback Alignment and Pocket Activations in Pure C++",
        "summary":"Standard deep learning algorithms are implemented using floating-point real numbers. This presents an obstacle for implementing them on low-end devices which may not have dedicated floating-point units (FPUs). As a result, researchers in tinyML have considered machine learning algorithms that can train and run a deep neural network (DNN) on a low-end device using integer operations only. In this paper we propose PocketNN, a light and self-contained proof-of-concept framework in pure C++ for the training and inference of DNNs using only integers. Unlike other approaches, PocketNN directly operates on integers without requiring any explicit quantization algorithms or customized fixed-point formats. This was made possible by pocket activations, which are a family of activation functions devised for integer-only DNNs, and an emerging DNN training algorithm called direct feedback alignment (DFA). Unlike the standard backpropagation (BP), DFA trains each layer independently, thus avoiding integer overflow which is a key problem when using BP with integer-only operations. We used PocketNN to train some DNNs on two well-known datasets, MNIST and Fashion-MNIST. Our experiments show that the DNNs trained with our PocketNN achieved 96.98% and 87.7% accuracies on MNIST and Fashion-MNIST datasets, respectively. The accuracies are very close to the equivalent DNNs trained using BP with floating-point real number operations, such that accuracy degradations were just 1.02%p and 2.09%p, respectively. Finally, our PocketNN has high compatibility and portability for low-end devices as it is open source and implemented in pure C++ without any dependencies.",
        "published":1641660754000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.02863v6",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jan 08, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1007993712,
        "popularmechanics":0.1597998862,
        "scienmag":0.1591736492,
        "technologyreview":0.2594271872,
        "vox":0.1320054042,
        "newscientist":0.1675921386,
        "vice":0.1299601802,
        "statnews":0.1764533739,
        "nytimes":0.1470151181,
        "techcrunch":0.175900499,
        "quartz":0.126002165,
        "venturebeat":0.2427448525,
        "futurism":0.190314376,
        "scientificamerican":0.1400713366,
        "wired":0.1975128659,
        "popsci":0.1967193785,
        "arstechnica":0.1319117811,
        "salon":0.0948429699,
        "washingtonpost":0.1544211911,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.10938v2",
        "predicted_newsworthiness":44.4718772753,
        "title":"A Multi-level Alignment Training Scheme for Video-and-Language Grounding",
        "summary":"To solve video-and-language grounding tasks, the key is for the network to understand the connection between the two modalities. For a pair of video and language description, their semantic relation is reflected by their encodings' similarity. A good multi-modality encoder should be able to well capture both inputs' semantics and encode them in the shared feature space where embedding distance gets properly translated into their semantic similarity. In this work, we focused on this semantic connection between video and language, and developed a multi-level alignment training scheme to directly shape the encoding process. Global and segment levels of video-language alignment pairs were designed, based on the information similarity ranging from high-level context to fine-grained semantics. The contrastive loss was used to contrast the encodings' similarities between the positive and negative alignment pairs, and to ensure the network is trained in such a way that similar information is encoded closely in the shared feature space while information of different semantics is kept apart. Our multi-level alignment training can be applied to various video-and-language grounding tasks. Together with the task-specific training loss, our framework achieved comparable performance to previous state-of-the-arts on multiple video QA and retrieval datasets.",
        "published":1650664012000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.10938v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Apr 22, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0997633368,
        "popularmechanics":0.1032898111,
        "scienmag":0.0847822352,
        "technologyreview":0.1865206884,
        "vox":0.118900361,
        "newscientist":0.1099159692,
        "vice":0.0885773567,
        "statnews":0.0766008584,
        "nytimes":0.1127008624,
        "techcrunch":0.1223911446,
        "quartz":0.1141062196,
        "venturebeat":0.1724158652,
        "futurism":0.1212595871,
        "scientificamerican":0.0915113713,
        "wired":0.1448389919,
        "popsci":0.1311273302,
        "arstechnica":0.0926396134,
        "salon":0.0765178312,
        "washingtonpost":0.1154426192,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.05340v4",
        "predicted_newsworthiness":50.2314947621,
        "title":"Domain Generalization via Shuffled Style Assembly for Face Anti-Spoofing",
        "summary":"With diverse presentation attacks emerging continually, generalizable face anti-spoofing (FAS) has drawn growing attention. Most existing methods implement domain generalization (DG) on the complete representations. However, different image statistics may have unique properties for the FAS tasks. In this work, we separate the complete representation into content and style ones. A novel Shuffled Style Assembly Network (SSAN) is proposed to extract and reassemble different content and style features for a stylized feature space. Then, to obtain a generalized representation, a contrastive learning strategy is developed to emphasize liveness-related style information while suppress the domain-specific one. Finally, the representations of the correct assemblies are used to distinguish between living and spoofing during the inferring. On the other hand, despite the decent performance, there still exists a gap between academia and industry, due to the difference in data quantity and distribution. Thus, a new large-scale benchmark for FAS is built up to further evaluate the performance of algorithms in reality. Both qualitative and quantitative results on existing and proposed benchmarks demonstrate the effectiveness of our methods. The codes will be available at https:\/\/github.com\/wangzhuo2019\/SSAN.",
        "published":1646916245000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.05340v4",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Mar 10, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0935363551,
        "popularmechanics":0.1470326656,
        "scienmag":0.1202608003,
        "technologyreview":0.2403279547,
        "vox":0.117811639,
        "newscientist":0.1488048646,
        "vice":0.0796566497,
        "statnews":0.1173477876,
        "nytimes":0.1368899731,
        "techcrunch":0.1363810882,
        "quartz":0.1195729258,
        "venturebeat":0.1972106009,
        "futurism":0.1727125896,
        "scientificamerican":0.1277682286,
        "wired":0.167209041,
        "popsci":0.1692160266,
        "arstechnica":0.1381371991,
        "salon":0.0874863215,
        "washingtonpost":0.1645753241,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.06568v1",
        "predicted_newsworthiness":41.6234889728,
        "title":"Online-updated High-order Collaborative Networks for Single Image Deraining",
        "summary":"Single image deraining is an important and challenging task for some downstream artificial intelligence applications such as video surveillance and self-driving systems. Most of the existing deep-learning-based methods constrain the network to generate derained images but few of them explore features from intermediate layers, different levels, and different modules which are beneficial for rain streaks removal. In this paper, we propose a high-order collaborative network with multi-scale compact constraints and a bidirectional scale-content similarity mining module to exploit features from deep networks externally and internally for rain streaks removal. Externally, we design a deraining framework with three sub-networks trained in a collaborative manner, where the bottom network transmits intermediate features to the middle network which also receives shallower rainy features from the top network and sends back features to the bottom network. Internally, we enforce multi-scale compact constraints on the intermediate layers of deep networks to learn useful features via a Laplacian pyramid. Further, we develop a bidirectional scale-content similarity mining module to explore features at different scales in a down-to-up and up-to-down manner. To improve the model performance on real-world images, we propose an online-update learning approach, which uses real-world rainy images to fine-tune the network and update the deraining results in a self-supervised manner. Extensive experiments demonstrate that our proposed method performs favorably against eleven state-of-the-art methods on five public synthetic datasets and one real-world dataset. The source code will be available at \\url{https:\/\/supercong94.wixsite.com\/supercong94}.",
        "published":1644829748000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.06568v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Feb 14, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1061670234,
        "popularmechanics":0.1512915288,
        "scienmag":0.1545865561,
        "technologyreview":0.2263532028,
        "vox":0.1324962934,
        "newscientist":0.1542087887,
        "vice":0.1313251969,
        "statnews":0.1261838422,
        "nytimes":0.1316107434,
        "techcrunch":0.1507211075,
        "quartz":0.1155137668,
        "venturebeat":0.2014083112,
        "futurism":0.1651025827,
        "scientificamerican":0.1358098132,
        "wired":0.1718715403,
        "popsci":0.1784390902,
        "arstechnica":0.1161736472,
        "salon":0.1218193121,
        "washingtonpost":0.1503662366,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.01529v2",
        "predicted_newsworthiness":42.9119961135,
        "title":"Masked Generative Distillation",
        "summary":"Knowledge distillation has been applied to various tasks successfully. The current distillation algorithm usually improves students' performance by imitating the output of the teacher. This paper shows that teachers can also improve students' representation power by guiding students' feature recovery. From this point of view, we propose Masked Generative Distillation (MGD), which is simple: we mask random pixels of the student's feature and force it to generate the teacher's full feature through a simple block. MGD is a truly general feature-based distillation method, which can be utilized on various tasks, including image classification, object detection, semantic segmentation and instance segmentation. We experiment on different models with extensive datasets and the results show that all the students achieve excellent improvements. Notably, we boost ResNet-18 from 69.90% to 71.69% ImageNet top-1 accuracy, RetinaNet with ResNet-50 backbone from 37.4 to 41.0 Boundingbox mAP, SOLO based on ResNet-50 from 33.1 to 36.2 Mask mAP and DeepLabV3 based on ResNet-18 from 73.20 to 76.02 mIoU. Our codes are available at https:\/\/github.com\/yzd-v\/MGD.",
        "published":1651588226000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.01529v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 03, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1070415049,
        "popularmechanics":0.1390212223,
        "scienmag":0.1369348378,
        "technologyreview":0.2625351552,
        "vox":0.1162039191,
        "newscientist":0.1471804321,
        "vice":0.1134368259,
        "statnews":0.1561630958,
        "nytimes":0.1492234755,
        "techcrunch":0.1538156853,
        "quartz":0.1176667937,
        "venturebeat":0.2211042098,
        "futurism":0.1762996658,
        "scientificamerican":0.1274097256,
        "wired":0.165233366,
        "popsci":0.1661681408,
        "arstechnica":0.1096073338,
        "salon":0.098602517,
        "washingtonpost":0.141416855,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.00112v2",
        "predicted_newsworthiness":43.1264463851,
        "title":"GraphWorld: Fake Graphs Bring Real Insights for GNNs",
        "summary":"Despite advances in the field of Graph Neural Networks (GNNs), only a small number (~5) of datasets are currently used to evaluate new models. This continued reliance on a handful of datasets provides minimal insight into the performance differences between models, and is especially challenging for industrial practitioners who are likely to have datasets which look very different from those used as academic benchmarks. In the course of our work on GNN infrastructure and open-source software at Google, we have sought to develop improved benchmarks that are robust, tunable, scalable,and generalizable. In this work we introduce GraphWorld, a novel methodology and system for benchmarking GNN models on an arbitrarily-large population of synthetic graphs for any conceivable GNN task. GraphWorld allows a user to efficiently generate a world with millions of statistically diverse datasets. It is accessible, scalable, and easy to use. GraphWorld can be run on a single machine without specialized hardware, or it can be easily scaled up to run on arbitrary clusters or cloud frameworks. Using GraphWorld, a user has fine-grained control over graph generator parameters, and can benchmark arbitrary GNN models with built-in hyperparameter tuning. We present insights from GraphWorld experiments regarding the performance characteristics of tens of thousands of GNN models over millions of benchmark datasets. We further show that GraphWorld efficiently explores regions of benchmark dataset space uncovered by standard benchmarks, revealing comparisons between models that have not been historically obtainable. Using GraphWorld, we also are able to study in-detail the relationship between graph properties and task performance metrics, which is nearly impossible with the classic collection of real-world benchmarks.",
        "published":1646085602000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.00112v2",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Feb 28, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1239614898,
        "popularmechanics":0.1602800373,
        "scienmag":0.1733164917,
        "technologyreview":0.3325733259,
        "vox":0.2099360416,
        "newscientist":0.1827128057,
        "vice":0.1346874694,
        "statnews":0.2603883393,
        "nytimes":0.1902778506,
        "techcrunch":0.2217784004,
        "quartz":0.1613246741,
        "venturebeat":0.3175180403,
        "futurism":0.2360826655,
        "scientificamerican":0.1505648325,
        "wired":0.2230281736,
        "popsci":0.2253896152,
        "arstechnica":0.1745814981,
        "salon":0.1318889179,
        "washingtonpost":0.2270647958,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.02655v2",
        "predicted_newsworthiness":44.0237326162,
        "title":"Language Models Can See: Plugging Visual Controls in Text Generation",
        "summary":"Generative language models (LMs) such as GPT-2\/3 can be prompted to generate text with remarkable quality. While they are designed for text-prompted generation, it remains an open question how the generation process could be guided by modalities beyond text such as images. In this work, we propose a training-free framework, called MAGIC (iMAge-Guided text generatIon with CLIP), for plugging in visual controls in the generation process and enabling LMs to perform multimodal tasks (e.g., image captioning) in a zero-shot manner. MAGIC is a simple yet efficient plug-and-play framework, which directly combines an off-the-shelf LM (i.e., GPT-2) and an image-text matching model (i.e., CLIP) for image-grounded text generation. During decoding, MAGIC influences the generation of the LM by introducing a CLIP-induced score, called magic score, which regularizes the generated result to be semantically related to a given image while being coherent to the previously generated context. Notably, the proposed decoding scheme does not involve any gradient update operation, therefore being computationally efficient. On the challenging task of zero-shot image captioning, MAGIC outperforms the state-of-the-art method by notable margins with a nearly 27 times decoding speedup. MAGIC is a flexible framework and is theoretically compatible with any text generation tasks that incorporate image grounding. In the experiments, we showcase that it is also capable of performing visually grounded story generation given both an image and a text prompt.",
        "published":1651758978000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.02655v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 05, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1121074427,
        "popularmechanics":0.1227295,
        "scienmag":0.0994305366,
        "technologyreview":0.2251556551,
        "vox":0.1447859574,
        "newscientist":0.1402055653,
        "vice":0.1067696238,
        "statnews":0.1312957259,
        "nytimes":0.1492366375,
        "techcrunch":0.170100315,
        "quartz":0.1365167943,
        "venturebeat":0.2265574825,
        "futurism":0.1579313973,
        "scientificamerican":0.1251466898,
        "wired":0.2040200792,
        "popsci":0.1800850404,
        "arstechnica":0.1078144153,
        "salon":0.1012287344,
        "washingtonpost":0.1434247676,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.07862v1",
        "predicted_newsworthiness":46.6014042791,
        "title":"Unifying Framework for Optimizations in non-boolean Formalisms",
        "summary":"Search-optimization problems are plentiful in scientific and engineering domains. Artificial intelligence has long contributed to the development of search algorithms and declarative programming languages geared towards solving and modeling search-optimization problems. Automated reasoning and knowledge representation are the subfields of AI that are particularly vested in these developments. Many popular automated reasoning paradigms provide users with languages supporting optimization statements. Recall integer linear programming, MaxSAT, optimization satisfiability modulo theory, and (constraint) answer set programming. These paradigms vary significantly in their languages in ways they express quality conditions on computed solutions. Here we propose a unifying framework of so called extended weight systems that eliminates syntactic distinctions between paradigms. They allow us to see essential similarities and differences between optimization statements provided by distinct automated reasoning languages. We also study formal properties of the proposed systems that immediately translate into formal properties of paradigms that can be captured within our framework. Under consideration in Theory and Practice of Logic Programming (TPLP).",
        "published":1655339899000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.07862v1",
        "arxiv_primary_category":"cs.ai",
        "published_hr":"Jun 15, 2022",
        "arxiv_primary_category_hr":"Artificial Intelligence",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0813545296,
        "popularmechanics":0.1149140669,
        "scienmag":0.1284176261,
        "technologyreview":0.2064733298,
        "vox":0.0784627116,
        "newscientist":0.115497496,
        "vice":0.1106638303,
        "statnews":0.1959037216,
        "nytimes":0.1174811811,
        "techcrunch":0.1227068694,
        "quartz":0.0825796883,
        "venturebeat":0.1844165848,
        "futurism":0.1400020604,
        "scientificamerican":0.1065581848,
        "wired":0.1299094064,
        "popsci":0.1342963049,
        "arstechnica":0.1068725194,
        "salon":0.0848941645,
        "washingtonpost":0.090952109,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.04681v1",
        "predicted_newsworthiness":51.1030326863,
        "title":"Enhancing the Robustness, Efficiency, and Diversity of Differentiable Architecture Search",
        "summary":"Differentiable architecture search (DARTS) has attracted much attention due to its simplicity and significant improvement in efficiency. However, the excessive accumulation of the skip connection makes it suffer from long-term weak stability and low robustness. Many works attempt to restrict the accumulation of skip connections by indicators or manual design, however, these methods are susceptible to thresholds and human priors. In this work, we suggest a more subtle and direct approach that removes skip connections from the operation space. Then, by introducing an adaptive channel allocation strategy, we redesign the DARTS framework to automatically refill the skip connections in the evaluation stage, resolving the performance degradation caused by the absence of skip connections. Our method, dubbed Adaptive-Channel-Allocation-DARTS (ACA-DRATS), could eliminate the inconsistency in operation strength and significantly expand the architecture diversity. We continue to explore smaller search space under our framework, and offer a direct search on the entire ImageNet dataset. Experiments show that ACA-DRATS improves the search stability and significantly speeds up DARTS by more than ten times while yielding higher accuracy.",
        "published":1649597136000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.04681v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Apr 10, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0755980154,
        "popularmechanics":0.1431494379,
        "scienmag":0.1322601863,
        "technologyreview":0.2379673414,
        "vox":0.11018074,
        "newscientist":0.126815314,
        "vice":0.1123706614,
        "statnews":0.1539995105,
        "nytimes":0.1257281354,
        "techcrunch":0.159992502,
        "quartz":0.1039625153,
        "venturebeat":0.2238368613,
        "futurism":0.1595731752,
        "scientificamerican":0.1076224837,
        "wired":0.1650473461,
        "popsci":0.1707086854,
        "arstechnica":0.1179837516,
        "salon":0.0710860355,
        "washingtonpost":0.1181216155,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.08096v1",
        "predicted_newsworthiness":43.0333821827,
        "title":"Nonmyopic Distilled Data Association Belief Space Planning Under Budget Constraints",
        "summary":"Autonomous agents operating in perceptually aliased environments should ideally be able to solve the data association problem. Yet, planning for future actions while considering this problem is not trivial. State of the art approaches therefore use multi-modal hypotheses to represent the states of the agent and of the environment. However, explicitly considering all possible data associations, the number of hypotheses grows exponentially with the planning horizon. As such, the corresponding Belief Space Planning problem quickly becomes unsolvable. Moreover, under hard computational budget constraints, some non-negligible hypotheses must eventually be pruned in both planning and inference. Nevertheless, the two processes are generally treated separately and the effect of budget constraints in one process over the other was barely studied. We present a computationally efficient method to solve the nonmyopic Belief Space Planning problem while reasoning about data association. Moreover, we rigorously analyze the effects of budget constraints in both inference and planning.",
        "published":1658041667000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.08096v1",
        "arxiv_primary_category":"cs.ai",
        "published_hr":"Jul 17, 2022",
        "arxiv_primary_category_hr":"Artificial Intelligence",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0946720033,
        "popularmechanics":0.1433268457,
        "scienmag":0.1262713066,
        "technologyreview":0.2221261357,
        "vox":0.1147423026,
        "newscientist":0.1521676132,
        "vice":0.1449132301,
        "statnews":0.1607196324,
        "nytimes":0.1426560222,
        "techcrunch":0.1481974579,
        "quartz":0.1035970548,
        "venturebeat":0.1981728606,
        "futurism":0.1700602175,
        "scientificamerican":0.1354894194,
        "wired":0.1619929105,
        "popsci":0.1731951941,
        "arstechnica":0.1240118285,
        "salon":0.1038044066,
        "washingtonpost":0.1370881919,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.01071v1",
        "predicted_newsworthiness":48.4633566596,
        "title":"You Only Need One Detector: Unified Object Detector for Different Modalities based on Vision Transformers",
        "summary":"Most systems use different models for different modalities, such as one model for processing RGB images and one for depth images. Meanwhile, some recent works discovered that an identical model for one modality can be used for another modality with the help of cross modality transfer learning. In this article, we further find out that by using a vision transformer together with cross\/inter modality transfer learning, a unified detector can achieve better performances when using different modalities as inputs. The unified model is useful as we don't need to maintain separate models or weights for robotics, hence, it is more efficient. One application scenario of our unified system for robotics can be: without any model architecture and model weights updating, robotics can switch smoothly on using RGB camera or both RGB and Depth Sensor during the day time and Depth sensor during the night time . Experiments on SUN RGB-D dataset show: Our unified model is not only efficient, but also has a similar or better performance in terms of mAP50 based on SUNRGBD16 category: compare with the RGB only one, ours is slightly worse (52.3 $\\to$ 51.9). compare with the point cloud only one, we have similar performance (52.7 $\\to$ 52.8); When using the novel inter modality mixing method proposed in this work, our model can achieve a significantly better performance with 3.1 (52.7 $\\to$ 55.8) absolute improvement comparing with the previous best result. Code (including training\/inference logs and model checkpoints) is available: \\url{https:\/\/github.com\/liketheflower\/YONOD.git}",
        "published":1656864064000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.01071v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 03, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0659712168,
        "popularmechanics":0.1708376362,
        "scienmag":0.1112660483,
        "technologyreview":0.2153470776,
        "vox":0.0805150815,
        "newscientist":0.1430558599,
        "vice":0.1193223666,
        "statnews":0.0735412294,
        "nytimes":0.1038492617,
        "techcrunch":0.1585747452,
        "quartz":0.0787702257,
        "venturebeat":0.1957433452,
        "futurism":0.1796239298,
        "scientificamerican":0.1097652324,
        "wired":0.1487817663,
        "popsci":0.2107188227,
        "arstechnica":0.0950513419,
        "salon":0.0607247748,
        "washingtonpost":0.1326359215,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.11016v1",
        "predicted_newsworthiness":44.3989351064,
        "title":"Recency Dropout for Recurrent Recommender Systems",
        "summary":"Recurrent recommender systems have been successful in capturing the temporal dynamics in users' activity trajectories. However, recurrent neural networks (RNNs) are known to have difficulty learning long-term dependencies. As a consequence, RNN-based recommender systems tend to overly focus on short-term user interests. This is referred to as the recency bias, which could negatively affect the long-term user experience as well as the health of the ecosystem. In this paper, we introduce the recency dropout technique, a simple yet effective data augmentation technique to alleviate the recency bias in recurrent recommender systems. We demonstrate the effectiveness of recency dropout in various experimental settings including a simulation study, offline experiments, as well as live experiments on a large-scale industrial recommendation platform.",
        "published":1643212220000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.11016v1",
        "arxiv_primary_category":"cs.ir",
        "published_hr":"Jan 26, 2022",
        "arxiv_primary_category_hr":"Information Retrieval",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1482210094,
        "popularmechanics":0.1539622606,
        "scienmag":0.1795438326,
        "technologyreview":0.2859053505,
        "vox":0.2245185562,
        "newscientist":0.1889799438,
        "vice":0.1329812225,
        "statnews":0.2681141531,
        "nytimes":0.2036571246,
        "techcrunch":0.254598285,
        "quartz":0.1881111633,
        "venturebeat":0.3076910335,
        "futurism":0.2137993484,
        "scientificamerican":0.1746911508,
        "wired":0.2624318992,
        "popsci":0.2568389764,
        "arstechnica":0.1541986976,
        "salon":0.1527683439,
        "washingtonpost":0.2019585062,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.07302v2",
        "predicted_newsworthiness":46.4128142542,
        "title":"Do DNNs trained on Natural Images organize visual features into Gestalts?",
        "summary":"Gestalt psychologists have identified a range of conditions in which humans organize elements of a scene into a group or whole, and these perceptual grouping principles play an important role in scene perception and object identification. More recently, Deep Neural Networks (DNNs) trained on natural images have been proposed as compelling models of human vision based on reports that they perform well on various brain and behavioral benchmarks. Here we compared human and DNNs responses in discrimination judgments that assess a range of Gestalt organization principles. We found that most networks exhibited a moderate degree of Gestalt grouping for some complex stimuli at the last fully connected layer. However, in contrast with human neural data, this sensitivity vanishes at earlier visual processing layers. In a second experiment, by using simple dots configuration patterns, we found that all networks were only weakly sensitive to the grouping properties of proximity, and completely insensitive to orientation and linearity, three principles that have been shown to have a strong and robust effect on humans. Even top-performing models on the behavioral and brain benchmark Brain-Score miss these fundamental properties of human vision. Our overall conclusion is that, even when exhibiting Gestalt grouping, networks trained on 2D images use perceptual principles fundamentally different than humans.",
        "published":1647277571000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.07302v2",
        "arxiv_primary_category":"cs.ai",
        "published_hr":"Mar 14, 2022",
        "arxiv_primary_category_hr":"Artificial Intelligence",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1444320659,
        "popularmechanics":0.1604761325,
        "scienmag":0.2198811387,
        "technologyreview":0.2711806539,
        "vox":0.1387869703,
        "newscientist":0.2099818593,
        "vice":0.189424511,
        "statnews":0.2014022003,
        "nytimes":0.1726358174,
        "techcrunch":0.1530543543,
        "quartz":0.1396485914,
        "venturebeat":0.2195210381,
        "futurism":0.2062737553,
        "scientificamerican":0.2025565861,
        "wired":0.2011659572,
        "popsci":0.2001463377,
        "arstechnica":0.1492915204,
        "salon":0.1463439894,
        "washingtonpost":0.1577888585,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.07945v1",
        "predicted_newsworthiness":50.052320565,
        "title":"Stochastic Attribute Modeling for Face Super-Resolution",
        "summary":"When a high-resolution (HR) image is degraded into a low-resolution (LR) image, the image loses some of the existing information. Consequently, multiple HR images can correspond to the LR image. Most of the existing methods do not consider the uncertainty caused by the stochastic attribute, which can only be probabilistically inferred. Therefore, the predicted HR images are often blurry because the network tries to reflect all possibilities in a single output image. To overcome this limitation, this paper proposes a novel face super-resolution (SR) scheme to take into the uncertainty by stochastic modeling. Specifically, the information in LR images is separately encoded into deterministic and stochastic attributes. Furthermore, an Input Conditional Attribute Predictor is proposed and separately trained to predict the partially alive stochastic attributes from only the LR images. Extensive evaluation shows that the proposed method successfully reduces the uncertainty in the learning process and outperforms the existing state-of-the-art approaches.",
        "published":1657978685000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.07945v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 16, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0775711015,
        "popularmechanics":0.1060779523,
        "scienmag":0.1123797744,
        "technologyreview":0.2028910661,
        "vox":0.0895639573,
        "newscientist":0.1207522872,
        "vice":0.0825535623,
        "statnews":0.1559067298,
        "nytimes":0.1097847419,
        "techcrunch":0.1181823573,
        "quartz":0.0923994263,
        "venturebeat":0.1742040256,
        "futurism":0.1470322711,
        "scientificamerican":0.0948177443,
        "wired":0.1303123412,
        "popsci":0.1466053263,
        "arstechnica":0.0798230228,
        "salon":0.0735722423,
        "washingtonpost":0.1108684019,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.11292v1",
        "predicted_newsworthiness":44.9811097426,
        "title":"Excavation Reinforcement Learning Using Geometric Representation",
        "summary":"Excavation of irregular rigid objects in clutter, such as fragmented rocks and wood blocks, is very challenging due to their complex interaction dynamics and highly variable geometries. In this paper, we adopt reinforcement learning (RL) to tackle this challenge and learn policies to plan for a sequence of excavation trajectories for irregular rigid objects, given point clouds of excavation scenes. Moreover, we separately learn a compact representation of the point cloud on geometric tasks that do not require human labeling. We show that using the representation reduces training time for RL, while achieving similar asymptotic performance compare to an end-to-end RL algorithm. When using a policy trained in simulation directly on a real scene, we show that the policy trained with the representation outperforms end-to-end RL. To our best knowledge, this paper presents the first application of RL to plan a sequence of excavation trajectories of irregular rigid objects in clutter.",
        "published":1643252396000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.11292v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Jan 26, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1085931269,
        "popularmechanics":0.1918099676,
        "scienmag":0.1452432559,
        "technologyreview":0.2464039105,
        "vox":0.1099336898,
        "newscientist":0.1739298912,
        "vice":0.1873381832,
        "statnews":0.1188454271,
        "nytimes":0.1490922229,
        "techcrunch":0.1635716312,
        "quartz":0.1091377167,
        "venturebeat":0.2111631332,
        "futurism":0.2002729831,
        "scientificamerican":0.1431338157,
        "wired":0.1819895407,
        "popsci":0.2059599323,
        "arstechnica":0.1319476131,
        "salon":0.1142582441,
        "washingtonpost":0.1481774391,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.06205v2",
        "predicted_newsworthiness":36.7544874094,
        "title":"kNN-Embed: Locally Smoothed Embedding Mixtures For Multi-interest Candidate Retrieval",
        "summary":"Candidate generation is the first stage in recommendation systems, where a light-weight system is used to retrieve potentially relevant items for an input user. These candidate items are then ranked and pruned in later stages of recommender systems using a more complex ranking model. Since candidate generation is the top of the recommendation funnel, it is important to retrieve a high-recall candidate set to feed into downstream ranking models. A common approach for candidate generation is to leverage approximate nearest neighbor (ANN) search from a single dense query embedding; however, this approach this can yield a low-diversity result set with many near duplicates. As users often have multiple interests, candidate retrieval should ideally return a diverse set of candidates reflective of the user's multiple interests. To this end, we introduce kNN-Embed, a general approach to improving diversity in dense ANN-based retrieval. kNN-Embed represents each user as a smoothed mixture over learned item clusters that represent distinct `interests' of the user. By querying each of a user's mixture component in proportion to their mixture weights, we retrieve a high-diversity set of candidates reflecting elements from each of a user's interests. We experimentally compare kNN-Embed to standard ANN candidate retrieval, and show significant improvements in overall recall and improved diversity across three datasets. Accompanying this work, we open source a large Twitter follow-graph dataset, to spur further research in graph-mining and representation learning for recommender systems.",
        "published":1652373744000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.06205v2",
        "arxiv_primary_category":"cs.ir",
        "published_hr":"May 12, 2022",
        "arxiv_primary_category_hr":"Information Retrieval",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0864450954,
        "popularmechanics":0.1008459507,
        "scienmag":0.0984478419,
        "technologyreview":0.171151433,
        "vox":0.1634291602,
        "newscientist":0.1026676785,
        "vice":0.0742813777,
        "statnews":0.1282175065,
        "nytimes":0.1376806926,
        "techcrunch":0.1713039379,
        "quartz":0.1302132142,
        "venturebeat":0.1893871033,
        "futurism":0.1211221244,
        "scientificamerican":0.0924303949,
        "wired":0.1774662122,
        "popsci":0.1633358506,
        "arstechnica":0.1114612506,
        "salon":0.0770112585,
        "washingtonpost":0.1617220226,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.03674v3",
        "predicted_newsworthiness":46.159028202,
        "title":"PrintsGAN: Synthetic Fingerprint Generator",
        "summary":"A major impediment to researchers working in the area of fingerprint recognition is the lack of publicly available, large-scale, fingerprint datasets. The publicly available datasets that do exist contain very few identities and impressions per finger. This limits research on a number of topics, including e.g., using deep networks to learn fixed length fingerprint embeddings. Therefore, we propose PrintsGAN, a synthetic fingerprint generator capable of generating unique fingerprints along with multiple impressions for a given fingerprint. Using PrintsGAN, we synthesize a database of 525k fingerprints (35K distinct fingers, each with 15 impressions). Next, we show the utility of the PrintsGAN generated dataset by training a deep network to extract a fixed-length embedding from a fingerprint. In particular, an embedding model trained on our synthetic fingerprints and fine-tuned on a small number of publicly available real fingerprints (25K prints from NIST SD302) obtains a TAR of 87.03% @ FAR=0.01% on the NIST SD4 database (a boost from TAR=73.37% when only trained on NIST SD302). Prevailing synthetic fingerprint generation methods do not enable such performance gains due to i) lack of realism or ii) inability to generate multiple impressions per finger. We plan to release our database of synthetic fingerprints to the public.",
        "published":1641853510000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.03674v3",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jan 10, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1287669594,
        "popularmechanics":0.1586974477,
        "scienmag":0.1693069287,
        "technologyreview":0.274468454,
        "vox":0.1514553406,
        "newscientist":0.1821799543,
        "vice":0.147064955,
        "statnews":0.1964510374,
        "nytimes":0.1903251299,
        "techcrunch":0.1850045847,
        "quartz":0.1560002314,
        "venturebeat":0.2394379351,
        "futurism":0.2093209531,
        "scientificamerican":0.1563234526,
        "wired":0.195391515,
        "popsci":0.1949244862,
        "arstechnica":0.1720183779,
        "salon":0.1287007573,
        "washingtonpost":0.1878989685,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.02437v1",
        "predicted_newsworthiness":36.9808999702,
        "title":"Complementary Bi-directional Feature Compression for Indoor 360\u00b0 Semantic Segmentation with Self-distillation",
        "summary":"Recently, horizontal representation-based panoramic semantic segmentation approaches outperform projection-based solutions, because the distortions can be effectively removed by compressing the spherical data in the vertical direction. However, these methods ignore the distortion distribution prior and are limited to unbalanced receptive fields, e.g., the receptive fields are sufficient in the vertical direction and insufficient in the horizontal direction. Differently, a vertical representation compressed in another direction can offer implicit distortion prior and enlarge horizontal receptive fields. In this paper, we combine the two different representations and propose a novel 360{\\deg} semantic segmentation solution from a complementary perspective. Our network comprises three modules: a feature extraction module, a bi-directional compression module, and an ensemble decoding module. First, we extract multi-scale features from a panorama. Then, a bi-directional compression module is designed to compress features into two complementary low-dimensional representations, which provide content perception and distortion prior. Furthermore, to facilitate the fusion of bi-directional features, we design a unique self distillation strategy in the ensemble decoding module to enhance the interaction of different features and further improve the performance. Experimental results show that our approach outperforms the state-of-the-art solutions with at least 10\\% improvement on quantitative evaluations while displaying the best performance on visual appearance.",
        "published":1657083954000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.02437v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 06, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.086183456,
        "popularmechanics":0.1427837735,
        "scienmag":0.1005242222,
        "technologyreview":0.1824813922,
        "vox":0.1134264914,
        "newscientist":0.1226455962,
        "vice":0.112208524,
        "statnews":0.0911408007,
        "nytimes":0.1094928064,
        "techcrunch":0.1593764173,
        "quartz":0.1053189175,
        "venturebeat":0.1988592671,
        "futurism":0.148465471,
        "scientificamerican":0.1056921457,
        "wired":0.1662495208,
        "popsci":0.1808421533,
        "arstechnica":0.0931997003,
        "salon":0.0863636688,
        "washingtonpost":0.1349927638,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.05027v1",
        "predicted_newsworthiness":43.1336527369,
        "title":"Unsupervised Semantic Segmentation with Self-supervised Object-centric Representations",
        "summary":"In this paper, we show that recent advances in self-supervised feature learning enable unsupervised object discovery and semantic segmentation with a performance that matches the state of the field on supervised semantic segmentation 10 years ago. We propose a methodology based on unsupervised saliency masks and self-supervised feature clustering to kickstart object discovery followed by training a semantic segmentation network on pseudo-labels to bootstrap the system on images with multiple objects. We present results on PASCAL VOC that go far beyond the current state of the art (47.3 mIoU), and we report for the first time results on MS COCO for the whole set of 81 classes: our method discovers 34 categories with more than $20\\%$ IoU, while obtaining an average IoU of 19.6 for all 81 categories.",
        "published":1657560504000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.05027v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 11, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0769773568,
        "popularmechanics":0.1377130415,
        "scienmag":0.1174269385,
        "technologyreview":0.2146161341,
        "vox":0.1073568517,
        "newscientist":0.1434283937,
        "vice":0.1154937899,
        "statnews":0.1137544026,
        "nytimes":0.123139354,
        "techcrunch":0.1520770894,
        "quartz":0.1055996652,
        "venturebeat":0.2030331195,
        "futurism":0.1573280325,
        "scientificamerican":0.112437359,
        "wired":0.160385784,
        "popsci":0.1624619141,
        "arstechnica":0.0930489701,
        "salon":0.0702456595,
        "washingtonpost":0.131576226,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.13876v1",
        "predicted_newsworthiness":47.4650945854,
        "title":"PMC-Patients: A Large-scale Dataset of Patient Notes and Relations Extracted from Case Reports in PubMed Central",
        "summary":"We present PMC-Patients, a dataset consisting of 167k patient notes with 3.1M relevant article annotations and 293k similar patient annotations. The patient notes are extracted by identifying certain sections from case reports in PubMed Central, and those with at least CC BY-NC-SA license are re-distributed. Patient-article relevance and patient-patient similarity are defined by citation relationships in PubMed. We also perform four tasks with PMC-Patients to demonstrate its utility, including Patient Note Recognition (PNR), Patient-Patient Similarity (PPS), Patient-Patient Retrieval (PPR), and Patient-Article Retrieval (PAR). In summary, PMC-Patients provides the largest-scale patient notes with high quality, diverse conditions, easy access, and rich annotations.",
        "published":1646061873000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.13876v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Feb 28, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1963290536,
        "popularmechanics":0.1137335381,
        "scienmag":0.3196159191,
        "technologyreview":0.2430237536,
        "vox":0.2145077323,
        "newscientist":0.2186732042,
        "vice":0.1510426022,
        "statnews":0.3855558119,
        "nytimes":0.2345760246,
        "techcrunch":0.1618848105,
        "quartz":0.1578606362,
        "venturebeat":0.1942348132,
        "futurism":0.211818631,
        "scientificamerican":0.2411278741,
        "wired":0.1635670341,
        "popsci":0.1690877488,
        "arstechnica":0.2349619333,
        "salon":0.2611616696,
        "washingtonpost":0.1792486978,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.08728v1",
        "predicted_newsworthiness":39.6343094199,
        "title":"RandomMix: A mixed sample data augmentation method with multiple mixed modes",
        "summary":"Data augmentation is a very practical technique that can be used to improve the generalization ability of neural networks and prevent overfitting. Recently, mixed sample data augmentation has received a lot of attention and achieved great success. In order to enhance the performance of mixed sample data augmentation, a series of recent works are devoted to obtaining and analyzing the salient regions of the image, and using the saliency area to guide the image mixing. However, obtaining the salient information of an image requires a lot of extra calculations. Different from improving performance through saliency analysis, our proposed method RandomMix mainly increases the diversity of the mixed sample to enhance the generalization ability and performance of neural networks. Moreover, RandomMix can improve the robustness of the model, does not require too much additional calculation, and is easy to insert into the training pipeline. Finally, experiments on the CIFAR-10\/100, Tiny-ImageNet, ImageNet, and Google Speech Commands datasets demonstrate that RandomMix achieves better performance than other state-of-the-art mixed sample data augmentation methods.",
        "published":1652851896000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.08728v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 18, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.087711931,
        "popularmechanics":0.1266222834,
        "scienmag":0.1235784669,
        "technologyreview":0.2344722782,
        "vox":0.113406133,
        "newscientist":0.1393120324,
        "vice":0.0945495276,
        "statnews":0.1569754855,
        "nytimes":0.1227492175,
        "techcrunch":0.1597999436,
        "quartz":0.1078053077,
        "venturebeat":0.2208039492,
        "futurism":0.1657383671,
        "scientificamerican":0.1218983318,
        "wired":0.1579588099,
        "popsci":0.1818885811,
        "arstechnica":0.0982108428,
        "salon":0.0847742615,
        "washingtonpost":0.1349482046,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.02791v1",
        "predicted_newsworthiness":58.6858678381,
        "title":"SFMGNet: A Physics-based Neural Network To Predict Pedestrian Trajectories",
        "summary":"Autonomous robots and vehicles are expected to soon become an integral part of our environment. Unsatisfactory issues regarding interaction with existing road users, performance in mixed-traffic areas and lack of interpretable behavior remain key obstacles. To address these, we present a physics-based neural network, based on a hybrid approach combining a social force model extended by group force (SFMG) with Multi-Layer Perceptron (MLP) to predict pedestrian trajectories considering its interaction with static obstacles, other pedestrians and pedestrian groups. We quantitatively and qualitatively evaluate the model with respect to realistic prediction, prediction performance and prediction \"interpretability\". Initial results suggest, the model even when solely trained on a synthetic dataset, can predict realistic and interpretable trajectories with better than state-of-the-art accuracy.",
        "published":1644159489000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.02791v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Feb 06, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1531088147,
        "popularmechanics":0.2001680649,
        "scienmag":0.2065233782,
        "technologyreview":0.2919465514,
        "vox":0.1663454914,
        "newscientist":0.2016455836,
        "vice":0.1742682671,
        "statnews":0.2027548417,
        "nytimes":0.1895486567,
        "techcrunch":0.2075642478,
        "quartz":0.1563344798,
        "venturebeat":0.2528762879,
        "futurism":0.2562399201,
        "scientificamerican":0.2059895887,
        "wired":0.2379864509,
        "popsci":0.2490946164,
        "arstechnica":0.1575012903,
        "salon":0.1504282292,
        "washingtonpost":0.1956749715,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.04735v1",
        "predicted_newsworthiness":52.3164748836,
        "title":"Reducing Model Jitter: Stable Re-training of Semantic Parsers in Production Environments",
        "summary":"Retraining modern deep learning systems can lead to variations in model performance even when trained using the same data and hyper-parameters by simply using different random seeds. We call this phenomenon model jitter. This issue is often exacerbated in production settings, where models are retrained on noisy data. In this work we tackle the problem of stable retraining with a focus on conversational semantic parsers. We first quantify the model jitter problem by introducing the model agreement metric and showing the variation with dataset noise and model sizes. We then demonstrate the effectiveness of various jitter reduction techniques such as ensembling and distillation. Lastly, we discuss practical trade-offs between such techniques and show that co-distillation provides a sweet spot in terms of jitter reduction for semantic parsing systems with only a modest increase in resource usage.",
        "published":1649613475000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.04735v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Apr 10, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0888025007,
        "popularmechanics":0.1410963638,
        "scienmag":0.1115139276,
        "technologyreview":0.2336026345,
        "vox":0.1560060723,
        "newscientist":0.1267140925,
        "vice":0.1093101752,
        "statnews":0.1645268001,
        "nytimes":0.1347083504,
        "techcrunch":0.1784870354,
        "quartz":0.1275480852,
        "venturebeat":0.2449938826,
        "futurism":0.161576826,
        "scientificamerican":0.1238800335,
        "wired":0.1830674048,
        "popsci":0.1714347726,
        "arstechnica":0.1371346517,
        "salon":0.0952350784,
        "washingtonpost":0.1370802058,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.08807v1",
        "predicted_newsworthiness":35.7211551416,
        "title":"Multi-level Cross-view Contrastive Learning for Knowledge-aware Recommender System",
        "summary":"Knowledge graph (KG) plays an increasingly important role in recommender systems. Recently, graph neural networks (GNNs) based model has gradually become the theme of knowledge-aware recommendation (KGR). However, there is a natural deficiency for GNN-based KGR models, that is, the sparse supervised signal problem, which may make their actual performance drop to some extent. Inspired by the recent success of contrastive learning in mining supervised signals from data itself, in this paper, we focus on exploring the contrastive learning in KG-aware recommendation and propose a novel multi-level cross-view contrastive learning mechanism, named MCCLK. Different from traditional contrastive learning methods which generate two graph views by uniform data augmentation schemes such as corruption or dropping, we comprehensively consider three different graph views for KG-aware recommendation, including global-level structural view, local-level collaborative and semantic views. Specifically, we consider the user-item graph as a collaborative view, the item-entity graph as a semantic view, and the user-item-entity graph as a structural view. MCCLK hence performs contrastive learning across three views on both local and global levels, mining comprehensive graph feature and structure information in a self-supervised manner. Besides, in semantic view, a k-Nearest-Neighbor (kNN) item-item semantic graph construction module is proposed, to capture the important item-item semantic relation which is usually ignored by previous work. Extensive experiments conducted on three benchmark datasets show the superior performance of our proposed method over the state-of-the-arts. The implementations are available at: https:\/\/github.com\/CCIIPLab\/MCCLK.",
        "published":1650366450000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.08807v1",
        "arxiv_primary_category":"cs.ir",
        "published_hr":"Apr 19, 2022",
        "arxiv_primary_category_hr":"Information Retrieval",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0799400483,
        "popularmechanics":0.0941300089,
        "scienmag":0.11997584,
        "technologyreview":0.1724430761,
        "vox":0.1333532445,
        "newscientist":0.105292925,
        "vice":0.0832795578,
        "statnews":0.1639687233,
        "nytimes":0.1173678193,
        "techcrunch":0.1538233686,
        "quartz":0.1129630398,
        "venturebeat":0.1890863085,
        "futurism":0.115068488,
        "scientificamerican":0.0946261539,
        "wired":0.1500999799,
        "popsci":0.1469667201,
        "arstechnica":0.0940724977,
        "salon":0.0798176535,
        "washingtonpost":0.1290574044,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.15936v1",
        "predicted_newsworthiness":35.2169320703,
        "title":"Skeleton-based Action Recognition via Temporal-Channel Aggregation",
        "summary":"Skeleton-based action recognition methods are limited by the semantic extraction of spatio-temporal skeletal maps. However, current methods have difficulty in effectively combining features from both temporal and spatial graph dimensions and tend to be thick on one side and thin on the other. In this paper, we propose a Temporal-Channel Aggregation Graph Convolutional Networks (TCA-GCN) to learn spatial and temporal topologies dynamically and efficiently aggregate topological features in different temporal and channel dimensions for skeleton-based action recognition. We use the Temporal Aggregation module to learn temporal dimensional features and the Channel Aggregation module to efficiently combine spatial dynamic topological features learned using Channel-wise with temporal dynamic topological features. In addition, we extract multi-scale skeletal features on temporal modeling and fuse them with priori skeletal knowledge with an attention mechanism. Extensive experiments show that our model results outperform state-of-the-art methods on the NTU RGB+D, NTU RGB+D 120, and NW-UCLA datasets.",
        "published":1654014510000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.15936v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 31, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0799513013,
        "popularmechanics":0.108618857,
        "scienmag":0.1046945179,
        "technologyreview":0.1257154785,
        "vox":0.0854252557,
        "newscientist":0.1149008662,
        "vice":0.1127251479,
        "statnews":0.0666103603,
        "nytimes":0.1060735378,
        "techcrunch":0.1044305717,
        "quartz":0.0844116101,
        "venturebeat":0.1289660545,
        "futurism":0.1033964163,
        "scientificamerican":0.105116544,
        "wired":0.1241278495,
        "popsci":0.1208595393,
        "arstechnica":0.0904299396,
        "salon":0.0676228602,
        "washingtonpost":0.1064532842,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.06014v2",
        "predicted_newsworthiness":48.7565293888,
        "title":"Multi-direction and Multi-scale Pyramid in Transformer for Video-based Pedestrian Retrieval",
        "summary":"In video surveillance, pedestrian retrieval (also called person re-identification) is a critical task. This task aims to retrieve the pedestrian of interest from non-overlapping cameras. Recently, transformer-based models have achieved significant progress for this task. However, these models still suffer from ignoring fine-grained, part-informed information. This paper proposes a multi-direction and multi-scale Pyramid in Transformer (PiT) to solve this problem. In transformer-based architecture, each pedestrian image is split into many patches. Then, these patches are fed to transformer layers to obtain the feature representation of this image. To explore the fine-grained information, this paper proposes to apply vertical division and horizontal division on these patches to generate different-direction human parts. These parts provide more fine-grained information. To fuse multi-scale feature representation, this paper presents a pyramid structure containing global-level information and many pieces of local-level information from different scales. The feature pyramids of all the pedestrian images from the same video are fused to form the final multi-direction and multi-scale feature representation. Experimental results on two challenging video-based benchmarks, MARS and iLIDS-VID, show the proposed PiT achieves state-of-the-art performance. Extensive ablation studies demonstrate the superiority of the proposed pyramid structure. The code is available at https:\/\/git.openi.org.cn\/zangxh\/PiT.git.",
        "published":1644654167000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.06014v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Feb 12, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0974270226,
        "popularmechanics":0.1480943207,
        "scienmag":0.1091683035,
        "technologyreview":0.2111116072,
        "vox":0.1088572855,
        "newscientist":0.1380386292,
        "vice":0.1296076652,
        "statnews":0.0685333116,
        "nytimes":0.1275200969,
        "techcrunch":0.1438243318,
        "quartz":0.1144576486,
        "venturebeat":0.1842232313,
        "futurism":0.165741269,
        "scientificamerican":0.1099934622,
        "wired":0.1573928658,
        "popsci":0.1859079191,
        "arstechnica":0.1127552027,
        "salon":0.0740254444,
        "washingtonpost":0.1572389001,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.07649v2",
        "predicted_newsworthiness":49.0756232933,
        "title":"Generalizing to Evolving Domains with Latent Structure-Aware Sequential Autoencoder",
        "summary":"Domain generalization aims to improve the generalization capability of machine learning systems to out-of-distribution (OOD) data. Existing domain generalization techniques embark upon stationary and discrete environments to tackle the generalization issue caused by OOD data. However, many real-world tasks in non-stationary environments (e.g. self-driven car system, sensor measures) involve more complex and continuously evolving domain drift, which raises new challenges for the problem of domain generalization. In this paper, we formulate the aforementioned setting as the problem of evolving domain generalization. Specifically, we propose to introduce a probabilistic framework called Latent Structure-aware Sequential Autoencoder (LSSAE) to tackle the problem of evolving domain generalization via exploring the underlying continuous structure in the latent space of deep neural networks, where we aim to identify two major factors namely covariate shift and concept shift accounting for distribution shift in non-stationary environments. Experimental results on both synthetic and real-world datasets show that LSSAE can lead to superior performances based on the evolving domain generalization setting.",
        "published":1652706689000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.07649v2",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"May 16, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.092321341,
        "popularmechanics":0.1239176382,
        "scienmag":0.1378742287,
        "technologyreview":0.2503486126,
        "vox":0.123859362,
        "newscientist":0.1333687647,
        "vice":0.116837693,
        "statnews":0.193426135,
        "nytimes":0.1284673644,
        "techcrunch":0.1583199039,
        "quartz":0.1098500716,
        "venturebeat":0.2298420918,
        "futurism":0.1725048587,
        "scientificamerican":0.1204985616,
        "wired":0.159036966,
        "popsci":0.1604391777,
        "arstechnica":0.1037452634,
        "salon":0.0930953908,
        "washingtonpost":0.120771957,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.00795v1",
        "predicted_newsworthiness":74.5865964058,
        "title":"Disaster Tweets Classification using BERT-Based Language Model",
        "summary":"Social networking services have became an important communication channel in time of emergency. The aim of this study is to create a machine learning language model that is able to investigate if a person or area was in danger or not. The ubiquitousness of smartphones enables people to announce an emergency they are observing in real-time. Because of this, more agencies are interested in programmatically monitoring Twitter (i.e. disaster relief organizations and news agencies). Design a language model that is able to understand and acknowledge when a disaster is happening based on the social network posts will become more and more necessary over time.",
        "published":1643624729000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.00795v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Jan 31, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.213527995,
        "popularmechanics":0.1735370069,
        "scienmag":0.1965358467,
        "technologyreview":0.2848342615,
        "vox":0.2636831268,
        "newscientist":0.2047957687,
        "vice":0.1630828202,
        "statnews":0.2467552719,
        "nytimes":0.2335283816,
        "techcrunch":0.229040349,
        "quartz":0.2223209683,
        "venturebeat":0.2659799789,
        "futurism":0.2134520128,
        "scientificamerican":0.1899007956,
        "wired":0.2563314688,
        "popsci":0.2421994539,
        "arstechnica":0.2186259274,
        "salon":0.2179556371,
        "washingtonpost":0.2818749374,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.01508v1",
        "predicted_newsworthiness":45.9281411664,
        "title":"Compact Neural Networks via Stacking Designed Basic Units",
        "summary":"Unstructured pruning has the limitation of dealing with the sparse and irregular weights. By contrast, structured pruning can help eliminate this drawback but it requires complex criterion to determine which components to be pruned. To this end, this paper presents a new method termed TissueNet, which directly constructs compact neural networks with fewer weight parameters by independently stacking designed basic units, without requiring additional judgement criteria anymore. Given the basic units of various architectures, they are combined and stacked in a certain form to build up compact neural networks. We formulate TissueNet in diverse popular backbones for comparison with the state-of-the-art pruning methods on different benchmark datasets. Moreover, two new metrics are proposed to evaluate compression performance. Experiment results show that TissueNet can achieve comparable classification accuracy while saving up to around 80% FLOPs and 89.7% parameters. That is, stacking basic units provides a new promising way for network compression.",
        "published":1651586689000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.01508v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 03, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0795737478,
        "popularmechanics":0.1413586292,
        "scienmag":0.1339144861,
        "technologyreview":0.2086702754,
        "vox":0.1005900409,
        "newscientist":0.1287833937,
        "vice":0.0954085457,
        "statnews":0.1591086916,
        "nytimes":0.1084734778,
        "techcrunch":0.1457605292,
        "quartz":0.0987348063,
        "venturebeat":0.1999229148,
        "futurism":0.1495701322,
        "scientificamerican":0.1054824466,
        "wired":0.1401278662,
        "popsci":0.1614897194,
        "arstechnica":0.1192601919,
        "salon":0.0738188471,
        "washingtonpost":0.1300060557,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.06675v2",
        "predicted_newsworthiness":69.7164553801,
        "title":"Can Machines Help Us Answering Question 16 in Datasheets, and In Turn Reflecting on Inappropriate Content?",
        "summary":"Large datasets underlying much of current machine learning raise serious issues concerning inappropriate content such as offensive, insulting, threatening, or might otherwise cause anxiety. This calls for increased dataset documentation, e.g., using datasheets. They, among other topics, encourage to reflect on the composition of the datasets. So far, this documentation, however, is done manually and therefore can be tedious and error-prone, especially for large image datasets. Here we ask the arguably \"circular\" question of whether a machine can help us reflect on inappropriate content, answering Question 16 in Datasheets. To this end, we propose to use the information stored in pre-trained transformer models to assist us in the documentation process. Specifically, prompt-tuning based on a dataset of socio-moral values steers CLIP to identify potentially inappropriate content, therefore reducing human labor. We then document the inappropriate images found using word clouds, based on captions generated using a vision-language model. The documentations of two popular, large-scale computer vision datasets -- ImageNet and OpenImages -- produced this way suggest that machines can indeed help dataset creators to answer Question 16 on inappropriate image content.",
        "published":1644843631000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.06675v2",
        "arxiv_primary_category":"cs.ai",
        "published_hr":"Feb 14, 2022",
        "arxiv_primary_category_hr":"Artificial Intelligence",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2362086145,
        "popularmechanics":0.1710275243,
        "scienmag":0.2094132013,
        "technologyreview":0.4003825339,
        "vox":0.2996830668,
        "newscientist":0.2566307468,
        "vice":0.1646369351,
        "statnews":0.3630000607,
        "nytimes":0.2789814121,
        "techcrunch":0.2778679442,
        "quartz":0.2513924888,
        "venturebeat":0.3616500749,
        "futurism":0.3005716274,
        "scientificamerican":0.2157334707,
        "wired":0.3252414878,
        "popsci":0.2894530914,
        "arstechnica":0.2595144467,
        "salon":0.228106778,
        "washingtonpost":0.3335893921,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.07510v1",
        "predicted_newsworthiness":64.7498409005,
        "title":"Crowdsourced Hypothesis Generation and their Verification: A Case Study on Sleep Quality Improvement",
        "summary":"A clinical study is often necessary for exploring important research questions; however, this approach is sometimes time and money consuming. Another extreme approach, which is to collect and aggregate opinions from crowds, provides a result drawn from the crowds' past experiences and knowledge. To explore a solution that takes advantage of both the rigid clinical approach and the crowds' opinion-based approach, we design a framework that exploits crowdsourcing as a part of the research process, whereby crowd workers serve as if they were a scientist conducting a \"pseudo\" prospective study. This study evaluates the feasibility of the proposed framework to generate hypotheses on a specified topic and verify them in the real world by employing many crowd workers. The framework comprises two phases of crowd-based workflow. In Phase 1 - the hypothesis generation and ranking phase - our system asks workers two types of questions to collect a number of hypotheses and rank them. In Phase 2 - the hypothesis verification phase - the system asks workers to verify the top-ranked hypotheses from Phase 1 by implementing one of them in real life. Through experiments, we explore the potential and limitations of the framework to generate and evaluate hypotheses about the factors that result in a good night's sleep. Our results on significant sleep quality improvement show the basic feasibility of our framework, suggesting that crowd-based research is compatible with experts' knowledge in a certain domain.",
        "published":1652690619000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.07510v1",
        "arxiv_primary_category":"cs.hc",
        "published_hr":"May 16, 2022",
        "arxiv_primary_category_hr":"Human-Computer Interaction",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2376569694,
        "popularmechanics":0.1983879104,
        "scienmag":0.283027345,
        "technologyreview":0.3169546014,
        "vox":0.2525159403,
        "newscientist":0.2659697686,
        "vice":0.2241285077,
        "statnews":0.382638433,
        "nytimes":0.2759196369,
        "techcrunch":0.2671910345,
        "quartz":0.2369469207,
        "venturebeat":0.2884459026,
        "futurism":0.2683326351,
        "scientificamerican":0.2710348929,
        "wired":0.2642394554,
        "popsci":0.2673587121,
        "arstechnica":0.2296947727,
        "salon":0.2670584062,
        "washingtonpost":0.2595692947,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.10086v1",
        "predicted_newsworthiness":36.93027176,
        "title":"OTExtSum: Extractive Text Summarisation with Optimal Transport",
        "summary":"Extractive text summarisation aims to select salient sentences from a document to form a short yet informative summary. While learning-based methods have achieved promising results, they have several limitations, such as dependence on expensive training and lack of interpretability. Therefore, in this paper, we propose a novel non-learning-based method by for the first time formulating text summarisation as an Optimal Transport (OT) problem, namely Optimal Transport Extractive Summariser (OTExtSum). Optimal sentence extraction is conceptualised as obtaining an optimal summary that minimises the transportation cost to a given document regarding their semantic distributions. Such a cost is defined by the Wasserstein distance and used to measure the summary's semantic coverage of the original document. Comprehensive experiments on four challenging and widely used datasets - MultiNews, PubMed, BillSum, and CNN\/DM demonstrate that our proposed method outperforms the state-of-the-art non-learning-based methods and several recent learning-based methods in terms of the ROUGE metric.",
        "published":1650547534000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.10086v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Apr 21, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1198103243,
        "popularmechanics":0.1038549633,
        "scienmag":0.1381854974,
        "technologyreview":0.1872447144,
        "vox":0.1473497414,
        "newscientist":0.1293604725,
        "vice":0.1030627051,
        "statnews":0.1740399246,
        "nytimes":0.1448682168,
        "techcrunch":0.1448770557,
        "quartz":0.1278212666,
        "venturebeat":0.186223667,
        "futurism":0.1380883171,
        "scientificamerican":0.142388721,
        "wired":0.1541306634,
        "popsci":0.1444639828,
        "arstechnica":0.1206105598,
        "salon":0.1241878689,
        "washingtonpost":0.1369460192,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.02170v2",
        "predicted_newsworthiness":46.4462089473,
        "title":"Efficient Few-Shot Fine-Tuning for Opinion Summarization",
        "summary":"Abstractive summarization models are typically pre-trained on large amounts of generic texts, then fine-tuned on tens or hundreds of thousands of annotated samples. However, in opinion summarization, large annotated datasets of reviews paired with reference summaries are not available and would be expensive to create. This calls for fine-tuning methods robust to overfitting on small datasets. In addition, generically pre-trained models are often not accustomed to the specifics of customer reviews and, after fine-tuning, yield summaries with disfluencies and semantic mistakes. To address these problems, we utilize an efficient few-shot method based on adapters which, as we show, can easily store in-domain knowledge. Instead of fine-tuning the entire model, we add adapters and pre-train them in a task-specific way on a large corpus of unannotated customer reviews, using held-out reviews as pseudo summaries. Then, fine-tune the adapters on the small available human-annotated dataset. We show that this self-supervised adapter pre-training improves summary quality over standard fine-tuning by 2.0 and 1.3 ROUGE-L points on the Amazon and Yelp datasets, respectively. Finally, for summary personalization, we condition on aspect keyword queries, automatically created from generic datasets. In the same vein, we pre-train the adapters in a query-based manner on customer reviews and then fine-tune them on annotated datasets. This results in better-organized summary content reflected in improved coherence and fewer redundancies.",
        "published":1651682317000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.02170v2",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"May 04, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1183518427,
        "popularmechanics":0.111976399,
        "scienmag":0.1183323234,
        "technologyreview":0.2052653625,
        "vox":0.1861916131,
        "newscientist":0.123828785,
        "vice":0.0806789834,
        "statnews":0.173147044,
        "nytimes":0.154330128,
        "techcrunch":0.1800614373,
        "quartz":0.1512972073,
        "venturebeat":0.2246570028,
        "futurism":0.1444926211,
        "scientificamerican":0.1227167733,
        "wired":0.1856906787,
        "popsci":0.1719075874,
        "arstechnica":0.1274539909,
        "salon":0.1182721197,
        "washingtonpost":0.1623296084,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.06318v1",
        "predicted_newsworthiness":34.9777994966,
        "title":"Deformable VisTR: Spatio temporal deformable attention for video instance segmentation",
        "summary":"Video instance segmentation (VIS) task requires classifying, segmenting, and tracking object instances over all frames in a video clip. Recently, VisTR has been proposed as end-to-end transformer-based VIS framework, while demonstrating state-of-the-art performance. However, VisTR is slow to converge during training, requiring around 1000 GPU hours due to the high computational cost of its transformer attention module. To improve the training efficiency, we propose Deformable VisTR, leveraging spatio-temporal deformable attention module that only attends to a small fixed set of key spatio-temporal sampling points around a reference point. This enables Deformable VisTR to achieve linear computation in the size of spatio-temporal feature maps. Moreover, it can achieve on par performance as the original VisTR with 10$\\times$ less GPU training hours. We validate the effectiveness of our method on the Youtube-VIS benchmark. Code is available at https:\/\/github.com\/skrya\/DefVIS.",
        "published":1647052034000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.06318v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Mar 11, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0936574249,
        "popularmechanics":0.1400818939,
        "scienmag":0.1109030131,
        "technologyreview":0.1839720434,
        "vox":0.1163600169,
        "newscientist":0.1337457089,
        "vice":0.1175809195,
        "statnews":0.0905479026,
        "nytimes":0.1197101308,
        "techcrunch":0.149299105,
        "quartz":0.1090572006,
        "venturebeat":0.1875931193,
        "futurism":0.1505852483,
        "scientificamerican":0.1128900846,
        "wired":0.1607229536,
        "popsci":0.158922458,
        "arstechnica":0.1010088616,
        "salon":0.0963920215,
        "washingtonpost":0.1346423124,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.04398v1",
        "predicted_newsworthiness":40.9924132915,
        "title":"Self-supervised Learning with Local Contrastive Loss for Detection and Semantic Segmentation",
        "summary":"We present a self-supervised learning (SSL) method suitable for semi-global tasks such as object detection and semantic segmentation. We enforce local consistency between self-learned features, representing corresponding image locations of transformed versions of the same image, by minimizing a pixel-level local contrastive (LC) loss during training. LC-loss can be added to existing self-supervised learning methods with minimal overhead. We evaluate our SSL approach on two downstream tasks -- object detection and semantic segmentation, using COCO, PASCAL VOC, and CityScapes datasets. Our method outperforms the existing state-of-the-art SSL approaches by 1.9% on COCO object detection, 1.4% on PASCAL VOC detection, and 0.6% on CityScapes segmentation.",
        "published":1657435995000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.04398v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 10, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0933568448,
        "popularmechanics":0.1307900861,
        "scienmag":0.106744412,
        "technologyreview":0.2162056381,
        "vox":0.1125251651,
        "newscientist":0.130185794,
        "vice":0.1023853524,
        "statnews":0.0872718508,
        "nytimes":0.1234243034,
        "techcrunch":0.1449530267,
        "quartz":0.115308829,
        "venturebeat":0.1918973778,
        "futurism":0.1595296398,
        "scientificamerican":0.1107209137,
        "wired":0.1642697575,
        "popsci":0.1623749455,
        "arstechnica":0.0954774676,
        "salon":0.0960538106,
        "washingtonpost":0.1327583996,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.08891v1",
        "predicted_newsworthiness":56.7421113014,
        "title":"A Scalable Workflow to Build Machine Learning Classifiers with Clinician-in-the-Loop to Identify Patients in Specific Diseases",
        "summary":"Clinicians may rely on medical coding systems such as International Classification of Diseases (ICD) to identify patients with diseases from Electronic Health Records (EHRs). However, due to the lack of detail and specificity as well as a probability of miscoding, recent studies suggest the ICD codes often cannot characterise patients accurately for specific diseases in real clinical practice, and as a result, using them to find patients for studies or trials can result in high failure rates and missing out on uncoded patients. Manual inspection of all patients at scale is not feasible as it is highly costly and slow. This paper proposes a scalable workflow which leverages both structured data and unstructured textual notes from EHRs with techniques including NLP, AutoML and Clinician-in-the-Loop mechanism to build machine learning classifiers to identify patients at scale with given diseases, especially those who might currently be miscoded or missed by ICD codes. Case studies in the MIMIC-III dataset were conducted where the proposed workflow demonstrates a higher classification performance in terms of F1 scores compared to simply using ICD codes on gold testing subset to identify patients with Ovarian Cancer (0.901 vs 0.814), Lung Cancer (0.859 vs 0.828), Cancer Cachexia (0.862 vs 0.650), and Lupus Nephritis (0.959 vs 0.855). Also, the proposed workflow that leverages unstructured notes consistently outperforms the baseline that uses structured data only with an increase of F1 (Ovarian Cancer 0.901 vs 0.719, Lung Cancer 0.859 vs 0.787, Cancer Cachexia 0.862 vs 0.838 and Lupus Nephritis 0.959 vs 0.785). Experiments on the large testing set also demonstrate the proposed workflow can find more patients who are miscoded or missed by ICD codes. Moreover, interpretability studies are also conducted to clinically validate the top impact features of the classifiers.",
        "published":1652876647000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.08891v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"May 18, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2042400153,
        "popularmechanics":0.1364442773,
        "scienmag":0.3239887425,
        "technologyreview":0.326473092,
        "vox":0.2263256696,
        "newscientist":0.2366263669,
        "vice":0.1255306685,
        "statnews":0.5266326529,
        "nytimes":0.2479905588,
        "techcrunch":0.244450315,
        "quartz":0.1819692887,
        "venturebeat":0.3108978035,
        "futurism":0.2398387479,
        "scientificamerican":0.234915524,
        "wired":0.2064669569,
        "popsci":0.2044883687,
        "arstechnica":0.2230689954,
        "salon":0.2722829213,
        "washingtonpost":0.2179706317,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.01401v1",
        "predicted_newsworthiness":42.6585842457,
        "title":"Robotic Laser Orientation Planning with a 3D Data-driven Method",
        "summary":"This paper focuses on a research problem of robotic controlled laser orientation to minimize errant overcutting of healthy tissue during the course of pathological tissue resection. Laser scalpels have been widely used in surgery to remove pathological tissue targets such as tumors or other lesions. However, different laser orientations can create various tissue ablation cavities, and incorrect incident angles can cause over-irradiation of healthy tissue that should not be ablated. This work aims to formulate an optimization problem to find the optimal laser orientation in order to minimize the possibility of excessive laser-induced tissue ablation. We first develop a 3D data-driven geometric model to predict the shape of the tissue cavity after a single laser ablation. Modelling the target and non-target tissue region by an obstacle boundary, the determination of an optimal orientation is converted to a collision-minimization problem. The goal of this optimization formulation is maintaining the ablated contour distance from the obstacle boundary, which is solved by Projected gradient descent. Simulation experiments were conducted and the results validated the proposed method with conditions of various obstacle shapes and different initial incident angles.",
        "published":1641345417000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.01401v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Jan 04, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.079987946,
        "popularmechanics":0.1714394374,
        "scienmag":0.1762350169,
        "technologyreview":0.1613801549,
        "vox":0.0641159203,
        "newscientist":0.1329213428,
        "vice":0.1223994799,
        "statnews":0.1449227169,
        "nytimes":0.099510165,
        "techcrunch":0.0909988383,
        "quartz":0.0640298611,
        "venturebeat":0.1175245786,
        "futurism":0.1630667242,
        "scientificamerican":0.098918772,
        "wired":0.1148508142,
        "popsci":0.1815252804,
        "arstechnica":0.0955651884,
        "salon":0.0844065197,
        "washingtonpost":0.0881604642,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.10641v1",
        "predicted_newsworthiness":37.9434122702,
        "title":"Pre-train a Discriminative Text Encoder for Dense Retrieval via Contrastive Span Prediction",
        "summary":"Dense retrieval has shown promising results in many information retrieval (IR) related tasks, whose foundation is high-quality text representation learning for effective search. Some recent studies have shown that autoencoder-based language models are able to boost the dense retrieval performance using a weak decoder. However, we argue that 1) it is not discriminative to decode all the input texts and, 2) even a weak decoder has the bypass effect on the encoder. Therefore, in this work, we introduce a novel contrastive span prediction task to pre-train the encoder alone, but still retain the bottleneck ability of the autoencoder. % Therefore, in this work, we propose to drop out the decoder and introduce a novel contrastive span prediction task to pre-train the encoder alone. The key idea is to force the encoder to generate the text representation close to its own random spans while far away from others using a group-wise contrastive loss. In this way, we can 1) learn discriminative text representations efficiently with the group-wise contrastive learning over spans and, 2) avoid the bypass effect of the decoder thoroughly. Comprehensive experiments over publicly available retrieval benchmark datasets show that our approach can outperform existing pre-training methods for dense retrieval significantly.",
        "published":1650626549000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.10641v1",
        "arxiv_primary_category":"cs.ir",
        "published_hr":"Apr 22, 2022",
        "arxiv_primary_category_hr":"Information Retrieval",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0777290969,
        "popularmechanics":0.0904695353,
        "scienmag":0.0934895152,
        "technologyreview":0.1776652184,
        "vox":0.1243192939,
        "newscientist":0.0956861999,
        "vice":0.0815725248,
        "statnews":0.1116793816,
        "nytimes":0.105690745,
        "techcrunch":0.1298598462,
        "quartz":0.1002504517,
        "venturebeat":0.1789965431,
        "futurism":0.1145540706,
        "scientificamerican":0.0819629872,
        "wired":0.1401207001,
        "popsci":0.1265652609,
        "arstechnica":0.1050036849,
        "salon":0.068825589,
        "washingtonpost":0.1244256702,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.12546v1",
        "predicted_newsworthiness":45.6457054303,
        "title":"Reachability analysis in stochastic directed graphs by reinforcement learning",
        "summary":"We characterize the reachability probabilities in stochastic directed graphs by means of reinforcement learning methods. In particular, we show that the dynamics of the transition probabilities in a stochastic digraph can be modeled via a difference inclusion, which, in turn, can be interpreted as a Markov decision process. Using the latter framework, we offer a methodology to design reward functions to provide upper and lower bounds on the reachability probabilities of a set of nodes for stochastic digraphs. The effectiveness of the proposed technique is demonstrated by application to the diffusion of epidemic diseases over time-varying contact networks generated by the proximity patterns of mobile agents.",
        "published":1645777243000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.12546v1",
        "arxiv_primary_category":"cs.ai",
        "published_hr":"Feb 25, 2022",
        "arxiv_primary_category_hr":"Artificial Intelligence",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1559787917,
        "popularmechanics":0.1184794978,
        "scienmag":0.1755978111,
        "technologyreview":0.1952648856,
        "vox":0.1634824962,
        "newscientist":0.1622108414,
        "vice":0.1277532956,
        "statnews":0.216100012,
        "nytimes":0.1618881993,
        "techcrunch":0.1331553921,
        "quartz":0.1260071948,
        "venturebeat":0.1529901024,
        "futurism":0.1574281493,
        "scientificamerican":0.1690709367,
        "wired":0.13872246,
        "popsci":0.1506849914,
        "arstechnica":0.1545732114,
        "salon":0.1694264918,
        "washingtonpost":0.1393129953,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.01480v1",
        "predicted_newsworthiness":79.6676340629,
        "title":"Life, the Metaverse and Everything: An Overview of Privacy, Ethics, and Governance in Metaverse",
        "summary":"The metaverse is expected to be the next major evolution phase of the internet. The metaverse will have an impact on human society, production, and life. In this work, we analyze the current trends and challenges that building such a virtual environment will face. We focus on three major pillars to guide the development of the metaverse: privacy, governance, and ethical design, to guide the development of the metaverse. Finally, we propose a preliminary modular-based framework for an ethical design of the metaverse.",
        "published":1648179745000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.01480v1",
        "arxiv_primary_category":"cs.cy",
        "published_hr":"Mar 24, 2022",
        "arxiv_primary_category_hr":"Computers and Society",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2633292373,
        "popularmechanics":0.2236984277,
        "scienmag":0.2162767634,
        "technologyreview":0.367656217,
        "vox":0.3275604368,
        "newscientist":0.277563909,
        "vice":0.2465088781,
        "statnews":0.3252351161,
        "nytimes":0.3208638011,
        "techcrunch":0.330574254,
        "quartz":0.2767788638,
        "venturebeat":0.3416454862,
        "futurism":0.3151321559,
        "scientificamerican":0.2387149616,
        "wired":0.3687685633,
        "popsci":0.3123429039,
        "arstechnica":0.3022175116,
        "salon":0.235645724,
        "washingtonpost":0.3395320774,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.02100v1",
        "predicted_newsworthiness":58.0929232996,
        "title":"Self-supervised learning -- A way to minimize time and effort for precision agriculture?",
        "summary":"Machine learning, satellites or local sensors are key factors for a sustainable and resource-saving optimisation of agriculture and proved its values for the management of agricultural land. Up to now, the main focus was on the enlargement of data which were evaluated by means of supervised learning methods. Nevertheless, the need for labels is also a limiting and time-consuming factor, while in contrast, ongoing technological development is already providing an ever-increasing amount of unlabeled data. Self-supervised learning (SSL) could overcome this limitation and incorporate existing unlabeled data. Therefore, a crop type data set was utilized to conduct experiments with SSL and compare it to supervised methods. A unique feature of our data set from 2016 to 2018 was a divergent climatological condition in 2018 that reduced yields and affected the spectral fingerprint of the plants. Our experiments focused on predicting 2018 using SLL without or a few labels to clarify whether new labels should be collected for an unknown year. Despite these challenging conditions, the results showed that SSL contributed to higher accuracies. We believe that the results will encourage further improvements in the field of precision farming, why the SSL framework and data will be published (Marszalek, 2021).",
        "published":1649155447000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.02100v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Apr 05, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1599058264,
        "popularmechanics":0.1643478927,
        "scienmag":0.2228366164,
        "technologyreview":0.2584510491,
        "vox":0.1395643942,
        "newscientist":0.1941093276,
        "vice":0.1566249864,
        "statnews":0.2034814233,
        "nytimes":0.1641601067,
        "techcrunch":0.1907764433,
        "quartz":0.1446618787,
        "venturebeat":0.2358244292,
        "futurism":0.1973655902,
        "scientificamerican":0.1920799176,
        "wired":0.1865351897,
        "popsci":0.1985420012,
        "arstechnica":0.1282253537,
        "salon":0.1644476214,
        "washingtonpost":0.1613952911,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.12406v1",
        "predicted_newsworthiness":65.3982024628,
        "title":"UrduFake@FIRE2020: Shared Track on Fake News Identification in Urdu",
        "summary":"This paper gives the overview of the first shared task at FIRE 2020 on fake news detection in the Urdu language. This is a binary classification task in which the goal is to identify fake news using a dataset composed of 900 annotated news articles for training and 400 news articles for testing. The dataset contains news in five domains: (i) Health, (ii) Sports, (iii) Showbiz, (iv) Technology, and (v) Business. 42 teams from 6 different countries (India, China, Egypt, Germany, Pakistan, and the UK) registered for the task. 9 teams submitted their experimental results. The participants used various machine learning methods ranging from feature-based traditional machine learning to neural network techniques. The best performing system achieved an F-score value of 0.90, showing that the BERT-based approach outperforms other machine learning classifiers.",
        "published":1658720811000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.12406v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Jul 24, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2218470732,
        "popularmechanics":0.1538533427,
        "scienmag":0.1565811699,
        "technologyreview":0.3133568942,
        "vox":0.2763084304,
        "newscientist":0.2013635417,
        "vice":0.1413199579,
        "statnews":0.2171331495,
        "nytimes":0.2497352893,
        "techcrunch":0.2376105659,
        "quartz":0.249259428,
        "venturebeat":0.2773478417,
        "futurism":0.2251119515,
        "scientificamerican":0.1726126691,
        "wired":0.2826276421,
        "popsci":0.2342426165,
        "arstechnica":0.2382055198,
        "salon":0.1700581414,
        "washingtonpost":0.3083719656,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.00806v1",
        "predicted_newsworthiness":57.9760970759,
        "title":"HLDC: Hindi Legal Documents Corpus",
        "summary":"Many populous countries including India are burdened with a considerable backlog of legal cases. Development of automated systems that could process legal documents and augment legal practitioners can mitigate this. However, there is a dearth of high-quality corpora that is needed to develop such data-driven systems. The problem gets even more pronounced in the case of low resource languages such as Hindi. In this resource paper, we introduce the Hindi Legal Documents Corpus (HLDC), a corpus of more than 900K legal documents in Hindi. Documents are cleaned and structured to enable the development of downstream applications. Further, as a use-case for the corpus, we introduce the task of bail prediction. We experiment with a battery of models and propose a Multi-Task Learning (MTL) based model for the same. MTL models use summarization as an auxiliary task along with bail prediction as the main task. Experiments with different models are indicative of the need for further research in this area. We release the corpus and model implementation code with this paper: https:\/\/github.com\/Exploration-Lab\/HLDC",
        "published":1648887772000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.00806v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Apr 02, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1627357761,
        "popularmechanics":0.0937532149,
        "scienmag":0.1101254438,
        "technologyreview":0.2138177748,
        "vox":0.1715991053,
        "newscientist":0.128700873,
        "vice":0.0684125452,
        "statnews":0.1661839687,
        "nytimes":0.1698847301,
        "techcrunch":0.1899288459,
        "quartz":0.2056245558,
        "venturebeat":0.2233317606,
        "futurism":0.1530135133,
        "scientificamerican":0.0967281427,
        "wired":0.1844516706,
        "popsci":0.1570558199,
        "arstechnica":0.1821815415,
        "salon":0.1044460321,
        "washingtonpost":0.1864036257,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.02601v1",
        "predicted_newsworthiness":37.4177832332,
        "title":"Probing Structured Pruning on Multilingual Pre-trained Models: Settings, Algorithms, and Efficiency",
        "summary":"Structured pruning has been extensively studied on monolingual pre-trained language models and is yet to be fully evaluated on their multilingual counterparts. This work investigates three aspects of structured pruning on multilingual pre-trained language models: settings, algorithms, and efficiency. Experiments on nine downstream tasks show several counter-intuitive phenomena: for settings, individually pruning for each language does not induce a better result; for algorithms, the simplest method performs the best; for efficiency, a fast model does not imply that it is also small. To facilitate the comparison on all sparsity levels, we present Dynamic Sparsification, a simple approach that allows training the model once and adapting to different model sizes at inference. We hope this work fills the gap in the study of structured pruning on multilingual pre-trained models and sheds light on future research.",
        "published":1649226592000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.02601v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Apr 06, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0887200652,
        "popularmechanics":0.0913792703,
        "scienmag":0.0860724215,
        "technologyreview":0.1685137295,
        "vox":0.104232577,
        "newscientist":0.0949380858,
        "vice":0.0650888777,
        "statnews":0.0977560587,
        "nytimes":0.0992787733,
        "techcrunch":0.106874917,
        "quartz":0.1094417826,
        "venturebeat":0.1640141506,
        "futurism":0.1011829644,
        "scientificamerican":0.0962479103,
        "wired":0.1172307531,
        "popsci":0.1127755574,
        "arstechnica":0.0938152836,
        "salon":0.0742353935,
        "washingtonpost":0.1020269501,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.05775v1",
        "predicted_newsworthiness":58.358902623,
        "title":"Physics-informed Reinforcement Learning for Perception and Reasoning about Fluids",
        "summary":"Learning and reasoning about physical phenomena is still a challenge in robotics development, and computational sciences play a capital role in the search for accurate methods able to provide explanations for past events and rigorous forecasts of future situations. We propose a physics-informed reinforcement learning strategy for fluid perception and reasoning from observations. As a model problem, we take the sloshing phenomena of different fluids contained in a glass. Starting from full-field and high-resolution synthetic data for a particular fluid, we develop a method for the tracking (perception) and analysis (reasoning) of any previously unseen liquid whose free surface is observed with a commodity camera. This approach demonstrates the importance of physics and knowledge not only in data-driven (grey box) modeling but also in the correction for real physics adaptation in low data regimes and partial observations of the dynamics. The method here presented is extensible to other domains such as the development of cognitive digital twins, able to learn from observation of phenomena for which they have not been trained explicitly.",
        "published":1646982083000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.05775v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Mar 11, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1294283225,
        "popularmechanics":0.2147350412,
        "scienmag":0.22181293,
        "technologyreview":0.2828433437,
        "vox":0.1274623077,
        "newscientist":0.2324116005,
        "vice":0.2217953646,
        "statnews":0.203228875,
        "nytimes":0.19470056,
        "techcrunch":0.1838331505,
        "quartz":0.1231982303,
        "venturebeat":0.2328802168,
        "futurism":0.2347313125,
        "scientificamerican":0.2016926109,
        "wired":0.2208377855,
        "popsci":0.2546499346,
        "arstechnica":0.1728004495,
        "salon":0.1467666809,
        "washingtonpost":0.1814359053,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.06218v1",
        "predicted_newsworthiness":45.5843885106,
        "title":"A Novel Quadratic Interpolated Beetle Antennae Search for Manipulator Calibration",
        "summary":"Over the past decades, industrial manipulators play a vital role in in various fields, like aircraft manufacturing and automobile manufacturing. However, an industrial manipulator without calibration suffers from its low absolute positioning accuracy, which extensively restricts its application in high-precision intelligent manufacture. Recent manipulator calibration methods are developed to address this issue, while they frequently encounter long-tail convergence and low calibration accuracy. To address this thorny issue, this work proposes a novel manipulator calibration method incorporating an extended Kalman filter with a Quadratic Interpolated Beetle Antennae Search algorithm. This paper has three-fold ideas: a) proposing a new Quadratic Interpolated Beetle Antennae Search algorithm to deal with the issue of local optimum and low convergence rate in a Beetle Antennae Search algorithm; b) adopting an extended Kalman filter algorithm to suppress non-Gaussian noises and c) developing a new manipulator calibration method incorporating an extended Kalman filter with a Quadratic Interpolated Beetle Antennae Search algorithm to calibrating a manipulator. Extensively experimental results on an ABB IRB120 industrial manipulator demonstrate that the proposed method achieves much higher calibration accuracy than several state-of-the-art calibration methods.",
        "published":1649835861000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.06218v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Apr 13, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0612489295,
        "popularmechanics":0.1828708176,
        "scienmag":0.1073254248,
        "technologyreview":0.1772765061,
        "vox":0.0767851971,
        "newscientist":0.1285379843,
        "vice":0.1314579639,
        "statnews":0.0584074767,
        "nytimes":0.1095636858,
        "techcrunch":0.1309978527,
        "quartz":0.0826567613,
        "venturebeat":0.1446311798,
        "futurism":0.1689033447,
        "scientificamerican":0.1207663582,
        "wired":0.1380607318,
        "popsci":0.2152643767,
        "arstechnica":0.106267712,
        "salon":0.0455867201,
        "washingtonpost":0.1213945659,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.02566v1",
        "predicted_newsworthiness":45.2941603909,
        "title":"LST: Lexicon-Guided Self-Training for Few-Shot Text Classification",
        "summary":"Self-training provides an effective means of using an extremely small amount of labeled data to create pseudo-labels for unlabeled data. Many state-of-the-art self-training approaches hinge on different regularization methods to prevent overfitting and improve generalization. Yet they still rely heavily on predictions initially trained with the limited labeled data as pseudo-labels and are likely to put overconfident label belief on erroneous classes depending on the first prediction. To tackle this issue in text classification, we introduce LST, a simple self-training method that uses a lexicon to guide the pseudo-labeling mechanism in a linguistically-enriched manner. We consistently refine the lexicon by predicting confidence of the unseen data to teach pseudo-labels better in the training iterations. We demonstrate that this simple yet well-crafted lexical knowledge achieves 1.0-2.0% better performance on 30 labeled samples per class for five benchmark datasets than the current state-of-the-art approaches.",
        "published":1644071592000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.02566v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Feb 05, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1091862598,
        "popularmechanics":0.1218056747,
        "scienmag":0.1319153418,
        "technologyreview":0.2270023634,
        "vox":0.1512769111,
        "newscientist":0.1417468671,
        "vice":0.0907782092,
        "statnews":0.195712841,
        "nytimes":0.1475617517,
        "techcrunch":0.1588241505,
        "quartz":0.1317087683,
        "venturebeat":0.2211262,
        "futurism":0.1582127415,
        "scientificamerican":0.1267111678,
        "wired":0.1725407674,
        "popsci":0.1698939244,
        "arstechnica":0.128137014,
        "salon":0.1266384935,
        "washingtonpost":0.159980594,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.02132v1",
        "predicted_newsworthiness":45.2090380422,
        "title":"Multi-Granularity Semantic Aware Graph Model for Reducing Position Bias in Emotion-Cause Pair Extraction",
        "summary":"The Emotion-Cause Pair Extraction (ECPE) task aims to extract emotions and causes as pairs from documents. We observe that the relative distance distribution of emotions and causes is extremely imbalanced in the typical ECPE dataset. Existing methods have set a fixed size window to capture relations between neighboring clauses. However, they neglect the effective semantic connections between distant clauses, leading to poor generalization ability towards position-insensitive data. To alleviate the problem, we propose a novel \\textbf{M}ulti-\\textbf{G}ranularity \\textbf{S}emantic \\textbf{A}ware \\textbf{G}raph model (MGSAG) to incorporate fine-grained and coarse-grained semantic features jointly, without regard to distance limitation. In particular, we first explore semantic dependencies between clauses and keywords extracted from the document that convey fine-grained semantic features, obtaining keywords enhanced clause representations. Besides, a clause graph is also established to model coarse-grained semantic relations between clauses. Experimental results indicate that MGSAG surpasses the existing state-of-the-art ECPE models. Especially, MGSAG outperforms other models significantly in the condition of position-insensitive data.",
        "published":1651678786000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.02132v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"May 04, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1289172461,
        "popularmechanics":0.1009230569,
        "scienmag":0.1302585501,
        "technologyreview":0.2025588519,
        "vox":0.1709563884,
        "newscientist":0.1266426588,
        "vice":0.0939395644,
        "statnews":0.175930607,
        "nytimes":0.1509842438,
        "techcrunch":0.1592096073,
        "quartz":0.1449523008,
        "venturebeat":0.20425245,
        "futurism":0.1396812743,
        "scientificamerican":0.1241638557,
        "wired":0.1729669452,
        "popsci":0.1489332402,
        "arstechnica":0.1340840755,
        "salon":0.1271450525,
        "washingtonpost":0.166286049,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.07476v1",
        "predicted_newsworthiness":43.8207994081,
        "title":"Guiding Attention using Partial-Order Relationships for Image Captioning",
        "summary":"The use of attention models for automated image captioning has enabled many systems to produce accurate and meaningful descriptions for images. Over the years, many novel approaches have been proposed to enhance the attention process using different feature representations. In this paper, we extend this approach by creating a guided attention network mechanism, that exploits the relationship between the visual scene and text-descriptions using spatial features from the image, high-level information from the topics, and temporal context from caption generation, which are embedded together in an ordered embedding space. A pairwise ranking objective is used for training this embedding space which allows similar images, topics and captions in the shared semantic space to maintain a partial order in the visual-semantic hierarchy and hence, helps the model to produce more visually accurate captions. The experimental results based on MSCOCO dataset shows the competitiveness of our approach, with many state-of-the-art models on various evaluation metrics.",
        "published":1650032529000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.07476v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Apr 15, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1085573042,
        "popularmechanics":0.1144435896,
        "scienmag":0.1077886974,
        "technologyreview":0.1906446886,
        "vox":0.1192922038,
        "newscientist":0.1286657676,
        "vice":0.099136422,
        "statnews":0.1322677346,
        "nytimes":0.1305175728,
        "techcrunch":0.1278759899,
        "quartz":0.1191074618,
        "venturebeat":0.1863594525,
        "futurism":0.1291201705,
        "scientificamerican":0.1125079276,
        "wired":0.1692144921,
        "popsci":0.1471499924,
        "arstechnica":0.09400311,
        "salon":0.1016154425,
        "washingtonpost":0.1217229083,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.10879v1",
        "predicted_newsworthiness":45.1624019697,
        "title":"Evaluating Persian Tokenizers",
        "summary":"Tokenization plays a significant role in the process of lexical analysis. Tokens become the input for other natural language processing tasks, like semantic parsing and language modeling. Natural Language Processing in Persian is challenging due to Persian's exceptional cases, such as half-spaces. Thus, it is crucial to have a precise tokenizer for Persian. This article provides a novel work by introducing the most widely used tokenizers for Persian and comparing and evaluating their performance on Persian texts using a simple algorithm with a pre-tagged Persian dependency dataset. After evaluating tokenizers with the F1-Score, the hybrid version of the Farsi Verb and Hazm with bounded morphemes fixing showed the best performance with an F1 score of 98.97%.",
        "published":1645536444000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.10879v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Feb 22, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1178362971,
        "popularmechanics":0.1096742466,
        "scienmag":0.1028605057,
        "technologyreview":0.1508994181,
        "vox":0.1118674468,
        "newscientist":0.095526137,
        "vice":0.101528571,
        "statnews":0.1023739436,
        "nytimes":0.1188845854,
        "techcrunch":0.1434372692,
        "quartz":0.1297599852,
        "venturebeat":0.1686439193,
        "futurism":0.117954163,
        "scientificamerican":0.0866936012,
        "wired":0.1267013042,
        "popsci":0.1275702676,
        "arstechnica":0.1122043713,
        "salon":0.0765281172,
        "washingtonpost":0.1187611147,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.03369v1",
        "predicted_newsworthiness":50.8153392311,
        "title":"QoS and Resource aware Security Orchestration System",
        "summary":"Network Function Virtualization (NFV) and Software Distributed Networking (SDN) technologies play a crucial role in enabling 5G system and beyond. A synergy between these both technologies has been identified for enabling a new concept dubbed service function chains (SFC) that aims to reduce both the capital expenditures (CAPEX) and operating expenses (OPEX). The SFC paradigm considers different constraints and key performance indicators (KPIs), that includes QoS and different resources, for enabling network slice services. However, the large-scale, complexity and security issues brought by these technologies create an extra overhead for ensuring secure network slicing. To cope with these challenges, this paper proposes a cost-efficient optimized SFC management system that enables the creation of SFCs for enabling efficient and secure network slices. The proposed system considers the network and computational resources and current network security levels to ensure trusted deployments. The simulation results demonstrated the efficiency of the proposed solution for achieving its designed objectives. The proposed solution efficiently manages the SFCs by optimizing deployment costs and reducing overall end-to-end delay",
        "published":1641366706000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.03369v1",
        "arxiv_primary_category":"cs.ni",
        "published_hr":"Jan 05, 2022",
        "arxiv_primary_category_hr":"Networking and Internet Architecture",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1275463277,
        "popularmechanics":0.1810194099,
        "scienmag":0.1054523762,
        "technologyreview":0.2171820772,
        "vox":0.1822155002,
        "newscientist":0.1123171755,
        "vice":0.1181705301,
        "statnews":0.1598405304,
        "nytimes":0.1610331261,
        "techcrunch":0.2665450591,
        "quartz":0.1780136641,
        "venturebeat":0.3031656021,
        "futurism":0.1774715201,
        "scientificamerican":0.0847832796,
        "wired":0.1980219817,
        "popsci":0.2084505096,
        "arstechnica":0.2223031207,
        "salon":0.1161026658,
        "washingtonpost":0.1973096184,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.03521v1",
        "predicted_newsworthiness":50.8848926762,
        "title":"DeepXPalm: Tilt and Position Rendering using Palm-worn Haptic Display and CNN-based Tactile Pattern Recognition",
        "summary":"Telemanipulation of deformable objects requires high precision and dexterity from the users, which can be increased by kinesthetic and tactile feedback. However, the object shape can change dynamically, causing ambiguous perception of its alignment and hence errors in the robot positioning. Therefore, the tilt angle and position classification problem has to be solved to present a clear tactile pattern to the user. This work presents a telemanipulation system for plastic pipettes consisting of a multi-contact haptic device LinkGlide to deliver haptic feedback at the users' palm and two tactile sensors array embedded in the 2-finger Robotiq gripper. We propose a novel approach based on Convolutional Neural Networks (CNN) to detect the tilt and position while grasping deformable objects. The CNN generates a mask based on recognized tilt and position data to render further multi-contact tactile stimuli provided to the user during the telemanipulation. The study has shown that using the CNN algorithm and the preset mask, tilt, and position recognition by users is increased from 9.67% using the direct data to 82.5%.",
        "published":1649345990000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.03521v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Apr 07, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0928553571,
        "popularmechanics":0.2068386115,
        "scienmag":0.1859135896,
        "technologyreview":0.2254635837,
        "vox":0.1045543523,
        "newscientist":0.1743079011,
        "vice":0.1320653826,
        "statnews":0.1252656674,
        "nytimes":0.1547689835,
        "techcrunch":0.1788559437,
        "quartz":0.1121098165,
        "venturebeat":0.2162677534,
        "futurism":0.2094757006,
        "scientificamerican":0.1360035646,
        "wired":0.1818700338,
        "popsci":0.2270098519,
        "arstechnica":0.1165514582,
        "salon":0.0966771599,
        "washingtonpost":0.1543350882,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.09265v1",
        "predicted_newsworthiness":40.8921012379,
        "title":"Dynamic Free-Space Roadmap for Safe Quadrotor Motion Planning",
        "summary":"Free-space-oriented roadmaps typically generate a series of convex geometric primitives, which constitute the safe region for motion planning. However, a static environment is assumed for this kind of roadmap. This assumption makes it unable to deal with dynamic obstacles and limits its applications. In this paper, we present a dynamic free-space roadmap, which provides feasible spaces and a navigation graph for safe quadrotor motion planning. Our roadmap is constructed by continuously seeding and extracting free regions in the environment. In order to adapt our map to environments with dynamic obstacles, we incrementally decompose the polyhedra intersecting with obstacles into obstacle-free regions, while the graph is also updated by our well-designed mechanism. Extensive simulations and real-world experiments demonstrate that our method is practically applicable and efficient.",
        "published":1650438743000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.09265v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Apr 20, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0822205563,
        "popularmechanics":0.2107591226,
        "scienmag":0.0915149711,
        "technologyreview":0.1967453369,
        "vox":0.1000618321,
        "newscientist":0.1505754397,
        "vice":0.1870457508,
        "statnews":0.0729473359,
        "nytimes":0.1472206334,
        "techcrunch":0.1624225974,
        "quartz":0.1010591152,
        "venturebeat":0.1746320681,
        "futurism":0.2019404106,
        "scientificamerican":0.1049592618,
        "wired":0.1888416058,
        "popsci":0.2353698201,
        "arstechnica":0.1639698205,
        "salon":0.0863117624,
        "washingtonpost":0.1701636072,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.03794v2",
        "predicted_newsworthiness":33.2069698692,
        "title":"Efficient Non-Local Contrastive Attention for Image Super-Resolution",
        "summary":"Non-Local Attention (NLA) brings significant improvement for Single Image Super-Resolution (SISR) by leveraging intrinsic feature correlation in natural images. However, NLA gives noisy information large weights and consumes quadratic computation resources with respect to the input size, limiting its performance and application. In this paper, we propose a novel Efficient Non-Local Contrastive Attention (ENLCA) to perform long-range visual modeling and leverage more relevant non-local features. Specifically, ENLCA consists of two parts, Efficient Non-Local Attention (ENLA) and Sparse Aggregation. ENLA adopts the kernel method to approximate exponential function and obtains linear computation complexity. For Sparse Aggregation, we multiply inputs by an amplification factor to focus on informative features, yet the variance of approximation increases exponentially. Therefore, contrastive learning is applied to further separate relevant and irrelevant features. To demonstrate the effectiveness of ENLCA, we build an architecture called Efficient Non-Local Contrastive Network (ENLCN) by adding a few of our modules in a simple backbone. Extensive experimental results show that ENLCN reaches superior performance over state-of-the-art approaches on both quantitative and qualitative evaluations.",
        "published":1641880749000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.03794v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jan 10, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0689760103,
        "popularmechanics":0.1088756774,
        "scienmag":0.1128993363,
        "technologyreview":0.1905300912,
        "vox":0.0904903539,
        "newscientist":0.1143056468,
        "vice":0.0899804323,
        "statnews":0.1212586139,
        "nytimes":0.0995468386,
        "techcrunch":0.1146764127,
        "quartz":0.0857041151,
        "venturebeat":0.1717345369,
        "futurism":0.1323602397,
        "scientificamerican":0.0982421777,
        "wired":0.1358587765,
        "popsci":0.1386615326,
        "arstechnica":0.0764001673,
        "salon":0.0736644299,
        "washingtonpost":0.1079082233,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.12720v1",
        "predicted_newsworthiness":50.2104118582,
        "title":"Convolutional neural networks and multi-threshold analysis for contamination detection in the apparel industry",
        "summary":"Quality control of apparel items is mandatory in modern textile industry, as consumer's awareness and expectations about the highest possible standard is constantly increasing in favor of sustainable and ethical textile products. Such a level of quality is achieved by checking the product throughout its life cycle, from raw materials to boxed stock. Checks may include color shading tests, fasteners fatigue tests, fabric weigh tests, contamination tests, etc. This work deals specifically with the automatic detection of contaminations given by small parts in the finished product such as raw material like little stones and plastic bits or materials from the construction process, like a whole needle or a clip. Identification is performed by a two-level processing of X-ray images of the items: in the first, a multi-threshold analysis recognizes the contaminations by gray level and shape attributes; the second level consists of a deep learning classifier that has been trained to distinguish between true positives and false positives. The automatic detector was successfully deployed in an actual production plant, since the results satisfy the technical specification of the process, namely a number of false negatives smaller than 3% and a number of false positives smaller than 15%.",
        "published":1658823701000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.12720v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 26, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1549100991,
        "popularmechanics":0.1907400795,
        "scienmag":0.2197276438,
        "technologyreview":0.250476699,
        "vox":0.1461770422,
        "newscientist":0.195151778,
        "vice":0.1656611612,
        "statnews":0.2055557957,
        "nytimes":0.1844861508,
        "techcrunch":0.1894338412,
        "quartz":0.1816770959,
        "venturebeat":0.2247521406,
        "futurism":0.2108619404,
        "scientificamerican":0.1761941341,
        "wired":0.1694311781,
        "popsci":0.2161868223,
        "arstechnica":0.1671461615,
        "salon":0.166981977,
        "washingtonpost":0.184103355,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.04605v1",
        "predicted_newsworthiness":47.6947460205,
        "title":"Sentence-level Privacy for Document Embeddings",
        "summary":"User language data can contain highly sensitive personal content. As such, it is imperative to offer users a strong and interpretable privacy guarantee when learning from their data. In this work, we propose SentDP: pure local differential privacy at the sentence level for a single user document. We propose a novel technique, DeepCandidate, that combines concepts from robust statistics and language modeling to produce high-dimensional, general-purpose $\\epsilon$-SentDP document embeddings. This guarantees that any single sentence in a document can be substituted with any other sentence while keeping the embedding $\\epsilon$-indistinguishable. Our experiments indicate that these private document embeddings are useful for downstream tasks like sentiment analysis and topic classification and even outperform baseline methods with weaker guarantees like word-level Metric DP.",
        "published":1652141975000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.04605v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"May 09, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1595487037,
        "popularmechanics":0.1405003896,
        "scienmag":0.1364746799,
        "technologyreview":0.2846686358,
        "vox":0.2438053762,
        "newscientist":0.1769262426,
        "vice":0.1191458992,
        "statnews":0.2158505611,
        "nytimes":0.212681944,
        "techcrunch":0.2291183009,
        "quartz":0.1887731042,
        "venturebeat":0.2658113074,
        "futurism":0.2160839893,
        "scientificamerican":0.1471210011,
        "wired":0.2528869375,
        "popsci":0.2407782653,
        "arstechnica":0.2244624325,
        "salon":0.1475598014,
        "washingtonpost":0.2680831836,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.04679v1",
        "predicted_newsworthiness":47.5488321397,
        "title":"Scale Invariant Semantic Segmentation with RGB-D Fusion",
        "summary":"In this paper, we propose a neural network architecture for scale-invariant semantic segmentation using RGB-D images. We utilize depth information as an additional modality apart from color images only. Especially in an outdoor scene which consists of different scale objects due to the distance of the objects from the camera. The near distance objects consist of significantly more pixels than the far ones. We propose to incorporate depth information to the RGB data for pixel-wise semantic segmentation to address the different scale objects in an outdoor scene. We adapt to a well-known DeepLab-v2(ResNet-101) model as our RGB baseline. Depth images are passed separately as an additional input with a distinct branch. The intermediate feature maps of both color and depth image branch are fused using a novel fusion block. Our model is compact and can be easily applied to the other RGB model. We perform extensive qualitative and quantitative evaluation on a challenging dataset Cityscapes. The results obtained are comparable to the state-of-the-art. Additionally, we evaluated our model on a self-recorded real dataset. For the shake of extended evaluation of a driving scene with ground truth we generated a synthetic dataset using popular vehicle simulation project CARLA. The results obtained from the real and synthetic dataset shows the effectiveness of our approach.",
        "published":1649595267000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.04679v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Apr 10, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0889768573,
        "popularmechanics":0.1551219273,
        "scienmag":0.1035779461,
        "technologyreview":0.2022067033,
        "vox":0.1047498151,
        "newscientist":0.1327565055,
        "vice":0.1219928118,
        "statnews":0.0582549479,
        "nytimes":0.1048189764,
        "techcrunch":0.1558972316,
        "quartz":0.1002433384,
        "venturebeat":0.1913155194,
        "futurism":0.1663852923,
        "scientificamerican":0.1022252491,
        "wired":0.1637616746,
        "popsci":0.1903767194,
        "arstechnica":0.0934421722,
        "salon":0.0799078289,
        "washingtonpost":0.123778793,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.02189v1",
        "predicted_newsworthiness":32.8457864224,
        "title":"Matrix Completion via Non-Convex Relaxation and Adaptive Correlation Learning",
        "summary":"The existing matrix completion methods focus on optimizing the relaxation of rank function such as nuclear norm, Schatten-p norm, etc. They usually need many iterations to converge. Moreover, only the low-rank property of matrices is utilized in most existing models and several methods that incorporate other knowledge are quite time-consuming in practice. To address these issues, we propose a novel non-convex surrogate that can be optimized by closed-form solutions, such that it empirically converges within dozens of iterations. Besides, the optimization is parameter-free and the convergence is proved. Compared with the relaxation of rank, the surrogate is motivated by optimizing an upper-bound of rank. We theoretically validate that it is equivalent to the existing matrix completion models. Besides the low-rank assumption, we intend to exploit the column-wise correlation for matrix completion, and thus an adaptive correlation learning, which is scaling-invariant, is developed. More importantly, after incorporating the correlation learning, the model can be still solved by closed-form solutions such that it still converges fast. Experiments show the effectiveness of the non-convex surrogate and adaptive correlation learning.",
        "published":1646383850000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.02189v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Mar 04, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0405102332,
        "popularmechanics":0.0700558062,
        "scienmag":0.0839859432,
        "technologyreview":0.1136959255,
        "vox":0.0643605522,
        "newscientist":0.0709942779,
        "vice":0.0568600066,
        "statnews":0.0892866762,
        "nytimes":0.0728396879,
        "techcrunch":0.076543433,
        "quartz":0.0624207392,
        "venturebeat":0.109370828,
        "futurism":0.086048006,
        "scientificamerican":0.0628259882,
        "wired":0.088793179,
        "popsci":0.0928384662,
        "arstechnica":0.0638799419,
        "salon":0.0422021742,
        "washingtonpost":0.0785731324,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.09880v1",
        "predicted_newsworthiness":46.3502079593,
        "title":"Beyond Labels: Visual Representations for Bone Marrow Cell Morphology Recognition",
        "summary":"Analyzing and inspecting bone marrow cell cytomorphology is a critical but highly complex and time-consuming component of hematopathology diagnosis. Recent advancements in artificial intelligence have paved the way for the application of deep learning algorithms to complex medical tasks. Nevertheless, there are many challenges in applying effective learning algorithms to medical image analysis, such as the lack of sufficient and reliably annotated training datasets and the highly class-imbalanced nature of most medical data. Here, we improve on the state-of-the-art methodologies of bone marrow cell recognition by deviating from sole reliance on labeled data and leveraging self-supervision in training our learning models. We investigate our approach's effectiveness in identifying bone marrow cell types. Our experiments demonstrate significant performance improvements in conducting different bone marrow cell recognition tasks compared to the current state-of-the-art methodologies.",
        "published":1652997946000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.09880v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 19, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1077473368,
        "popularmechanics":0.138997855,
        "scienmag":0.2243465822,
        "technologyreview":0.2463508674,
        "vox":0.1172217295,
        "newscientist":0.1751890993,
        "vice":0.1410289732,
        "statnews":0.2934802782,
        "nytimes":0.1450549264,
        "techcrunch":0.1420910248,
        "quartz":0.1053220722,
        "venturebeat":0.2088775341,
        "futurism":0.1840675765,
        "scientificamerican":0.1534569025,
        "wired":0.1584581577,
        "popsci":0.168450419,
        "arstechnica":0.1184067877,
        "salon":0.1263040473,
        "washingtonpost":0.1374116449,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.09148v2",
        "predicted_newsworthiness":48.5859444192,
        "title":"What Makes Instruction Learning Hard? An Investigation and a New Challenge in a Synthetic Environment",
        "summary":"The instruction learning paradigm -- where a model learns to perform new tasks from task descriptions alone -- has become popular in general-purpose model research. The capabilities of large transformer models as instruction learners, however, remain poorly understood. We use a controlled synthetic environment to characterize such capabilities. Specifically, we use the task of deciding whether a given string matches a regular expression (viewed as an instruction) to identify properties of tasks, instructions, and instances that make instruction learning challenging. For instance, we find that our model, a fine-tuned T5-based text2text transformer, struggles with large regular languages, suggesting that less precise instructions are challenging for models. Additionally, instruction executions that require tracking longer contexts of prior steps are also more difficult. We use our findings to systematically construct a challenging instruction learning dataset, which we call Hard RegSet. Fine-tuning on Hard RegSet, our large transformer learns to correctly interpret only 65.6% of test instructions (with at least 90% accuracy), and 11%-24% of the instructions in out-of-distribution generalization settings. We propose Hard RegSet as a challenging instruction learning task, and a controlled environment for studying instruction learning.",
        "published":1650406307000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.09148v2",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Apr 19, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1175855937,
        "popularmechanics":0.1512784774,
        "scienmag":0.1598257654,
        "technologyreview":0.3184723692,
        "vox":0.1457148163,
        "newscientist":0.1878955903,
        "vice":0.1197572598,
        "statnews":0.236038191,
        "nytimes":0.1680451341,
        "techcrunch":0.1834089966,
        "quartz":0.1362727224,
        "venturebeat":0.290246329,
        "futurism":0.2227553854,
        "scientificamerican":0.172675548,
        "wired":0.2074666772,
        "popsci":0.2143576066,
        "arstechnica":0.1353089065,
        "salon":0.1234325183,
        "washingtonpost":0.1620731499,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.06633v1",
        "predicted_newsworthiness":48.6903294489,
        "title":"FlowEval: A Consensus-Based Dialogue Evaluation Framework Using Segment Act Flows",
        "summary":"Despite recent progress in open-domain dialogue evaluation, how to develop automatic metrics remains an open problem. We explore the potential of dialogue evaluation featuring dialog act information, which was hardly explicitly modeled in previous methods. However, defined at the utterance level in general, dialog act is of coarse granularity, as an utterance can contain multiple segments possessing different functions. Hence, we propose segment act, an extension of dialog act from utterance level to segment level, and crowdsource a large-scale dataset for it. To utilize segment act flows, sequences of segment acts, for evaluation, we develop the first consensus-based dialogue evaluation framework, FlowEval. This framework provides a reference-free approach for dialog evaluation by finding pseudo-references. Extensive experiments against strong baselines on three benchmark datasets demonstrate the effectiveness and other desirable characteristics of our FlowEval, pointing out a potential path for better dialogue evaluation.",
        "published":1644838640000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.06633v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Feb 14, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1240685655,
        "popularmechanics":0.1110846933,
        "scienmag":0.1089337934,
        "technologyreview":0.2136573804,
        "vox":0.182501545,
        "newscientist":0.1223460994,
        "vice":0.097001916,
        "statnews":0.1519993819,
        "nytimes":0.154457606,
        "techcrunch":0.1874956292,
        "quartz":0.1526628983,
        "venturebeat":0.2336190974,
        "futurism":0.149200785,
        "scientificamerican":0.1463427152,
        "wired":0.2057648058,
        "popsci":0.171393559,
        "arstechnica":0.1470871155,
        "salon":0.123298361,
        "washingtonpost":0.1589402597,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.03035v1",
        "predicted_newsworthiness":47.4702987611,
        "title":"Hierarchical Annotation for Building A Suite of Clinical Natural Language Processing Tasks: Progress Note Understanding",
        "summary":"Applying methods in natural language processing on electronic health records (EHR) data is a growing field. Existing corpus and annotation focus on modeling textual features and relation prediction. However, there is a paucity of annotated corpus built to model clinical diagnostic thinking, a process involving text understanding, domain knowledge abstraction and reasoning. This work introduces a hierarchical annotation schema with three stages to address clinical text understanding, clinical reasoning, and summarization. We created an annotated corpus based on an extensive collection of publicly available daily progress notes, a type of EHR documentation that is collected in time series in a problem-oriented format. The conventional format for a progress note follows a Subjective, Objective, Assessment and Plan heading (SOAP). We also define a new suite of tasks, Progress Note Understanding, with three tasks utilizing the three annotation stages. The novel suite of tasks was designed to train and evaluate future NLP models for clinical text understanding, clinical knowledge representation, inference, and summarization.",
        "published":1649270288000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.03035v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Apr 06, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1710797284,
        "popularmechanics":0.1014244256,
        "scienmag":0.2447040138,
        "technologyreview":0.236428429,
        "vox":0.1786633427,
        "newscientist":0.1685096442,
        "vice":0.0986658835,
        "statnews":0.3816535226,
        "nytimes":0.1913202428,
        "techcrunch":0.1798092797,
        "quartz":0.1451929152,
        "venturebeat":0.2289028459,
        "futurism":0.1720482297,
        "scientificamerican":0.1836577981,
        "wired":0.1662609283,
        "popsci":0.1662345074,
        "arstechnica":0.168399397,
        "salon":0.2221591661,
        "washingtonpost":0.1572617797,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2208.00467v1",
        "predicted_newsworthiness":49.1628761968,
        "title":"COCOA: Cross Modality Contrastive Learning for Sensor Data",
        "summary":"Self-Supervised Learning (SSL) is a new paradigm for learning discriminative representations without labelled data and has reached comparable or even state-of-the-art results in comparison to supervised counterparts. Contrastive Learning (CL) is one of the most well-known approaches in SSL that attempts to learn general, informative representations of data. CL methods have been mostly developed for applications in computer vision and natural language processing where only a single sensor modality is used. A majority of pervasive computing applications, however, exploit data from a range of different sensor modalities. While existing CL methods are limited to learning from one or two data sources, we propose COCOA (Cross mOdality COntrastive leArning), a self-supervised model that employs a novel objective function to learn quality representations from multisensor data by computing the cross-correlation between different data modalities and minimizing the similarity between irrelevant instances. We evaluate the effectiveness of COCOA against eight recently introduced state-of-the-art self-supervised models, and two supervised baselines across five public datasets. We show that COCOA achieves superior classification performance to all other approaches. Also, COCOA is far more label-efficient than the other baselines including the fully supervised model using only one-tenth of available labelled data.",
        "published":1659285373000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2208.00467v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 31, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1083091974,
        "popularmechanics":0.1466449552,
        "scienmag":0.1489227001,
        "technologyreview":0.2521945927,
        "vox":0.1531116102,
        "newscientist":0.154518956,
        "vice":0.1075318541,
        "statnews":0.2119865305,
        "nytimes":0.1545795032,
        "techcrunch":0.1912099516,
        "quartz":0.1297516903,
        "venturebeat":0.2528682273,
        "futurism":0.1825540608,
        "scientificamerican":0.1340903316,
        "wired":0.2154393477,
        "popsci":0.2205533296,
        "arstechnica":0.1358844843,
        "salon":0.1042898887,
        "washingtonpost":0.1848227328,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.00949v1",
        "predicted_newsworthiness":46.4604983142,
        "title":"Answer-Me: Multi-Task Open-Vocabulary Visual Question Answering",
        "summary":"We present Answer-Me, a task-aware multi-task framework which unifies a variety of question answering tasks, such as, visual question answering, visual entailment, visual reasoning. In contrast to previous works using contrastive or generative captioning training, we propose a novel and simple recipe to pre-train a vision-language joint model, which is multi-task as well. The pre-training uses only noisy image captioning data, and is formulated to use the entire architecture end-to-end with both a strong language encoder and decoder. Our results show state-of-the-art performance, zero-shot generalization, robustness to forgetting, and competitive single-task results across a variety of question answering tasks. Our multi-task mixture training learns from tasks of various question intents and thus generalizes better, including on zero-shot vision-language tasks. We conduct experiments in the challenging multi-task and open-vocabulary settings and across a variety of datasets and tasks, such as VQA2.0, SNLI-VE, NLVR2, GQA, VizWiz. We observe that the proposed approach is able to generalize to unseen tasks and that more diverse mixtures lead to higher accuracy in both known and novel tasks.",
        "published":1651503193000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.00949v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 02, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0843666651,
        "popularmechanics":0.1195658585,
        "scienmag":0.0932932388,
        "technologyreview":0.2176590482,
        "vox":0.1218869105,
        "newscientist":0.1232865646,
        "vice":0.0837197673,
        "statnews":0.1195905329,
        "nytimes":0.1144314355,
        "techcrunch":0.1482305096,
        "quartz":0.1078113109,
        "venturebeat":0.2143321536,
        "futurism":0.1477075836,
        "scientificamerican":0.0974776136,
        "wired":0.1585319777,
        "popsci":0.1574800032,
        "arstechnica":0.1032820839,
        "salon":0.0769882068,
        "washingtonpost":0.1188245777,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.06246v1",
        "predicted_newsworthiness":47.1611501913,
        "title":"A Modular Continuum Manipulator for Aerial Manipulation and Perching",
        "summary":"Most aerial manipulators use serial rigid-link designs, which results in large forces when initiating contacts during manipulation and could cause flight stability difficulty. This limitation could potentially be improved by the compliance of continuum manipulators. To achieve this goal, we present the novel design of a compact, lightweight, and modular cable-driven continuum manipulator for aerial drones. We then derive a complete modeling framework for its kinematics, statics, and stiffness (compliance). The framework is essential for integrating the manipulator to aerial drones. Finally, we report preliminary experimental validations of the hardware prototype, providing insights on its manipulation feasibility. Future work includes the integration and test of the proposed continuum manipulator with aerial drones.",
        "published":1655134109000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.06246v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Jun 13, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0649687845,
        "popularmechanics":0.2305967012,
        "scienmag":0.1242685596,
        "technologyreview":0.1797119204,
        "vox":0.0709309531,
        "newscientist":0.151485464,
        "vice":0.1473525799,
        "statnews":0.052683091,
        "nytimes":0.1194898469,
        "techcrunch":0.1520454337,
        "quartz":0.0825771495,
        "venturebeat":0.1518893262,
        "futurism":0.2067182545,
        "scientificamerican":0.1216931511,
        "wired":0.1723849086,
        "popsci":0.2879052286,
        "arstechnica":0.1600155141,
        "salon":0.0622398205,
        "washingtonpost":0.1559039192,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.12962v1",
        "predicted_newsworthiness":76.0712002407,
        "title":"How Do Mothers and Fathers Talk About Parenting to Different Audiences?: Stereotypes and Audience Effects: An Analysis of r\/Daddit, r\/Mommit, and r\/Parenting Using Topic Modelling",
        "summary":"While major strides have been made towards gender equality in public life, serious inequality remains in the domestic sphere, especially around parenting. The present study analyses discussions about parenting on Reddit to explore audience effects and gender stereotypes. It suggests a novel method to study topical variation in individuals' language when interacting with different audiences. Comments posted in 2020 were collected from three parenting subreddits, described as being for fathers (r\/Daddit), mothers (r\/Mommit), and all parents (r\/Parenting). Users posting on r\/Parenting and r\/Daddit or on r\/Parenting and r\/Mommit were assumed to identify as fathers or mothers, respectively, allowing gender comparison. Users' comments on r\/Parenting (to a mixed-gender audience) were compared with their comments to single-gender audiences on r\/Daddit or r\/Mommit using LDA topic modelling. Results showed that the most discussed topic among parents is about education and family advice, a topic mainly discussed in the mixed-gender subreddit and more by fathers than mothers. Regarding the basic needs of children (sleep, food, and medical care), mothers seemed to be more concerned regardless of the audience. In contrast, topics such as birth and pregnancy announcements and physical appearance were more discussed by fathers in the father-centric subreddit. Overall, findings seem to show that mothers are generally more concerned about the practical sides of parenting while fathers' expressed concerns are more contextual: with other fathers, there seems to be a desire to show their fatherhood and be recognized for it while they discuss education with mothers. These results demonstrate that concerns expressed by parents on Reddit are context-sensitive but also consistent with gender stereotypes, potentially reflecting a persistent gendered and unequal division of labour in parenting.",
        "published":1645821335000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.12962v1",
        "arxiv_primary_category":"cs.cy",
        "published_hr":"Feb 25, 2022",
        "arxiv_primary_category_hr":"Computers and Society",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2976425172,
        "popularmechanics":0.1318010826,
        "scienmag":0.2540534013,
        "technologyreview":0.2794596849,
        "vox":0.3019972837,
        "newscientist":0.2166991726,
        "vice":0.1640263513,
        "statnews":0.219954242,
        "nytimes":0.2803783822,
        "techcrunch":0.2340921062,
        "quartz":0.2879057956,
        "venturebeat":0.2301241054,
        "futurism":0.1990262049,
        "scientificamerican":0.2434087621,
        "wired":0.3059973118,
        "popsci":0.2281481008,
        "arstechnica":0.216633155,
        "salon":0.2849116182,
        "washingtonpost":0.3018447547,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.07389v1",
        "predicted_newsworthiness":46.6070479027,
        "title":"Ultra Fast Deep Lane Detection with Hybrid Anchor Driven Ordinal Classification",
        "summary":"Modern methods mainly regard lane detection as a problem of pixel-wise segmentation, which is struggling to address the problems of efficiency and challenging scenarios like severe occlusions and extreme lighting conditions. Inspired by human perception, the recognition of lanes under severe occlusions and extreme lighting conditions is mainly based on contextual and global information. Motivated by this observation, we propose a novel, simple, yet effective formulation aiming at ultra fast speed and the problem of challenging scenarios. Specifically, we treat the process of lane detection as an anchor-driven ordinal classification problem using global features. First, we represent lanes with sparse coordinates on a series of hybrid (row and column) anchors. With the help of the anchor-driven representation, we then reformulate the lane detection task as an ordinal classification problem to get the coordinates of lanes. Our method could significantly reduce the computational cost with the anchor-driven representation. Using the large receptive field property of the ordinal classification formulation, we could also handle challenging scenarios. Extensive experiments on four lane detection datasets show that our method could achieve state-of-the-art performance in terms of both speed and accuracy. A lightweight version could even achieve 300+ frames per second(FPS). Our code is at https:\/\/github.com\/cfzd\/Ultra-Fast-Lane-Detection-v2.",
        "published":1655283182000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.07389v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jun 15, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0862058467,
        "popularmechanics":0.1760079973,
        "scienmag":0.1047650776,
        "technologyreview":0.2037512864,
        "vox":0.1154904742,
        "newscientist":0.1177283354,
        "vice":0.0941330118,
        "statnews":0.0876927414,
        "nytimes":0.1098989865,
        "techcrunch":0.170649242,
        "quartz":0.117008408,
        "venturebeat":0.1967834898,
        "futurism":0.1892388475,
        "scientificamerican":0.0977443308,
        "wired":0.1816002053,
        "popsci":0.2202456077,
        "arstechnica":0.1080171714,
        "salon":0.0765590344,
        "washingtonpost":0.1307865924,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.16762v1",
        "predicted_newsworthiness":73.9378403926,
        "title":"Mapping Topics in 100,000 Real-life Moral Dilemmas",
        "summary":"Moral dilemmas play an important role in theorizing both about ethical norms and moral psychology. Yet thought experiments borrowed from the philosophical literature often lack the nuances and complexity of real life. We leverage 100,000 threads -- the largest collection to date -- from Reddit's r\/AmItheAsshole to examine the features of everyday moral dilemmas. Combining topic modeling with evaluation from both expert and crowd-sourced workers, we discover 47 finer-grained, meaningful topics and group them into five meta-categories. We show that most dilemmas combine at least two topics, such as family and money. We also observe that the pattern of topic co-occurrence carries interesting information about the structure of everyday moral concerns: for example, the generation of moral dilemmas from nominally neutral topics, and interaction effects in which final verdicts do not line up with the moral concerns in the original stories in any simple way. Our analysis demonstrates the utility of a fine-grained data-driven approach to online moral dilemmas, and provides a valuable resource for researchers aiming to explore the intersection of practical and theoretical ethics.",
        "published":1648694162000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.16762v1",
        "arxiv_primary_category":"cs.si",
        "published_hr":"Mar 30, 2022",
        "arxiv_primary_category_hr":"Social and Information Networks",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2676496984,
        "popularmechanics":0.1639103575,
        "scienmag":0.2118775533,
        "technologyreview":0.321654354,
        "vox":0.3116478862,
        "newscientist":0.2330592213,
        "vice":0.1695381832,
        "statnews":0.265665992,
        "nytimes":0.2905736708,
        "techcrunch":0.255635698,
        "quartz":0.2676317547,
        "venturebeat":0.2674059134,
        "futurism":0.2414634528,
        "scientificamerican":0.2378397794,
        "wired":0.3241255455,
        "popsci":0.2587099527,
        "arstechnica":0.2522011263,
        "salon":0.2640645121,
        "washingtonpost":0.3259436412,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.04937v1",
        "predicted_newsworthiness":50.4416933852,
        "title":"Assessment of Massively Multilingual Sentiment Classifiers",
        "summary":"Models are increasing in size and complexity in the hunt for SOTA. But what if those 2\\% increase in performance does not make a difference in a production use case? Maybe benefits from a smaller, faster model outweigh those slight performance gains. Also, equally good performance across languages in multilingual tasks is more important than SOTA results on a single one. We present the biggest, unified, multilingual collection of sentiment analysis datasets. We use these to assess 11 models and 80 high-quality sentiment datasets (out of 342 raw datasets collected) in 27 languages and included results on the internally annotated datasets. We deeply evaluate multiple setups, including fine-tuning transformer-based models for measuring performance. We compare results in numerous dimensions addressing the imbalance in both languages coverage and dataset sizes. Finally, we present some best practices for working with such a massive collection of datasets and models from a multilingual perspective.",
        "published":1649665325000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.04937v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Apr 11, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1693362306,
        "popularmechanics":0.129513029,
        "scienmag":0.1559323221,
        "technologyreview":0.2678798645,
        "vox":0.2203173982,
        "newscientist":0.1613089013,
        "vice":0.1222224338,
        "statnews":0.2218201591,
        "nytimes":0.192539001,
        "techcrunch":0.21149459,
        "quartz":0.1972655644,
        "venturebeat":0.2640910142,
        "futurism":0.1889462966,
        "scientificamerican":0.1579393038,
        "wired":0.2187458379,
        "popsci":0.1910457646,
        "arstechnica":0.1693856987,
        "salon":0.1521500439,
        "washingtonpost":0.2176683037,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.02279v1",
        "predicted_newsworthiness":46.2155004182,
        "title":"Leveraging Trajectory Prediction for Pedestrian Video Anomaly Detection",
        "summary":"Video anomaly detection is a core problem in vision. Correctly detecting and identifying anomalous behaviors in pedestrians from video data will enable safety-critical applications such as surveillance, activity monitoring, and human-robot interaction. In this paper, we propose to leverage trajectory localization and prediction for unsupervised pedestrian anomaly event detection. Different than previous reconstruction-based approaches, our proposed framework rely on the prediction errors of normal and abnormal pedestrian trajectories to detect anomalies spatially and temporally. We present experimental results on real-world benchmark datasets on varying timescales and show that our proposed trajectory-predictor-based anomaly detection pipeline is effective and efficient at identifying anomalous activities of pedestrians in videos. Code will be made available at https:\/\/github.com\/akanuasiegbu\/Leveraging-Trajectory-Prediction-for-Pedestrian-Video-Anomaly-Detection.",
        "published":1657050274000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.02279v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 05, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1244772585,
        "popularmechanics":0.167933147,
        "scienmag":0.1301615514,
        "technologyreview":0.2198070313,
        "vox":0.1428243992,
        "newscientist":0.16053952,
        "vice":0.1577486827,
        "statnews":0.1376687812,
        "nytimes":0.1523604762,
        "techcrunch":0.1692930302,
        "quartz":0.1389351848,
        "venturebeat":0.1967299171,
        "futurism":0.1935197002,
        "scientificamerican":0.1597531571,
        "wired":0.180801736,
        "popsci":0.1978028391,
        "arstechnica":0.1397805239,
        "salon":0.1218967273,
        "washingtonpost":0.1864782189,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.00278v1",
        "predicted_newsworthiness":53.2133976215,
        "title":"Slice-Aware Resource Calendaring in Cloud-based Radio Access Networks",
        "summary":"Network slicing has been introduced in 5G\/6G networks to address the challenge of providing new services with different and sometimes conflicting requirements. With SDN and NFV technologies being used in the design of 5G and 6G wireless network slicing, as well as the centralization of control over these technologies, new services such as resource calendaring can also be used in wireless networks. In bandwidth calendaring, traffic with a low latency sensitivity and a high volume is shifted to later time slots so that applications with a high latency sensitivity can be served instead. We discuss how to calendar radio resources in the C-RAN architecture, which also makes use of network slicing. This is referred to as Slice-Aware Radio Resource Calendaring. A model of the problem is developed as an ILP problem and two heuristic algorithms are proposed for solving it due to complexity of optimal solution. Observations have shown that when resources are shared between tenants, the number of accepted requests increases.",
        "published":1646120800000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.00278v1",
        "arxiv_primary_category":"cs.ni",
        "published_hr":"Mar 01, 2022",
        "arxiv_primary_category_hr":"Networking and Internet Architecture",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0916321965,
        "popularmechanics":0.1370667111,
        "scienmag":0.0812235877,
        "technologyreview":0.1631004947,
        "vox":0.1727254464,
        "newscientist":0.0913062608,
        "vice":0.1077700722,
        "statnews":0.1250240295,
        "nytimes":0.1260571603,
        "techcrunch":0.2115050798,
        "quartz":0.1480271701,
        "venturebeat":0.2243391302,
        "futurism":0.1315081817,
        "scientificamerican":0.0853113209,
        "wired":0.1668550993,
        "popsci":0.1738697621,
        "arstechnica":0.1886792243,
        "salon":0.1044982712,
        "washingtonpost":0.1637320795,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.04575v1",
        "predicted_newsworthiness":43.4289031757,
        "title":"Soft Robots Learn to Crawl: Jointly Optimizing Design and Control with Sim-to-Real Transfer",
        "summary":"This work provides a complete framework for the simulation, co-optimization, and sim-to-real transfer of the design and control of soft legged robots. The compliance of soft robots provides a form of \"mechanical intelligence\" -- the ability to passively exhibit behaviors that would otherwise be difficult to program. Exploiting this capacity requires careful consideration of the coupling between mechanical design and control. Co-optimization provides a promising means to generate sophisticated soft robots by reasoning over this coupling. However, the complex nature of soft robot dynamics makes it difficult to provide a simulation environment that is both sufficiently accurate to allow for sim-to-real transfer, while also being fast enough for contemporary co-optimization algorithms. In this work, we show that finite element simulation combined with recent model order reduction techniques provide both the efficiency and the accuracy required to successfully learn effective soft robot design-control pairs that transfer to reality. We propose a reinforcement learning-based framework for co-optimization and demonstrate successful optimization, construction, and zero-shot sim-to-real transfer of several soft crawling robots. Our learned robot outperforms an expert-designed crawling robot, showing that our approach can generate novel, high-performing designs even in well-understood domains.",
        "published":1644426884000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.04575v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Feb 09, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0765073054,
        "popularmechanics":0.1903573453,
        "scienmag":0.1825587556,
        "technologyreview":0.2317293743,
        "vox":0.0827076952,
        "newscientist":0.1768563691,
        "vice":0.1595390545,
        "statnews":0.1282437411,
        "nytimes":0.1335589099,
        "techcrunch":0.1451986549,
        "quartz":0.0866689289,
        "venturebeat":0.1714133609,
        "futurism":0.2111648814,
        "scientificamerican":0.1539790189,
        "wired":0.1697242046,
        "popsci":0.2404112026,
        "arstechnica":0.1196305387,
        "salon":0.0723038341,
        "washingtonpost":0.1318349668,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.00995v1",
        "predicted_newsworthiness":50.6126820735,
        "title":"Learning Efficiently Function Approximation for Contextual MDP",
        "summary":"We study learning contextual MDPs using a function approximation for both the rewards and the dynamics. We consider both the case where the dynamics is known and unknown, and the case that the dynamics dependent or independent of the context. For all four models we derive polynomial sample and time complexity (assuming an efficient ERM oracle). Our methodology gives a general reduction from learning contextual MDP to supervised learning.",
        "published":1646215315000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.00995v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Mar 02, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0567800324,
        "popularmechanics":0.1013291871,
        "scienmag":0.0768088826,
        "technologyreview":0.1735391117,
        "vox":0.0732785161,
        "newscientist":0.0928604783,
        "vice":0.0846257856,
        "statnews":0.1305080295,
        "nytimes":0.0945713196,
        "techcrunch":0.1187585684,
        "quartz":0.0755558945,
        "venturebeat":0.1665717833,
        "futurism":0.1223396019,
        "scientificamerican":0.0679401716,
        "wired":0.1145257473,
        "popsci":0.1177831224,
        "arstechnica":0.0784057169,
        "salon":0.0556792053,
        "washingtonpost":0.0917919706,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.04588v1",
        "predicted_newsworthiness":36.5108213833,
        "title":"Robust Cross-Modal Representation Learning with Progressive Self-Distillation",
        "summary":"The learning objective of vision-language approach of CLIP does not effectively account for the noisy many-to-many correspondences found in web-harvested image captioning datasets, which contributes to its compute and data inefficiency. To address this challenge, we introduce a novel training framework based on cross-modal contrastive learning that uses progressive self-distillation and soft image-text alignments to more efficiently learn robust representations from noisy data. Our model distills its own knowledge to dynamically generate soft-alignment targets for a subset of images and captions in every minibatch, which are then used to update its parameters. Extensive evaluation across 14 benchmark datasets shows that our method consistently outperforms its CLIP counterpart in multiple settings, including: (a) zero-shot classification, (b) linear probe transfer, and (c) image-text retrieval, without incurring added computational cost. Analysis using an ImageNet-based robustness test-bed reveals that our method offers better effective robustness to natural distribution shifts compared to both ImageNet-trained models and CLIP itself. Lastly, pretraining with datasets spanning two orders of magnitude in size shows that our improvements over CLIP tend to scale with number of training examples.",
        "published":1649561298000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.04588v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Apr 09, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.107044345,
        "popularmechanics":0.1200945797,
        "scienmag":0.097394363,
        "technologyreview":0.2244682003,
        "vox":0.1472471637,
        "newscientist":0.1207702318,
        "vice":0.0955802664,
        "statnews":0.1219875635,
        "nytimes":0.131100861,
        "techcrunch":0.1455651293,
        "quartz":0.1307423709,
        "venturebeat":0.2077224985,
        "futurism":0.1484508847,
        "scientificamerican":0.102338942,
        "wired":0.164474597,
        "popsci":0.1539310079,
        "arstechnica":0.1232856129,
        "salon":0.0960251482,
        "washingtonpost":0.1473695971,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.00266v1",
        "predicted_newsworthiness":42.3433782769,
        "title":"Multifaceted Improvements for Conversational Open-Domain Question Answering",
        "summary":"Open-domain question answering (OpenQA) is an important branch of textual QA which discovers answers for the given questions based on a large number of unstructured documents. Effectively mining correct answers from the open-domain sources still has a fair way to go. Existing OpenQA systems might suffer from the issues of question complexity and ambiguity, as well as insufficient background knowledge. Recently, conversational OpenQA is proposed to address these issues with the abundant contextual information in the conversation. Promising as it might be, there exist several fundamental limitations including the inaccurate question understanding, the coarse ranking for passage selection, and the inconsistent usage of golden passage in the training and inference phases. To alleviate these limitations, in this paper, we propose a framework with Multifaceted Improvements for Conversational open-domain Question Answering (MICQA). Specifically, MICQA has three significant advantages. First, the proposed KL-divergence based regularization is able to lead to a better question understanding for retrieval and answer reading. Second, the added post-ranker module can push more relevant passages to the top placements and be selected for reader with a two-aspect constrains. Third, the well designed curriculum learning strategy effectively narrows the gap between the golden passage settings of training and inference, and encourages the reader to find true answer without the golden passage assistance. Extensive experiments conducted on the publicly available dataset OR-QuAC demonstrate the superiority of MICQA over the state-of-the-art model in conversational OpenQA task.",
        "published":1648799667000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.00266v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Apr 01, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.108194619,
        "popularmechanics":0.0940119735,
        "scienmag":0.103838973,
        "technologyreview":0.2033358432,
        "vox":0.1520673619,
        "newscientist":0.1121112625,
        "vice":0.0841545935,
        "statnews":0.1649350278,
        "nytimes":0.1342871111,
        "techcrunch":0.1559829254,
        "quartz":0.1222589762,
        "venturebeat":0.2134120456,
        "futurism":0.1342420763,
        "scientificamerican":0.0984499438,
        "wired":0.1633338467,
        "popsci":0.1409401244,
        "arstechnica":0.1185276741,
        "salon":0.092429316,
        "washingtonpost":0.1231468362,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.05922v1",
        "predicted_newsworthiness":63.2305007875,
        "title":"Addressing the Challenges of Cross-Lingual Hate Speech Detection",
        "summary":"The goal of hate speech detection is to filter negative online content aiming at certain groups of people. Due to the easy accessibility of social media platforms it is crucial to protect everyone which requires building hate speech detection systems for a wide range of languages. However, the available labeled hate speech datasets are limited making it problematic to build systems for many languages. In this paper we focus on cross-lingual transfer learning to support hate speech detection in low-resource languages. We leverage cross-lingual word embeddings to train our neural network systems on the source language and apply it to the target language, which lacks labeled examples, and show that good performance can be achieved. We then incorporate unlabeled target language data for further model improvements by bootstrapping labels using an ensemble of different model architectures. Furthermore, we investigate the issue of label imbalance of hate speech datasets, since the high ratio of non-hate examples compared to hate examples often leads to low model performance. We test simple data undersampling and oversampling techniques and show their effectiveness.",
        "published":1642279694000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.05922v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Jan 15, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2020081174,
        "popularmechanics":0.1174514476,
        "scienmag":0.1474269024,
        "technologyreview":0.3010227574,
        "vox":0.2430584068,
        "newscientist":0.1698361614,
        "vice":0.0995578826,
        "statnews":0.1983897991,
        "nytimes":0.2026292963,
        "techcrunch":0.2075848344,
        "quartz":0.2150131974,
        "venturebeat":0.2620454885,
        "futurism":0.1998009379,
        "scientificamerican":0.1485416757,
        "wired":0.2580379312,
        "popsci":0.1980609007,
        "arstechnica":0.2045960691,
        "salon":0.1600795573,
        "washingtonpost":0.2908584032,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.10432v1",
        "predicted_newsworthiness":52.955011845,
        "title":"Reasoning with Scene Graphs for Robot Planning under Partial Observability",
        "summary":"Robot planning in partially observable domains is difficult, because a robot needs to estimate the current state and plan actions at the same time. When the domain includes many objects, reasoning about the objects and their relationships makes robot planning even more difficult. In this paper, we develop an algorithm called scene analysis for robot planning (SARP) that enables robots to reason with visual contextual information toward achieving long-term goals under uncertainty. SARP constructs scene graphs, a factored representation of objects and their relations, using images captured from different positions, and reasons with them to enable context-aware robot planning under partial observability. Experiments have been conducted using multiple 3D environments in simulation, and a dataset collected by a real robot. In comparison to standard robot planning and scene analysis methods, in a target search domain, SARP improves both efficiency and accuracy in task completion. Supplementary material can be found at https:\/\/tinyurl.com\/sarp22",
        "published":1645469156000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.10432v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Feb 21, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.087055201,
        "popularmechanics":0.1617862967,
        "scienmag":0.1132794575,
        "technologyreview":0.2413287537,
        "vox":0.1091541023,
        "newscientist":0.1520922533,
        "vice":0.1480961303,
        "statnews":0.1479417496,
        "nytimes":0.1462026722,
        "techcrunch":0.1696715331,
        "quartz":0.1028360618,
        "venturebeat":0.2123369285,
        "futurism":0.1867368035,
        "scientificamerican":0.1156687223,
        "wired":0.1842256605,
        "popsci":0.2090158817,
        "arstechnica":0.1166802646,
        "salon":0.092864495,
        "washingtonpost":0.1349203178,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.02978v1",
        "predicted_newsworthiness":35.635928392,
        "title":"Enhancing Dual-Encoders with Question and Answer Cross-Embeddings for Answer Retrieval",
        "summary":"Dual-Encoders is a promising mechanism for answer retrieval in question answering (QA) systems. Currently most conventional Dual-Encoders learn the semantic representations of questions and answers merely through matching score. Researchers proposed to introduce the QA interaction features in scoring function but at the cost of low efficiency in inference stage. To keep independent encoding of questions and answers during inference stage, variational auto-encoder is further introduced to reconstruct answers (questions) from question (answer) embeddings as an auxiliary task to enhance QA interaction in representation learning in training stage. However, the needs of text generation and answer retrieval are different, which leads to hardness in training. In this work, we propose a framework to enhance the Dual-Encoders model with question answer cross-embeddings and a novel Geometry Alignment Mechanism (GAM) to align the geometry of embeddings from Dual-Encoders with that from Cross-Encoders. Extensive experimental results show that our framework significantly improves Dual-Encoders model and outperforms the state-of-the-art method on multiple answer retrieval datasets.",
        "published":1654569564000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.02978v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Jun 06, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0697152655,
        "popularmechanics":0.0824488322,
        "scienmag":0.0868123222,
        "technologyreview":0.1560632509,
        "vox":0.0874840348,
        "newscientist":0.0923522158,
        "vice":0.0778284126,
        "statnews":0.1036552898,
        "nytimes":0.0874917514,
        "techcrunch":0.1108509822,
        "quartz":0.0742763458,
        "venturebeat":0.1588829466,
        "futurism":0.0989292447,
        "scientificamerican":0.0722965308,
        "wired":0.1141814537,
        "popsci":0.1016893998,
        "arstechnica":0.0817937781,
        "salon":0.0528257338,
        "washingtonpost":0.0832291731,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.08064v1",
        "predicted_newsworthiness":48.9871191718,
        "title":"Detecting Humans in RGB-D Data with CNNs",
        "summary":"We address the problem of people detection in RGB-D data where we leverage depth information to develop a region-of-interest (ROI) selection method that provides proposals to two color and depth CNNs. To combine the detections produced by the two CNNs, we propose a novel fusion approach based on the characteristics of depth images. We also present a new depth-encoding scheme, which not only encodes depth images into three channels but also enhances the information for classification. We conduct experiments on a publicly available RGB-D people dataset and show that our approach outperforms the baseline models that only use RGB data.",
        "published":1658027829000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.08064v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 16, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0982988739,
        "popularmechanics":0.1369259108,
        "scienmag":0.114402062,
        "technologyreview":0.1966778925,
        "vox":0.1162193677,
        "newscientist":0.1369520964,
        "vice":0.1259083245,
        "statnews":0.1064865161,
        "nytimes":0.1198857222,
        "techcrunch":0.1461304604,
        "quartz":0.1125610575,
        "venturebeat":0.1758973597,
        "futurism":0.1552524776,
        "scientificamerican":0.1143147364,
        "wired":0.1443438065,
        "popsci":0.1626132377,
        "arstechnica":0.1101331137,
        "salon":0.0954128656,
        "washingtonpost":0.1408454537,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.04240v1",
        "predicted_newsworthiness":68.1063365011,
        "title":"Controlling Traffic with Humanoid Social Robot",
        "summary":"The advancement of technology such as artificial intelligence, machine learning and internet of things it became easy to develop more humanoid robots and automate different processes. An interactive robot must have high social behavior so that it can be easily accepted by the people using it. In this study we designed a traffic police robot (TRAPROB) to automate the traffic control at intersection. The human police officer experiences high stress because of long duty hours as well as pose the risk of accidents. The digital electronic signals are automatic but we want to create a system which is more human like and looks like an officer controlling the traffic at intersection. We used Thiago++ robot in this study and modified its look to like a police officer, and then programmed it to imitate and make gestures just like traffic police officer makes gestures for controlling traffic. We evaluated the looks, gestures, functionality, and social behavior of the robot. We asked a limited sample of two participants to identify the TRAPBOT, rate its look, the social behaviors and gestures in comparison to a real life police officer. we found that people can identify the robot as traffic police robot. Our analysis also shows that TRAPBOT has appearance like a traffic robot and can make similar signal gestures as a traffic police officer.",
        "published":1649442281000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.04240v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Apr 08, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1753717882,
        "popularmechanics":0.2480154086,
        "scienmag":0.1969984259,
        "technologyreview":0.3502782713,
        "vox":0.2098427632,
        "newscientist":0.2389860849,
        "vice":0.1563819183,
        "statnews":0.1943260589,
        "nytimes":0.2379430125,
        "techcrunch":0.2695994959,
        "quartz":0.2020875896,
        "venturebeat":0.3079607119,
        "futurism":0.3246472959,
        "scientificamerican":0.2126830648,
        "wired":0.2942519305,
        "popsci":0.3148654691,
        "arstechnica":0.1835505333,
        "salon":0.1441556223,
        "washingtonpost":0.2677382112,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.08237v1",
        "predicted_newsworthiness":49.369768227,
        "title":"Noisy Learning for Neural ODEs Acts as a Robustness Locus Widening",
        "summary":"We investigate the problems and challenges of evaluating the robustness of Differential Equation-based (DE) networks against synthetic distribution shifts. We propose a novel and simple accuracy metric which can be used to evaluate intrinsic robustness and to validate dataset corruption simulators. We also propose methodology recommendations, destined for evaluating the many faces of neural DEs' robustness and for comparing them with their discrete counterparts rigorously. We then use this criteria to evaluate a cheap data augmentation technique as a reliable way for demonstrating the natural robustness of neural ODEs against simulated image corruptions across multiple datasets.",
        "published":1655392238000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.08237v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jun 16, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1053214809,
        "popularmechanics":0.1538755886,
        "scienmag":0.1588665437,
        "technologyreview":0.2572081019,
        "vox":0.1191717999,
        "newscientist":0.1583982965,
        "vice":0.1433408936,
        "statnews":0.1893220233,
        "nytimes":0.1371041991,
        "techcrunch":0.1450951786,
        "quartz":0.1150357993,
        "venturebeat":0.208756037,
        "futurism":0.1856394286,
        "scientificamerican":0.1463374998,
        "wired":0.1707319739,
        "popsci":0.1723087411,
        "arstechnica":0.141517357,
        "salon":0.1122832603,
        "washingtonpost":0.1426335249,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.00214v1",
        "predicted_newsworthiness":49.5549242499,
        "title":"LiDAR-MIMO: Efficient Uncertainty Estimation for LiDAR-based 3D Object Detection",
        "summary":"The estimation of uncertainty in robotic vision, such as 3D object detection, is an essential component in developing safe autonomous systems aware of their own performance. However, the deployment of current uncertainty estimation methods in 3D object detection remains challenging due to timing and computational constraints. To tackle this issue, we propose LiDAR-MIMO, an adaptation of the multi-input multi-output (MIMO) uncertainty estimation method to the LiDAR-based 3D object detection task. Our method modifies the original MIMO by performing multi-input at the feature level to ensure the detection, uncertainty estimation, and runtime performance benefits are retained despite the limited capacity of the underlying detector and the large computational costs of point cloud processing. We compare LiDAR-MIMO with MC dropout and ensembles as baselines and show comparable uncertainty estimation results with only a small number of output heads. Further, LiDAR-MIMO can be configured to be twice as fast as MC dropout and ensembles, while achieving higher mAP than MC dropout and approaching that of ensembles.",
        "published":1654055252000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.00214v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 31, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0914785548,
        "popularmechanics":0.209552992,
        "scienmag":0.1430510758,
        "technologyreview":0.2328357941,
        "vox":0.1433133028,
        "newscientist":0.1577445997,
        "vice":0.1805015268,
        "statnews":0.1096478409,
        "nytimes":0.1522256141,
        "techcrunch":0.2044002783,
        "quartz":0.1257279136,
        "venturebeat":0.2223935132,
        "futurism":0.2193531619,
        "scientificamerican":0.1337853426,
        "wired":0.2013351824,
        "popsci":0.2366168487,
        "arstechnica":0.160468339,
        "salon":0.1113253902,
        "washingtonpost":0.1761312703,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.05055v2",
        "predicted_newsworthiness":52.1340517244,
        "title":"WeShort: Out-of-distribution Detection With Weak Shortcut structure",
        "summary":"Neural networks have achieved impressive performance for data in the distribution which is the same as the training set but can produce an overconfident incorrect result for the data these networks have never seen. Therefore, it is essential to detect whether inputs come from out-of-distribution(OOD) in order to guarantee the safety of neural networks deployed in the real world. In this paper, we propose a simple and effective post-hoc technique, WeShort, to reduce the overconfidence of neural networks on OOD data. Our method is inspired by the observation of the internal residual structure, which shows the separation of the OOD and in-distribution (ID) data in the shortcut layer. Our method is compatible with different OOD detection scores and can generalize well to different architectures of networks. We demonstrate our method on various OOD datasets to show its competitive performances and provide reasonable hypotheses to explain why our method works. On the ImageNet benchmark, Weshort achieves state-of-the-art performance on the false positive rate (FPR95) and the area under the receiver operating characteristic (AUROC) on the family of post-hoc methods.",
        "published":1655971150000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.05055v2",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jun 23, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0874576281,
        "popularmechanics":0.1637346132,
        "scienmag":0.1461070753,
        "technologyreview":0.2453448972,
        "vox":0.1197835161,
        "newscientist":0.1489784006,
        "vice":0.1329995515,
        "statnews":0.2020650637,
        "nytimes":0.134019574,
        "techcrunch":0.1631563129,
        "quartz":0.1137840841,
        "venturebeat":0.223798728,
        "futurism":0.1755231319,
        "scientificamerican":0.1179348809,
        "wired":0.1600758803,
        "popsci":0.1874136839,
        "arstechnica":0.1480833705,
        "salon":0.0945001302,
        "washingtonpost":0.1604882454,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.03312v1",
        "predicted_newsworthiness":38.7309024818,
        "title":"Neither Fast Nor Slow: How to Fly Through Narrow Tunnels",
        "summary":"Nowadays, multirotors are playing important roles in abundant types of missions. During these missions, entering confined and narrow tunnels that are barely accessible to humans is desirable yet extremely challenging for multirotors. The restricted space and significant ego airflow disturbances induce control issues at both fast and slow flight speeds, meanwhile bringing about problems in state estimation and perception. Thus, a smooth trajectory at a proper speed is necessary for safe tunnel flights. To address these challenges, in this letter, a complete autonomous aerial system that can fly smoothly through tunnels with dimensions narrow to 0.6 m is presented. The system contains a motion planner that generates smooth mini-jerk trajectories along the tunnel center lines, which are extracted according to the map and Euclidean Distance Field (EDF), and its practical speed range is obtained through computational fluid dynamics (CFD) and flight data analyses. Extensive flight experiments on the quadrotor are conducted inside multiple narrow tunnels to validate the planning framework as well as the robustness of the whole system.",
        "published":1641817632000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.03312v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Jan 10, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0798300595,
        "popularmechanics":0.248833123,
        "scienmag":0.0979811036,
        "technologyreview":0.184563699,
        "vox":0.0946710862,
        "newscientist":0.1495612942,
        "vice":0.2091696135,
        "statnews":0.053972878,
        "nytimes":0.1516997703,
        "techcrunch":0.1579293996,
        "quartz":0.0986723727,
        "venturebeat":0.1736985625,
        "futurism":0.2196210492,
        "scientificamerican":0.1269480805,
        "wired":0.1954450456,
        "popsci":0.287835123,
        "arstechnica":0.1847877175,
        "salon":0.0854903363,
        "washingtonpost":0.1778624031,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.10983v1",
        "predicted_newsworthiness":47.7736590948,
        "title":"Online POI Recommendation: Learning Dynamic Geo-Human Interactions in Streams",
        "summary":"In this paper, we focus on the problem of modeling dynamic geo-human interactions in streams for online POI recommendations. Specifically, we formulate the in-stream geo-human interaction modeling problem into a novel deep interactive reinforcement learning framework, where an agent is a recommender and an action is a next POI to visit. We uniquely model the reinforcement learning environment as a joint and connected composition of users and geospatial contexts (POIs, POI categories, functional zones). An event that a user visits a POI in stream updates the states of both users and geospatial contexts; the agent perceives the updated environment state to make online recommendations. Specifically, we model a mixed-user event stream by unifying all users, visits, and geospatial contexts as a dynamic knowledge graph stream, in order to model human-human, geo-human, geo-geo interactions. We design an exit mechanism to address the expired information challenge, devise a meta-path method to address the recommendation candidate generation challenge, and develop a new deep policy network structure to address the varying action space challenge, and, finally, propose an effective adversarial training method for optimization. Finally, we present extensive experiments to demonstrate the enhanced performance of our method.",
        "published":1642610989000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.10983v1",
        "arxiv_primary_category":"cs.ir",
        "published_hr":"Jan 19, 2022",
        "arxiv_primary_category_hr":"Information Retrieval",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1522455043,
        "popularmechanics":0.137629305,
        "scienmag":0.1496212938,
        "technologyreview":0.2551360685,
        "vox":0.2122292507,
        "newscientist":0.1625338975,
        "vice":0.1294238117,
        "statnews":0.1998908362,
        "nytimes":0.1932652627,
        "techcrunch":0.2199732767,
        "quartz":0.1801250001,
        "venturebeat":0.2606111452,
        "futurism":0.1903115862,
        "scientificamerican":0.1457537794,
        "wired":0.232228116,
        "popsci":0.2134986819,
        "arstechnica":0.1650141878,
        "salon":0.1482586299,
        "washingtonpost":0.2042128247,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.07205v2",
        "predicted_newsworthiness":62.4069226052,
        "title":"Expanding the Reach of Research Computing: A Landscape Study",
        "summary":"Research-computing continues to play an ever increasing role in academia. Access to computing resources, however, varies greatly between institutions. Sustaining the growing need for computing skills and access to advanced cyberinfrastructure requires that computing resources be available to students at all levels of scholarship, including community colleges. The National Science Foundation-funded Building Research Innovation in Community Colleges (BRICCs) community set out to understand the challenges faced by administrators, researchers and faculty in building a sustainable research computing continuum that extends to smaller and two-year terminal degree granting institutions. BRICCs purpose is to address the technology gaps, and encourage the development of curriculum needed to grow a computationally proficient research workforce. Toward addressing these goals, we performed a landscape study that culminated with a community workshop. Here, we present our key findings from workshop discussions and identify next steps to be taken by BRICCs, funding agencies, and the broader cyberinfrastructure community.",
        "published":1649966008000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.07205v2",
        "arxiv_primary_category":"cs.si",
        "published_hr":"Apr 14, 2022",
        "arxiv_primary_category_hr":"Social and Information Networks",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2546884249,
        "popularmechanics":0.2229639957,
        "scienmag":0.2912560606,
        "technologyreview":0.3615545461,
        "vox":0.2963104824,
        "newscientist":0.2444062586,
        "vice":0.2534472013,
        "statnews":0.3273628069,
        "nytimes":0.343782239,
        "techcrunch":0.3332027656,
        "quartz":0.2641568042,
        "venturebeat":0.3272529849,
        "futurism":0.2847910653,
        "scientificamerican":0.2820559226,
        "wired":0.3232656852,
        "popsci":0.3080825815,
        "arstechnica":0.2662399482,
        "salon":0.2706159498,
        "washingtonpost":0.2617745515,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.02321v1",
        "predicted_newsworthiness":37.6832499861,
        "title":"An Unsupervised Masking Objective for Abstractive Multi-Document News Summarization",
        "summary":"We show that a simple unsupervised masking objective can approach near supervised performance on abstractive multi-document news summarization. Our method trains a state-of-the-art neural summarization model to predict the masked out source document with highest lexical centrality relative to the multi-document group. In experiments on the Multi-News dataset, our masked training objective yields a system that outperforms past unsupervised methods and, in human evaluation, surpasses the best supervised method without requiring access to any ground-truth summaries. Further, we evaluate how different measures of lexical centrality, inspired by past work on extractive summarization, affect final performance.",
        "published":1641529193000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.02321v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Jan 06, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1195581191,
        "popularmechanics":0.0949583838,
        "scienmag":0.1128063994,
        "technologyreview":0.1889332242,
        "vox":0.1621548779,
        "newscientist":0.1217485128,
        "vice":0.0951094997,
        "statnews":0.1453221169,
        "nytimes":0.1457833712,
        "techcrunch":0.1381976447,
        "quartz":0.1314975252,
        "venturebeat":0.1741778884,
        "futurism":0.133536753,
        "scientificamerican":0.1251091005,
        "wired":0.1666732701,
        "popsci":0.1423921157,
        "arstechnica":0.1252892059,
        "salon":0.1173539991,
        "washingtonpost":0.1544218006,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.00277v2",
        "predicted_newsworthiness":45.7102366673,
        "title":"Task-Specific Expert Pruning for Sparse Mixture-of-Experts",
        "summary":"The sparse Mixture-of-Experts (MoE) model is powerful for large-scale pre-training and has achieved promising results due to its model capacity. However, with trillions of parameters, MoE is hard to be deployed on cloud or mobile environment. The inference of MoE requires expert parallelism, which is not hardware-friendly and communication expensive. Especially for resource-limited downstream tasks, such sparse structure has to sacrifice a lot of computing efficiency for limited performance gains. In this work, we observe most experts contribute scarcely little to the MoE fine-tuning and inference. We further propose a general method to progressively drop the non-professional experts for the target downstream task, which preserves the benefits of MoE while reducing the MoE model into one single-expert dense model. Our experiments reveal that the fine-tuned single-expert model could preserve 99.3% benefits from MoE across six different types of tasks while enjoying 2x inference speed with free communication cost.",
        "published":1654067341000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.00277v2",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jun 01, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0812483881,
        "popularmechanics":0.1285245022,
        "scienmag":0.1247155251,
        "technologyreview":0.2805043075,
        "vox":0.1366748205,
        "newscientist":0.1365554086,
        "vice":0.0955255235,
        "statnews":0.2230852198,
        "nytimes":0.1387018043,
        "techcrunch":0.1843007139,
        "quartz":0.1155803718,
        "venturebeat":0.2796673313,
        "futurism":0.1921689962,
        "scientificamerican":0.1053202582,
        "wired":0.1782296665,
        "popsci":0.1854355038,
        "arstechnica":0.1085503175,
        "salon":0.0761853471,
        "washingtonpost":0.1471743621,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.00679v1",
        "predicted_newsworthiness":38.9027120423,
        "title":"Details of Second-Order Partial Derivatives of Rigid-Body Inverse Dynamics",
        "summary":"This document provides full details of second-order partial derivatives of rigid-body inverse dynamics. Several properties and identities using an extension of Spatial Vector Algebra for tensorial use are listed, along with their detailed derivations. Using those, the expressions for second-order derivatives are derived step-by-step in detail. The expressions build upon previous work by the authors on first-order partial derivatives of inverse dynamics.",
        "published":1646161066000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.00679v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Mar 01, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0774428719,
        "popularmechanics":0.1082419573,
        "scienmag":0.0812589509,
        "technologyreview":0.0803627513,
        "vox":0.0381006703,
        "newscientist":0.0886799427,
        "vice":0.102157769,
        "statnews":0.0068190261,
        "nytimes":0.0679297253,
        "techcrunch":0.0552765134,
        "quartz":0.0620006297,
        "venturebeat":0.0815616284,
        "futurism":0.0967100213,
        "scientificamerican":0.0723281286,
        "wired":0.0854157931,
        "popsci":0.1142370445,
        "arstechnica":0.0757364235,
        "salon":0.0540156641,
        "washingtonpost":0.0698252102,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.11786v1",
        "predicted_newsworthiness":53.0338826743,
        "title":"Physics-Informed Learning of Aerosol Microphysics",
        "summary":"Aerosol particles play an important role in the climate system by absorbing and scattering radiation and influencing cloud properties. They are also one of the biggest sources of uncertainty for climate modeling. Many climate models do not include aerosols in sufficient detail due to computational constraints. In order to represent key processes, aerosol microphysical properties and processes have to be accounted for. This is done in the ECHAM-HAM global climate aerosol model using the M7 microphysics, but high computational costs make it very expensive to run with finer resolution or for a longer time. We aim to use machine learning to emulate the microphysics model at sufficient accuracy and reduce the computational cost by being fast at inference time. The original M7 model is used to generate data of input-output pairs to train a neural network on it. We are able to learn the variables' tendencies achieving an average $R^2$ score of $77.1\\% $. We further explore methods to inform and constrain the neural network with physical knowledge to reduce mass violation and enforce mass positivity. On a GPU we achieve a speed-up of up to over 64x compared to the original model.",
        "published":1658687212000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.11786v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jul 24, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1587723629,
        "popularmechanics":0.1792410821,
        "scienmag":0.2478336804,
        "technologyreview":0.2488033154,
        "vox":0.1764664805,
        "newscientist":0.2150090327,
        "vice":0.2402398306,
        "statnews":0.1734432627,
        "nytimes":0.1921118017,
        "techcrunch":0.1328474017,
        "quartz":0.1279861907,
        "venturebeat":0.2094920586,
        "futurism":0.209705168,
        "scientificamerican":0.2100258476,
        "wired":0.1854052834,
        "popsci":0.1672533114,
        "arstechnica":0.1902968386,
        "salon":0.2046425871,
        "washingtonpost":0.1571297299,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.07032v1",
        "predicted_newsworthiness":42.1986077182,
        "title":"Adversarial Attacks on Monocular Pose Estimation",
        "summary":"Advances in deep learning have resulted in steady progress in computer vision with improved accuracy on tasks such as object detection and semantic segmentation. Nevertheless, deep neural networks are vulnerable to adversarial attacks, thus presenting a challenge in reliable deployment. Two of the prominent tasks in 3D scene-understanding for robotics and advanced drive assistance systems are monocular depth and pose estimation, often learned together in an unsupervised manner. While studies evaluating the impact of adversarial attacks on monocular depth estimation exist, a systematic demonstration and analysis of adversarial perturbations against pose estimation are lacking. We show how additive imperceptible perturbations can not only change predictions to increase the trajectory drift but also catastrophically alter its geometry. We also study the relation between adversarial perturbations targeting monocular depth and pose estimation networks, as well as the transferability of perturbations to other networks with different architectures and losses. Our experiments show how the generated perturbations lead to notable errors in relative rotation and translation predictions and elucidate vulnerabilities of the networks.",
        "published":1657815151000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.07032v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 14, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1145443362,
        "popularmechanics":0.1847533991,
        "scienmag":0.1325075726,
        "technologyreview":0.2689082674,
        "vox":0.166784418,
        "newscientist":0.1611290267,
        "vice":0.147943798,
        "statnews":0.1479293343,
        "nytimes":0.1567905087,
        "techcrunch":0.1834855583,
        "quartz":0.1388508184,
        "venturebeat":0.2347215251,
        "futurism":0.2162066058,
        "scientificamerican":0.1399869287,
        "wired":0.2029697271,
        "popsci":0.2100336851,
        "arstechnica":0.1642538108,
        "salon":0.1276618177,
        "washingtonpost":0.1769104469,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.04993v1",
        "predicted_newsworthiness":46.7841008796,
        "title":"Embedding Recycling for Language Models",
        "summary":"Training and inference with large neural models is expensive. However, for many application domains, while new tasks and models arise frequently, the underlying documents being modeled remain mostly unchanged. We study how to decrease computational cost in such settings through embedding recycling (ER): re-using activations from previous model runs when performing training or inference. In contrast to prior work focusing on freezing small classification heads for finetuning which often leads to notable drops in performance, we propose caching an intermediate layer's output from a pretrained model and finetuning the remaining layers for new tasks. We show that our method provides a 100% speedup during training and a 55-86% speedup for inference, and has negligible impacts on accuracy for text classification and entity recognition tasks in the scientific domain. For general-domain question answering tasks, ER offers a similar speedup and lowers accuracy by a small amount. Finally, we identify several open challenges and future directions for ER.",
        "published":1657557374000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.04993v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Jul 11, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0961958364,
        "popularmechanics":0.1256510443,
        "scienmag":0.1178092319,
        "technologyreview":0.245541368,
        "vox":0.1480742069,
        "newscientist":0.1381359701,
        "vice":0.1014635962,
        "statnews":0.1769363562,
        "nytimes":0.135120757,
        "techcrunch":0.161477692,
        "quartz":0.1188349468,
        "venturebeat":0.238301407,
        "futurism":0.1613887665,
        "scientificamerican":0.121714775,
        "wired":0.1741338428,
        "popsci":0.1761768533,
        "arstechnica":0.1214474559,
        "salon":0.1041546061,
        "washingtonpost":0.1338790246,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.03005v2",
        "predicted_newsworthiness":40.7304078948,
        "title":"Semantic-Aware Latent Space Exploration for Face Image Restoration",
        "summary":"For image restoration, the majority of existing deep learning-based algorithms have a tendency to overfit the training data, resulting in poor performance when confronted with unseen degradations. To achieve more robust restoration, generative adversarial network (GAN) prior based methods have been proposed, demonstrating a promising capacity to restore photo-realistic and high-quality results. However, these methods are susceptible to semantic ambiguity, particularly with semantically relevant images such as facial images. In this paper, we propose a semantic-aware latent space exploration method for image restoration (SAIR). By explicitly modeling referenced semantics information, SAIR is able to reliably restore severely degraded images not only to high-resolution highly-realistic looks but also to correct semantics. Quantitative and qualitative experiments collectively demonstrate the effectiveness of the proposed SAIR. Our code can be found in https:\/\/github.com\/Liamkuo\/SAIR.",
        "published":1646585548000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.03005v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Mar 06, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0944025087,
        "popularmechanics":0.1172199952,
        "scienmag":0.1201067713,
        "technologyreview":0.2154060119,
        "vox":0.1210494551,
        "newscientist":0.1276046096,
        "vice":0.1312960947,
        "statnews":0.1392765623,
        "nytimes":0.1189259176,
        "techcrunch":0.11814905,
        "quartz":0.1107018802,
        "venturebeat":0.1750155718,
        "futurism":0.1484486791,
        "scientificamerican":0.1089426674,
        "wired":0.1475463108,
        "popsci":0.1387945243,
        "arstechnica":0.1123906782,
        "salon":0.09947922,
        "washingtonpost":0.1335673745,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2208.02207v1",
        "predicted_newsworthiness":34.7655449788,
        "title":"Robot Learning from Demonstration Using Elastic Maps",
        "summary":"Learning from Demonstration (LfD) is a popular method of reproducing and generalizing robot skills from human-provided demonstrations. In this paper, we propose a novel optimization-based LfD method that encodes demonstrations as elastic maps. An elastic map is a graph of nodes connected through a mesh of springs. We build a skill model by fitting an elastic map to the set of demonstrations. The formulated optimization problem in our approach includes three objectives with natural and physical interpretations. The main term rewards the mean squared error in the Cartesian coordinate. The second term penalizes the non-equidistant distribution of points resulting in the optimum total length of the trajectory. The third term rewards smoothness while penalizing nonlinearity. These quadratic objectives form a convex problem that can be solved efficiently with local optimizers. We examine nine methods for constructing and weighting the elastic maps and study their performance in robotic tasks. We also evaluate the proposed method in several simulated and real-world experiments using a UR5e manipulator arm, and compare it to other LfD approaches to demonstrate its benefits and flexibility across a variety of metrics.",
        "published":1659544927000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2208.02207v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Aug 03, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.085801498,
        "popularmechanics":0.1625380746,
        "scienmag":0.1276721508,
        "technologyreview":0.2238564683,
        "vox":0.0810639125,
        "newscientist":0.1439052218,
        "vice":0.1243525199,
        "statnews":0.099969902,
        "nytimes":0.1333968915,
        "techcrunch":0.1313043858,
        "quartz":0.0938150024,
        "venturebeat":0.1619443434,
        "futurism":0.1882235507,
        "scientificamerican":0.1208360788,
        "wired":0.1712011951,
        "popsci":0.2088353014,
        "arstechnica":0.0969161321,
        "salon":0.0668508938,
        "washingtonpost":0.1282406105,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.02509v1",
        "predicted_newsworthiness":32.2316278442,
        "title":"Depth-Guided Sparse Structure-from-Motion for Movies and TV Shows",
        "summary":"Existing approaches for Structure from Motion (SfM) produce impressive 3-D reconstruction results especially when using imagery captured with large parallax. However, to create engaging video-content in movies and TV shows, the amount by which a camera can be moved while filming a particular shot is often limited. The resulting small-motion parallax between video frames makes standard geometry-based SfM approaches not as effective for movies and TV shows. To address this challenge, we propose a simple yet effective approach that uses single-frame depth-prior obtained from a pretrained network to significantly improve geometry-based SfM for our small-parallax setting. To this end, we first use the depth-estimates of the detected keypoints to reconstruct the point cloud and camera-pose for initial two-view reconstruction. We then perform depth-regularized optimization to register new images and triangulate the new points during incremental reconstruction. To comprehensively evaluate our approach, we introduce a new dataset (StudioSfM) consisting of 130 shots with 21K frames from 15 studio-produced videos that are manually annotated by a professional CG studio. We demonstrate that our approach: (a) significantly improves the quality of 3-D reconstruction for our small-parallax setting, (b) does not cause any degradation for data with large-parallax, and (c) maintains the generalizability and scalability of geometry-based sparse SfM. Our dataset can be obtained at https:\/\/github.com\/amazon-research\/small-baseline-camera-tracking.",
        "published":1649197150000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.02509v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Apr 05, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0819752825,
        "popularmechanics":0.1394259923,
        "scienmag":0.0883950536,
        "technologyreview":0.1418089996,
        "vox":0.0878003057,
        "newscientist":0.1188437545,
        "vice":0.1124161954,
        "statnews":0.0579609612,
        "nytimes":0.1183028059,
        "techcrunch":0.1283631619,
        "quartz":0.1012363017,
        "venturebeat":0.1644734288,
        "futurism":0.1284105539,
        "scientificamerican":0.0900331146,
        "wired":0.1772348645,
        "popsci":0.1473405289,
        "arstechnica":0.0893062273,
        "salon":0.0730946158,
        "washingtonpost":0.0964071159,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.01633v1",
        "predicted_newsworthiness":56.0000771564,
        "title":"Estimating Social Influence from Observational Data",
        "summary":"We consider the problem of estimating social influence, the effect that a person's behavior has on the future behavior of their peers. The key challenge is that shared behavior between friends could be equally explained by influence or by two other confounding factors: 1) latent traits that caused people to both become friends and engage in the behavior, and 2) latent preferences for the behavior. This paper addresses the challenges of estimating social influence with three contributions. First, we formalize social influence as a causal effect, one which requires inferences about hypothetical interventions. Second, we develop Poisson Influence Factorization (PIF), a method for estimating social influence from observational data. PIF fits probabilistic factor models to networks and behavior data to infer variables that serve as substitutes for the confounding latent traits. Third, we develop assumptions under which PIF recovers estimates of social influence. We empirically study PIF with semi-synthetic and real data from Last.fm, and conduct a sensitivity analysis. We find that PIF estimates social influence most accurately compared to related methods and remains robust under some violations of its assumptions.",
        "published":1648153284000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.01633v1",
        "arxiv_primary_category":"cs.si",
        "published_hr":"Mar 24, 2022",
        "arxiv_primary_category_hr":"Social and Information Networks",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2393113293,
        "popularmechanics":0.1371840453,
        "scienmag":0.2422572976,
        "technologyreview":0.2815726063,
        "vox":0.2765295238,
        "newscientist":0.2163445541,
        "vice":0.1552475744,
        "statnews":0.2411557643,
        "nytimes":0.2530029765,
        "techcrunch":0.250778214,
        "quartz":0.2407717305,
        "venturebeat":0.2602100373,
        "futurism":0.2070318685,
        "scientificamerican":0.2547825238,
        "wired":0.2538129749,
        "popsci":0.2388998351,
        "arstechnica":0.2209194114,
        "salon":0.2328910278,
        "washingtonpost":0.2794700423,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.16926v1",
        "predicted_newsworthiness":44.3923663753,
        "title":"Domain Adaptation for Sparse-Data Settings: What Do We Gain by Not Using Bert?",
        "summary":"The practical success of much of NLP depends on the availability of training data. However, in real-world scenarios, training data is often scarce, not least because many application domains are restricted and specific. In this work, we compare different methods to handle this problem and provide guidelines for building NLP applications when there is only a small amount of labeled training data available for a specific domain. While transfer learning with pre-trained language models outperforms other methods across tasks, alternatives do not perform much worse while requiring much less computational effort, thus significantly reducing monetary and environmental cost. We examine the performance tradeoffs of several such alternatives, including models that can be trained up to 175K times faster and do not require a single GPU.",
        "published":1648720748000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.16926v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Mar 31, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0947316678,
        "popularmechanics":0.1122049406,
        "scienmag":0.1102331688,
        "technologyreview":0.2351070387,
        "vox":0.1410786032,
        "newscientist":0.1217683164,
        "vice":0.0780542842,
        "statnews":0.1946525848,
        "nytimes":0.132130117,
        "techcrunch":0.1724427934,
        "quartz":0.1195796387,
        "venturebeat":0.2457481744,
        "futurism":0.1545197374,
        "scientificamerican":0.1030106281,
        "wired":0.1697716974,
        "popsci":0.1745923225,
        "arstechnica":0.1128034975,
        "salon":0.0982971831,
        "washingtonpost":0.1380488403,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.03757v1",
        "predicted_newsworthiness":55.5979939719,
        "title":"Combining Deep Learning with Good Old-Fashioned Machine Learning",
        "summary":"We present a comprehensive, stacking-based framework for combining deep learning with good old-fashioned machine learning, called Deep GOld. Our framework involves ensemble selection from 51 retrained pretrained deep networks as first-level models, and 10 machine-learning algorithms as second-level models. Enabled by today's state-of-the-art software tools and hardware platforms, Deep GOld delivers consistent improvement when tested on four image-classification datasets: Fashion MNIST, CIFAR10, CIFAR100, and Tiny ImageNet. Of 120 experiments, in all but 10 Deep GOld improved the original networks' performance.",
        "published":1657270723000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.03757v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jul 08, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1104404587,
        "popularmechanics":0.1606401781,
        "scienmag":0.1675896186,
        "technologyreview":0.328191226,
        "vox":0.1547096214,
        "newscientist":0.1706666555,
        "vice":0.1340796208,
        "statnews":0.2621530193,
        "nytimes":0.1702988052,
        "techcrunch":0.211482578,
        "quartz":0.1415949613,
        "venturebeat":0.2995129743,
        "futurism":0.2215553506,
        "scientificamerican":0.14142568,
        "wired":0.2111410033,
        "popsci":0.2388932294,
        "arstechnica":0.145505314,
        "salon":0.115165728,
        "washingtonpost":0.1809096142,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.08772v1",
        "predicted_newsworthiness":48.199376038,
        "title":"A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models",
        "summary":"With the increasing of model capacity brought by pre-trained language models, there emerges boosting needs for more knowledgeable natural language processing (NLP) models with advanced functionalities including providing and making flexible use of encyclopedic and commonsense knowledge. The mere pre-trained language models, however, lack the capacity of handling such knowledge-intensive NLP tasks alone. To address this challenge, large numbers of pre-trained language models augmented with external knowledge sources are proposed and in rapid development. In this paper, we aim to summarize the current progress of pre-trained language model-based knowledge-enhanced models (PLMKEs) by dissecting their three vital elements: knowledge sources, knowledge-intensive NLP tasks, and knowledge fusion methods. Finally, we present the challenges of PLMKEs based on the discussion regarding the three elements and attempt to provide NLP practitioners with potential directions for further research.",
        "published":1645118263000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.08772v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Feb 17, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0911369182,
        "popularmechanics":0.0928901686,
        "scienmag":0.101715909,
        "technologyreview":0.2046892194,
        "vox":0.1422546454,
        "newscientist":0.1162822329,
        "vice":0.0879782109,
        "statnews":0.1724697667,
        "nytimes":0.1266147433,
        "techcrunch":0.1585588199,
        "quartz":0.1144272385,
        "venturebeat":0.2171942083,
        "futurism":0.1325467658,
        "scientificamerican":0.1053864601,
        "wired":0.1536312218,
        "popsci":0.1508516119,
        "arstechnica":0.1034107864,
        "salon":0.0838584782,
        "washingtonpost":0.1395885796,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.01002v1",
        "predicted_newsworthiness":50.5600235844,
        "title":"Introducing One Sided Margin Loss for Solving Classification Problems in Deep Networks",
        "summary":"This paper introduces a new loss function, OSM (One-Sided Margin), to solve maximum-margin classification problems effectively. Unlike the hinge loss, in OSM the margin is explicitly determined with corresponding hyperparameters and then the classification problem is solved. In experiments, we observe that using OSM loss leads to faster training speeds and better accuracies than binary and categorical cross-entropy in several commonly used deep models for classification and optical character recognition problems. OSM has consistently shown better classification accuracies over cross-entropy and hinge losses for small to large neural networks. it has also led to a more efficient training procedure. We achieved state-of-the-art accuracies for small networks on several benchmark datasets of CIFAR10(98.82\\%), CIFAR100(91.56\\%), Flowers(98.04\\%), Stanford Cars(93.91\\%) with considerable improvements over other loss functions. Moreover, the accuracies are rather better than cross-entropy and hinge loss for large networks. Therefore, we strongly believe that OSM is a powerful alternative to hinge and cross-entropy losses to train deep neural networks on classification tasks.",
        "published":1654171419000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.01002v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jun 02, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0945693867,
        "popularmechanics":0.1309854512,
        "scienmag":0.1310205579,
        "technologyreview":0.2439154552,
        "vox":0.1165040361,
        "newscientist":0.1365343337,
        "vice":0.0924159715,
        "statnews":0.1685005146,
        "nytimes":0.1216866587,
        "techcrunch":0.1583199718,
        "quartz":0.1145433722,
        "venturebeat":0.2270940176,
        "futurism":0.1685856389,
        "scientificamerican":0.1080285499,
        "wired":0.1537361557,
        "popsci":0.1639453185,
        "arstechnica":0.1120267478,
        "salon":0.0773432665,
        "washingtonpost":0.1384421327,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.12597v1",
        "predicted_newsworthiness":43.5322665222,
        "title":"Context-Hierarchy Inverse Reinforcement Learning",
        "summary":"An inverse reinforcement learning (IRL) agent learns to act intelligently by observing expert demonstrations and learning the expert's underlying reward function. Although learning the reward functions from demonstrations has achieved great success in various tasks, several other challenges are mostly ignored. Firstly, existing IRL methods try to learn the reward function from scratch without relying on any prior knowledge. Secondly, traditional IRL methods assume the reward functions are homogeneous across all the demonstrations. Some existing IRL methods managed to extend to the heterogeneous demonstrations. However, they still assume one hidden variable that affects the behavior and learn the underlying hidden variable together with the reward from demonstrations. To solve these issues, we present Context Hierarchy IRL(CHIRL), a new IRL algorithm that exploits the context to scale up IRL and learn reward functions of complex behaviors. CHIRL models the context hierarchically as a directed acyclic graph; it represents the reward function as a corresponding modular deep neural network that associates each network module with a node of the context hierarchy. The context hierarchy and the modular reward representation enable data sharing across multiple contexts and state abstraction, significantly improving the learning performance. CHIRL has a natural connection with hierarchical task planning when the context hierarchy represents subtask decomposition. It enables to incorporate the prior knowledge of causal dependencies of subtasks and make it capable of solving large complex tasks by decoupling it into several subtasks and conquering each subtask to solve the original task. Experiments on benchmark tasks, including a large scale autonomous driving task in the CARLA simulator, show promising results in scaling up IRL for tasks with complex reward functions.",
        "published":1645784945000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.12597v1",
        "arxiv_primary_category":"cs.ai",
        "published_hr":"Feb 25, 2022",
        "arxiv_primary_category_hr":"Artificial Intelligence",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1070931114,
        "popularmechanics":0.168837656,
        "scienmag":0.1546757164,
        "technologyreview":0.3272411618,
        "vox":0.1467393605,
        "newscientist":0.1725281531,
        "vice":0.1393687476,
        "statnews":0.2408254138,
        "nytimes":0.1656397269,
        "techcrunch":0.2115226394,
        "quartz":0.1317032394,
        "venturebeat":0.2901449621,
        "futurism":0.2538110195,
        "scientificamerican":0.1440984401,
        "wired":0.2253624415,
        "popsci":0.2393506445,
        "arstechnica":0.1379204236,
        "salon":0.0968421048,
        "washingtonpost":0.163241178,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.02476v1",
        "predicted_newsworthiness":46.9907870301,
        "title":"Semantic Similarity Computing Model Based on Multi Model Fine-Grained Nonlinear Fusion",
        "summary":"Natural language processing (NLP) task has achieved excellent performance in many fields, including semantic understanding, automatic summarization, image recognition and so on. However, most of the neural network models for NLP extract the text in a fine-grained way, which is not conducive to grasp the meaning of the text from a global perspective. To alleviate the problem, the combination of the traditional statistical method and deep learning model as well as a novel model based on multi model nonlinear fusion are proposed in this paper. The model uses the Jaccard coefficient based on part of speech, Term Frequency-Inverse Document Frequency (TF-IDF) and word2vec-CNN algorithm to measure the similarity of sentences respectively. According to the calculation accuracy of each model, the normalized weight coefficient is obtained and the calculation results are compared. The weighted vector is input into the fully connected neural network to give the final classification results. As a result, the statistical sentence similarity evaluation algorithm reduces the granularity of feature extraction, so it can grasp the sentence features globally. Experimental results show that the matching of sentence similarity calculation method based on multi model nonlinear fusion is 84%, and the F1 value of the model is 75%.",
        "published":1644030757000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.02476v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Feb 04, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0808638274,
        "popularmechanics":0.1022799838,
        "scienmag":0.1116553392,
        "technologyreview":0.2073948791,
        "vox":0.1203590275,
        "newscientist":0.1162132786,
        "vice":0.0775700279,
        "statnews":0.1416730187,
        "nytimes":0.1149068177,
        "techcrunch":0.1312270755,
        "quartz":0.1121856893,
        "venturebeat":0.2032886193,
        "futurism":0.1355724901,
        "scientificamerican":0.1032923033,
        "wired":0.1381436551,
        "popsci":0.133928255,
        "arstechnica":0.1050495406,
        "salon":0.0596540333,
        "washingtonpost":0.1432712446,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.09416v1",
        "predicted_newsworthiness":57.1543459245,
        "title":"A Weakly-Supervised Iterative Graph-Based Approach to Retrieve COVID-19 Misinformation Topics",
        "summary":"The COVID-19 pandemic has been accompanied by an `infodemic' -- of accurate and inaccurate health information across social media. Detecting misinformation amidst dynamically changing information landscape is challenging; identifying relevant keywords and posts is arduous due to the large amount of human effort required to inspect the content and sources of posts. We aim to reduce the resource cost of this process by introducing a weakly-supervised iterative graph-based approach to detect keywords, topics, and themes related to misinformation, with a focus on COVID-19. Our approach can successfully detect specific topics from general misinformation-related seed words in a few seed texts. Our approach utilizes the BERT-based Word Graph Search (BWGS) algorithm that builds on context-based neural network embeddings for retrieving misinformation-related posts. We utilize Latent Dirichlet Allocation (LDA) topic modeling for obtaining misinformation-related themes from the texts returned by BWGS. Furthermore, we propose the BERT-based Multi-directional Word Graph Search (BMDWGS) algorithm that utilizes greater starting context information for misinformation extraction. In addition to a qualitative analysis of our approach, our quantitative analyses show that BWGS and BMDWGS are effective in extracting misinformation-related content compared to common baselines in low data resource settings. Extracting such content is useful for uncovering prevalent misconceptions and concerns and for facilitating precision public health messaging campaigns to improve health behaviors.",
        "published":1652952639000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.09416v1",
        "arxiv_primary_category":"cs.hc",
        "published_hr":"May 19, 2022",
        "arxiv_primary_category_hr":"Human-Computer Interaction",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2740864448,
        "popularmechanics":0.1514415082,
        "scienmag":0.2471969181,
        "technologyreview":0.3196590624,
        "vox":0.3219081717,
        "newscientist":0.2498969065,
        "vice":0.1758261582,
        "statnews":0.3224488687,
        "nytimes":0.2914342575,
        "techcrunch":0.2294052945,
        "quartz":0.2419704396,
        "venturebeat":0.2536036533,
        "futurism":0.2532751582,
        "scientificamerican":0.2838749184,
        "wired":0.2825427495,
        "popsci":0.2454929602,
        "arstechnica":0.2957097932,
        "salon":0.3222521569,
        "washingtonpost":0.3418996124,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.04771v4",
        "predicted_newsworthiness":40.7242298833,
        "title":"Multiscale Convolutional Transformer with Center Mask Pretraining for Hyperspectral Image Classification",
        "summary":"Hyperspectral images (HSI) not only have a broad macroscopic field of view but also contain rich spectral information, and the types of surface objects can be identified through spectral information, which is one of the main applications in hyperspectral image related research.In recent years, more and more deep learning methods have been proposed, among which convolutional neural networks (CNN) are the most influential. However, CNN-based methods are difficult to capture long-range dependencies, and also require a large amount of labeled data for model training.Besides, most of the self-supervised training methods in the field of HSI classification are based on the reconstruction of input samples, and it is difficult to achieve effective use of unlabeled samples. To address the shortcomings of CNN networks, we propose a noval multi-scale convolutional embedding module for HSI to realize effective extraction of spatial-spectral information, which can be better combined with Transformer network.In order to make more efficient use of unlabeled data, we propose a new self-supervised pretask. Similar to Mask autoencoder, but our pre-training method only masks the corresponding token of the central pixel in the encoder, and inputs the remaining token into the decoder to reconstruct the spectral information of the central pixel.Such a pretask can better model the relationship between the central feature and the domain feature, and obtain more stable training results.",
        "published":1646836946000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.04771v4",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Mar 09, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0780023798,
        "popularmechanics":0.1362504375,
        "scienmag":0.1525163192,
        "technologyreview":0.1907643578,
        "vox":0.0909476678,
        "newscientist":0.1341762426,
        "vice":0.1795680981,
        "statnews":0.1267429366,
        "nytimes":0.110717125,
        "techcrunch":0.1167958207,
        "quartz":0.089055288,
        "venturebeat":0.1701685285,
        "futurism":0.1501617728,
        "scientificamerican":0.1169108049,
        "wired":0.1250935961,
        "popsci":0.1384094506,
        "arstechnica":0.1129573719,
        "salon":0.0874800915,
        "washingtonpost":0.1307035654,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.07847v1",
        "predicted_newsworthiness":38.2620874055,
        "title":"SCD: Self-Contrastive Decorrelation for Sentence Embeddings",
        "summary":"In this paper, we propose Self-Contrastive Decorrelation (SCD), a self-supervised approach. Given an input sentence, it optimizes a joint self-contrastive and decorrelation objective. Learning a representation is facilitated by leveraging the contrast arising from the instantiation of standard dropout at different rates. The proposed method is conceptually simple yet empirically powerful. It achieves comparable results with state-of-the-art methods on multiple benchmarks without using contrastive pairs. This study opens up avenues for efficient self-supervised learning methods that are more robust than current contrastive methods.",
        "published":1647349330000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.07847v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Mar 15, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0871005132,
        "popularmechanics":0.0883517234,
        "scienmag":0.0872614797,
        "technologyreview":0.1702421164,
        "vox":0.1102921435,
        "newscientist":0.0996015091,
        "vice":0.0591612741,
        "statnews":0.1146659389,
        "nytimes":0.1052507996,
        "techcrunch":0.1098614365,
        "quartz":0.1072560097,
        "venturebeat":0.1705308771,
        "futurism":0.1122343849,
        "scientificamerican":0.0922274888,
        "wired":0.1356877454,
        "popsci":0.1219357629,
        "arstechnica":0.087271101,
        "salon":0.0834432562,
        "washingtonpost":0.1120825828,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.00757v1",
        "predicted_newsworthiness":32.1125236966,
        "title":"PhotoScene: Photorealistic Material and Lighting Transfer for Indoor Scenes",
        "summary":"Most indoor 3D scene reconstruction methods focus on recovering 3D geometry and scene layout. In this work, we go beyond this to propose PhotoScene, a framework that takes input image(s) of a scene along with approximately aligned CAD geometry (either reconstructed automatically or manually specified) and builds a photorealistic digital twin with high-quality materials and similar lighting. We model scene materials using procedural material graphs; such graphs represent photorealistic and resolution-independent materials. We optimize the parameters of these graphs and their texture scale and rotation, as well as the scene lighting to best match the input image via a differentiable rendering layer. We evaluate our technique on objects and layout reconstructions from ScanNet, SUN RGB-D and stock photographs, and demonstrate that our method reconstructs high-quality, fully relightable 3D scenes that can be re-rendered under arbitrary viewpoints, zooms and lighting.",
        "published":1656744764000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.00757v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 02, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.094727716,
        "popularmechanics":0.170650573,
        "scienmag":0.1230741785,
        "technologyreview":0.1922166399,
        "vox":0.1039267373,
        "newscientist":0.1441685377,
        "vice":0.140255522,
        "statnews":0.0717567842,
        "nytimes":0.1473515512,
        "techcrunch":0.1597326638,
        "quartz":0.1179246619,
        "venturebeat":0.2037991851,
        "futurism":0.1697704895,
        "scientificamerican":0.1137474276,
        "wired":0.1996739787,
        "popsci":0.1929708148,
        "arstechnica":0.0996048685,
        "salon":0.0851199099,
        "washingtonpost":0.1297605265,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.11523v1",
        "predicted_newsworthiness":47.1290447278,
        "title":"ResiDualGAN: Resize-Residual DualGAN for Cross-Domain Remote Sensing Images Semantic Segmentation",
        "summary":"The performance of a semantic segmentation model for remote sensing (RS) images pretrained on an annotated dataset would greatly decrease when testing on another unannotated dataset because of the domain gap. Adversarial generative methods, e.g., DualGAN, are utilized for unpaired image-to-image translation to minimize the pixel-level domain gap, which is one of the common approaches for unsupervised domain adaptation (UDA). However, existing image translation methods are facing two problems when performing RS images translation: 1) ignoring the scale discrepancy between two RS datasets which greatly affect the accuracy performance of scale-invariant objects, 2) ignoring the characteristic of real-to-real translation of RS images which brings an unstable factor for the training of the models. In this paper, ResiDualGAN is proposed for RS images translation, where a resizer module is used for addressing the scale discrepancy of RS datasets, and a residual connection is used for strengthening the stability of real-to-real images translation and improving the performance in cross-domain semantic segmentation tasks. Combining with an output space adaptation method, the proposed method greatly improves the accuracy performance on common benchmarks, which demonstrates the superiority and reliability of ResiDuanGAN. At the end of the paper, a thorough discussion is also conducted to give a reasonable explanation for the improvement of ResiDualGAN.",
        "published":1643291814000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.11523v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jan 27, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0982414255,
        "popularmechanics":0.1347626164,
        "scienmag":0.1338182,
        "technologyreview":0.1718942276,
        "vox":0.0957056541,
        "newscientist":0.1300873624,
        "vice":0.1591066035,
        "statnews":0.0886579717,
        "nytimes":0.111297766,
        "techcrunch":0.1006820614,
        "quartz":0.1036721543,
        "venturebeat":0.1428370072,
        "futurism":0.136478108,
        "scientificamerican":0.124051472,
        "wired":0.1146646981,
        "popsci":0.1296937013,
        "arstechnica":0.1174322675,
        "salon":0.1096432253,
        "washingtonpost":0.1200817606,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.12926v1",
        "predicted_newsworthiness":48.0038374616,
        "title":"A Guide to Image and Video based Small Object Detection using Deep Learning : Case Study of Maritime Surveillance",
        "summary":"Small object detection (SOD) in optical images and videos is a challenging problem that even state-of-the-art generic object detection methods fail to accurately localize and identify such objects. Typically, small objects appear in real-world due to large camera-object distance. Because small objects occupy only a small area in the input image (e.g., less than 10%), the information extracted from such a small area is not always rich enough to support decision making. Multidisciplinary strategies are being developed by researchers working at the interface of deep learning and computer vision to enhance the performance of SOD deep learning based methods. In this paper, we provide a comprehensive review of over 160 research papers published between 2017 and 2022 in order to survey this growing subject. This paper summarizes the existing literature and provide a taxonomy that illustrates the broad picture of current research. We investigate how to improve the performance of small object detection in maritime environments, where increasing performance is critical. By establishing a connection between generic and maritime SOD research, future directions have been identified. In addition, the popular datasets that have been used for SOD for generic and maritime applications are discussed, and also well-known evaluation metrics for the state-of-the-art methods on some of the datasets are provided.",
        "published":1658845718000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.12926v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 26, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1130905767,
        "popularmechanics":0.2348764222,
        "scienmag":0.1578017373,
        "technologyreview":0.2327504107,
        "vox":0.1234811439,
        "newscientist":0.183330546,
        "vice":0.1811682866,
        "statnews":0.1070487592,
        "nytimes":0.1476278069,
        "techcrunch":0.1707148016,
        "quartz":0.127501657,
        "venturebeat":0.217549777,
        "futurism":0.1952826789,
        "scientificamerican":0.1720324513,
        "wired":0.188828389,
        "popsci":0.22568139,
        "arstechnica":0.1550613397,
        "salon":0.1130036523,
        "washingtonpost":0.1660854596,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.03753v1",
        "predicted_newsworthiness":34.9869064221,
        "title":"Select and Calibrate the Low-confidence: Dual-Channel Consistency based Graph Convolutional Networks",
        "summary":"The Graph Convolutional Networks (GCNs) have achieved excellent results in node classification tasks, but the model's performance at low label rates is still unsatisfactory. Previous studies in Semi-Supervised Learning (SSL) for graph have focused on using network predictions to generate soft pseudo-labels or instructing message propagation, which inevitably contains the incorrect prediction due to the over-confident in the predictions. Our proposed Dual-Channel Consistency based Graph Convolutional Networks (DCC-GCN) uses dual-channel to extract embeddings from node features and topological structures, and then achieves reliable low-confidence and high-confidence samples selection based on dual-channel consistency. We further confirmed that the low-confidence samples obtained based on dual-channel consistency were low in accuracy, constraining the model's performance. Unlike previous studies ignoring low-confidence samples, we calibrate the feature embeddings of the low-confidence samples by using the neighborhood's high-confidence samples. Our experiments have shown that the DCC-GCN can more accurately distinguish between low-confidence and high-confidence samples, and can also significantly improve the accuracy of low-confidence samples. We conducted extensive experiments on the benchmark datasets and demonstrated that DCC-GCN is significantly better than state-of-the-art baselines at different label rates.",
        "published":1651973728000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.03753v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"May 07, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0952197095,
        "popularmechanics":0.1106007523,
        "scienmag":0.1341112947,
        "technologyreview":0.2038272532,
        "vox":0.1471852768,
        "newscientist":0.1272727581,
        "vice":0.0958098813,
        "statnews":0.1638043712,
        "nytimes":0.1279031384,
        "techcrunch":0.138175978,
        "quartz":0.115311111,
        "venturebeat":0.1802666377,
        "futurism":0.14137607,
        "scientificamerican":0.1147432262,
        "wired":0.1551709073,
        "popsci":0.1447180692,
        "arstechnica":0.1198334029,
        "salon":0.0873183103,
        "washingtonpost":0.1585624789,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.00484v1",
        "predicted_newsworthiness":37.874873801,
        "title":"Dynamic Programming in Rank Space: Scaling Structured Inference with Low-Rank HMMs and PCFGs",
        "summary":"Hidden Markov Models (HMMs) and Probabilistic Context-Free Grammars (PCFGs) are widely used structured models, both of which can be represented as factor graph grammars (FGGs), a powerful formalism capable of describing a wide range of models. Recent research found it beneficial to use large state spaces for HMMs and PCFGs. However, inference with large state spaces is computationally demanding, especially for PCFGs. To tackle this challenge, we leverage tensor rank decomposition (aka.\\ CPD) to decrease inference computational complexities for a subset of FGGs subsuming HMMs and PCFGs. We apply CPD on the factors of an FGG and then construct a new FGG defined in the rank space. Inference with the new FGG produces the same result but has a lower time complexity when the rank size is smaller than the state size. We conduct experiments on HMM language modeling and unsupervised PCFG parsing, showing better performance than previous work. Our code is publicly available at \\url{https:\/\/github.com\/VPeterV\/RankSpace-Models}.",
        "published":1651417105000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.00484v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"May 01, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0802531889,
        "popularmechanics":0.1049140097,
        "scienmag":0.0983024321,
        "technologyreview":0.1648302928,
        "vox":0.12124246,
        "newscientist":0.1038669825,
        "vice":0.0927465967,
        "statnews":0.1266026394,
        "nytimes":0.110984505,
        "techcrunch":0.1290299864,
        "quartz":0.1044362038,
        "venturebeat":0.175500439,
        "futurism":0.1217039633,
        "scientificamerican":0.0888035047,
        "wired":0.1441045784,
        "popsci":0.1285221633,
        "arstechnica":0.1159227746,
        "salon":0.0821100043,
        "washingtonpost":0.1193231448,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.07351v1",
        "predicted_newsworthiness":41.1488345054,
        "title":"Diverse Human Motion Prediction via Gumbel-Softmax Sampling from an Auxiliary Space",
        "summary":"Diverse human motion prediction aims at predicting multiple possible future pose sequences from a sequence of observed poses. Previous approaches usually employ deep generative networks to model the conditional distribution of data, and then randomly sample outcomes from the distribution. While different results can be obtained, they are usually the most likely ones which are not diverse enough. Recent work explicitly learns multiple modes of the conditional distribution via a deterministic network, which however can only cover a fixed number of modes within a limited range. In this paper, we propose a novel sampling strategy for sampling very diverse results from an imbalanced multimodal distribution learned by a deep generative model. Our method works by generating an auxiliary space and smartly making randomly sampling from the auxiliary space equivalent to the diverse sampling from the target distribution. We propose a simple yet effective network architecture that implements this novel sampling strategy, which incorporates a Gumbel-Softmax coefficient matrix sampling method and an aggressive diversity promoting hinge loss function. Extensive experiments demonstrate that our method significantly improves both the diversity and accuracy of the samplings compared with previous state-of-the-art sampling approaches. Code and pre-trained models are available at https:\/\/github.com\/Droliven\/diverse_sampling.",
        "published":1657875837000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.07351v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 15, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0878502699,
        "popularmechanics":0.1143625059,
        "scienmag":0.1024522369,
        "technologyreview":0.186928096,
        "vox":0.0915813542,
        "newscientist":0.1282221565,
        "vice":0.0990848648,
        "statnews":0.1087616011,
        "nytimes":0.114374442,
        "techcrunch":0.1168670416,
        "quartz":0.1049669549,
        "venturebeat":0.1668121995,
        "futurism":0.1350578328,
        "scientificamerican":0.0979240674,
        "wired":0.1468084436,
        "popsci":0.1397359375,
        "arstechnica":0.0881266814,
        "salon":0.0759920347,
        "washingtonpost":0.1119901602,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.06640v1",
        "predicted_newsworthiness":44.9913302213,
        "title":"Confidence Score for Source-Free Unsupervised Domain Adaptation",
        "summary":"Source-free unsupervised domain adaptation (SFUDA) aims to obtain high performance in the unlabeled target domain using the pre-trained source model, not the source data. Existing SFUDA methods assign the same importance to all target samples, which is vulnerable to incorrect pseudo-labels. To differentiate between sample importance, in this study, we propose a novel sample-wise confidence score, the Joint Model-Data Structure (JMDS) score for SFUDA. Unlike existing confidence scores that use only one of the source or target domain knowledge, the JMDS score uses both knowledge. We then propose a Confidence score Weighting Adaptation using the JMDS (CoWA-JMDS) framework for SFUDA. CoWA-JMDS consists of the JMDS scores as sample weights and weight Mixup that is our proposed variant of Mixup. Weight Mixup promotes the model make more use of the target domain knowledge. The experimental results show that the JMDS score outperforms the existing confidence scores. Moreover, CoWA-JMDS achieves state-of-the-art performance on various SFUDA scenarios: closed, open, and partial-set scenarios.",
        "published":1655190242000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.06640v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jun 14, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0726637735,
        "popularmechanics":0.1150772508,
        "scienmag":0.1213653648,
        "technologyreview":0.1894018716,
        "vox":0.0930189402,
        "newscientist":0.1057102115,
        "vice":0.0960880078,
        "statnews":0.1396423931,
        "nytimes":0.1014558418,
        "techcrunch":0.1176289561,
        "quartz":0.0933335886,
        "venturebeat":0.1814570997,
        "futurism":0.1270684445,
        "scientificamerican":0.0951339079,
        "wired":0.1157225777,
        "popsci":0.1331772468,
        "arstechnica":0.0980392491,
        "salon":0.0813490265,
        "washingtonpost":0.1064749458,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.01782v1",
        "predicted_newsworthiness":51.2168116425,
        "title":"Learning Multi-dimensional Edge Feature-based AU Relation Graph for Facial Action Unit Recognition",
        "summary":"The activations of Facial Action Units (AUs) mutually influence one another. While the relationship between a pair of AUs can be complex and unique, existing approaches fail to specifically and explicitly represent such cues for each pair of AUs in each facial display. This paper proposes an AU relationship modelling approach that deep learns a unique graph to explicitly describe the relationship between each pair of AUs of the target facial display. Our approach first encodes each AU's activation status and its association with other AUs into a node feature. Then, it learns a pair of multi-dimensional edge features to describe multiple task-specific relationship cues between each pair of AUs. During both node and edge feature learning, our approach also considers the influence of the unique facial display on AUs' relationship by taking the full face representation as an input. Experimental results on BP4D and DISFA datasets show that both node and edge feature learning modules provide large performance improvements for CNN and transformer-based backbones, with our best systems achieving the state-of-the-art AU recognition results. Our approach not only has a strong capability in modelling relationship cues for AU recognition but also can be easily incorporated into various backbones. Our PyTorch code is made available.",
        "published":1651462680000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.01782v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 01, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1021300689,
        "popularmechanics":0.1258211222,
        "scienmag":0.1261929782,
        "technologyreview":0.2358195374,
        "vox":0.1156360536,
        "newscientist":0.1296131204,
        "vice":0.083217942,
        "statnews":0.1310929445,
        "nytimes":0.1268265529,
        "techcrunch":0.1488436103,
        "quartz":0.1162259185,
        "venturebeat":0.2186964281,
        "futurism":0.1661603809,
        "scientificamerican":0.1038025735,
        "wired":0.1629669185,
        "popsci":0.1625861428,
        "arstechnica":0.0999555009,
        "salon":0.0917175723,
        "washingtonpost":0.1373434752,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.13645v1",
        "predicted_newsworthiness":42.8700553952,
        "title":"MSCTD: A Multimodal Sentiment Chat Translation Dataset",
        "summary":"Multimodal machine translation and textual chat translation have received considerable attention in recent years. Although the conversation in its natural form is usually multimodal, there still lacks work on multimodal machine translation in conversations. In this work, we introduce a new task named Multimodal Chat Translation (MCT), aiming to generate more accurate translations with the help of the associated dialogue history and visual context. To this end, we firstly construct a Multimodal Sentiment Chat Translation Dataset (MSCTD) containing 142,871 English-Chinese utterance pairs in 14,762 bilingual dialogues and 30,370 English-German utterance pairs in 3,079 bilingual dialogues. Each utterance pair, corresponding to the visual context that reflects the current conversational scene, is annotated with a sentiment label. Then, we benchmark the task by establishing multiple baseline systems that incorporate multimodal and sentiment features for MCT. Preliminary experiments on four language directions (English-Chinese and English-German) verify the potential of contextual and multimodal information fusion and the positive impact of sentiment on the MCT task. Additionally, as a by-product of the MSCTD, it also provides two new benchmarks on multimodal dialogue sentiment analysis. Our work can facilitate research on both multimodal chat translation and multimodal dialogue sentiment analysis.",
        "published":1646041246000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.13645v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Feb 28, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1330421168,
        "popularmechanics":0.1243948603,
        "scienmag":0.1131291154,
        "technologyreview":0.2290904664,
        "vox":0.1851474664,
        "newscientist":0.1438463994,
        "vice":0.1057994629,
        "statnews":0.1467335682,
        "nytimes":0.1672421815,
        "techcrunch":0.1817584324,
        "quartz":0.1714911908,
        "venturebeat":0.2338476535,
        "futurism":0.1717208909,
        "scientificamerican":0.1209495195,
        "wired":0.2086766554,
        "popsci":0.1867668581,
        "arstechnica":0.1455666151,
        "salon":0.1148821868,
        "washingtonpost":0.1924885092,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.04427v1",
        "predicted_newsworthiness":52.9229981977,
        "title":"Differentiating Geographic Movement Described in Text Documents",
        "summary":"Understanding movement described in text documents is important since text descriptions of movement contain a wealth of geographic and contextual information about the movement of people, wildlife, goods, and much more. Our research makes several contributions to improve our understanding of movement descriptions in text. First, we show how interpreting geographic movement described in text is challenging because of general spatial terms, linguistic constructions that make the thing(s) moving unclear, and many types of temporal references and groupings, among others. Next, as a step to overcome these challenges, we report on an experiment with human subjects through which we identify multiple important characteristics of movement descriptions (found in text) that humans use to differentiate one movement description from another. Based on our empirical results, we provide recommendations for computational analysis using movement described in text documents. Our findings contribute towards an improved understanding of the important characteristics of the underused information about geographic movement that is in the form of text descriptions.",
        "published":1641988153000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.04427v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Jan 12, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1977928753,
        "popularmechanics":0.1720551162,
        "scienmag":0.1979937431,
        "technologyreview":0.2160170374,
        "vox":0.1728482689,
        "newscientist":0.2001595014,
        "vice":0.2026612154,
        "statnews":0.1374790597,
        "nytimes":0.2023251291,
        "techcrunch":0.1651243658,
        "quartz":0.1729608496,
        "venturebeat":0.18747253,
        "futurism":0.1635513551,
        "scientificamerican":0.2346788579,
        "wired":0.2274801995,
        "popsci":0.21090738,
        "arstechnica":0.1669506906,
        "salon":0.1927414928,
        "washingtonpost":0.1908656293,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.01068v4",
        "predicted_newsworthiness":51.2644213258,
        "title":"OPT: Open Pre-trained Transformer Language Models",
        "summary":"Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero- and few-shot learning. Given their computational cost, these models are difficult to replicate without significant capital. For the few that are available through APIs, no access is granted to the full model weights, making them difficult to study. We present Open Pre-trained Transformers (OPT), a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, which we aim to fully and responsibly share with interested researchers. We show that OPT-175B is comparable to GPT-3, while requiring only 1\/7th the carbon footprint to develop. We are also releasing our logbook detailing the infrastructure challenges we faced, along with code for experimenting with all of the released models.",
        "published":1651513790000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.01068v4",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"May 02, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0969327301,
        "popularmechanics":0.1469553603,
        "scienmag":0.1227584275,
        "technologyreview":0.2404666533,
        "vox":0.1586519882,
        "newscientist":0.1358164889,
        "vice":0.1235298146,
        "statnews":0.1576481474,
        "nytimes":0.1423782109,
        "techcrunch":0.1929449599,
        "quartz":0.1324184012,
        "venturebeat":0.2461981602,
        "futurism":0.1735136245,
        "scientificamerican":0.1301290343,
        "wired":0.195855097,
        "popsci":0.1975302922,
        "arstechnica":0.1410456979,
        "salon":0.1124895159,
        "washingtonpost":0.1557816145,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.01414v2",
        "predicted_newsworthiness":59.3918024276,
        "title":"Multimodal Detection of Unknown Objects on Roads for Autonomous Driving",
        "summary":"Tremendous progress in deep learning over the last years has led towards a future with autonomous vehicles on our roads. Nevertheless, the performance of their perception systems is strongly dependent on the quality of the utilized training data. As these usually only cover a fraction of all object classes an autonomous driving system will face, such systems struggle with handling the unexpected. In order to safely operate on public roads, the identification of objects from unknown classes remains a crucial task. In this paper, we propose a novel pipeline to detect unknown objects. Instead of focusing on a single sensor modality, we make use of lidar and camera data by combining state-of-the art detection models in a sequential manner. We evaluate our approach on the Waymo Open Perception Dataset and point out current research gaps in anomaly detection.",
        "published":1651575521000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.01414v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 03, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1263684707,
        "popularmechanics":0.2168845095,
        "scienmag":0.1567480059,
        "technologyreview":0.2988233676,
        "vox":0.1638025001,
        "newscientist":0.1892309208,
        "vice":0.1882774572,
        "statnews":0.1542419044,
        "nytimes":0.1649818551,
        "techcrunch":0.2246601882,
        "quartz":0.1511468559,
        "venturebeat":0.2702812691,
        "futurism":0.2527009904,
        "scientificamerican":0.1681576893,
        "wired":0.2351052891,
        "popsci":0.2587244536,
        "arstechnica":0.1695778512,
        "salon":0.125445587,
        "washingtonpost":0.2007114703,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.10000v1",
        "predicted_newsworthiness":34.4830941366,
        "title":"Neural Manifold Clustering and Embedding",
        "summary":"Given a union of non-linear manifolds, non-linear subspace clustering or manifold clustering aims to cluster data points based on manifold structures and also learn to parameterize each manifold as a linear subspace in a feature space. Deep neural networks have the potential to achieve this goal under highly non-linear settings given their large capacity and flexibility. We argue that achieving manifold clustering with neural networks requires two essential ingredients: a domain-specific constraint that ensures the identification of the manifolds, and a learning algorithm for embedding each manifold to a linear subspace in the feature space. This work shows that many constraints can be implemented by data augmentation. For subspace feature learning, Maximum Coding Rate Reduction (MCR$^2$) objective can be used. Putting them together yields {\\em Neural Manifold Clustering and Embedding} (NMCE), a novel method for general purpose manifold clustering, which significantly outperforms autoencoder-based deep subspace clustering. Further, on more challenging natural image datasets, NMCE can also outperform other algorithms specifically designed for clustering. Qualitatively, we demonstrate that NMCE learns a meaningful and interpretable feature space. As the formulation of NMCE is closely related to several important Self-supervised learning (SSL) methods, we believe this work can help us build a deeper understanding on SSL representation learning.",
        "published":1643066017000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.10000v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jan 24, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0941312242,
        "popularmechanics":0.1193860049,
        "scienmag":0.1335171484,
        "technologyreview":0.2224440733,
        "vox":0.1110442851,
        "newscientist":0.1415804109,
        "vice":0.1222990386,
        "statnews":0.1619878067,
        "nytimes":0.1286454569,
        "techcrunch":0.1299753757,
        "quartz":0.1063877296,
        "venturebeat":0.1960765233,
        "futurism":0.153931308,
        "scientificamerican":0.1229206237,
        "wired":0.1564042931,
        "popsci":0.1533896365,
        "arstechnica":0.099250064,
        "salon":0.090100457,
        "washingtonpost":0.1342246011,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.05358v1",
        "predicted_newsworthiness":53.0532514718,
        "title":"eX-ViT: A Novel eXplainable Vision Transformer for Weakly Supervised Semantic Segmentation",
        "summary":"Recently vision transformer models have become prominent models for a range of vision tasks. These models, however, are usually opaque with weak feature interpretability. Moreover, there is no method currently built for an intrinsically interpretable transformer, which is able to explain its reasoning process and provide a faithful explanation. To close these crucial gaps, we propose a novel vision transformer dubbed the eXplainable Vision Transformer (eX-ViT), an intrinsically interpretable transformer model that is able to jointly discover robust interpretable features and perform the prediction. Specifically, eX-ViT is composed of the Explainable Multi-Head Attention (E-MHA) module, the Attribute-guided Explainer (AttE) module and the self-supervised attribute-guided loss. The E-MHA tailors explainable attention weights that are able to learn semantically interpretable representations from local patches in terms of model decisions with noise robustness. Meanwhile, AttE is proposed to encode discriminative attribute features for the target object through diverse attribute discovery, which constitutes faithful evidence for the model's predictions. In addition, a self-supervised attribute-guided loss is developed for our eX-ViT, which aims at learning enhanced representations through the attribute discriminability mechanism and attribute diversity mechanism, to localize diverse and discriminative attributes and generate more robust explanations. As a result, we can uncover faithful and robust interpretations with diverse attributes through the proposed eX-ViT.",
        "published":1657611809000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.05358v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 12, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0848438568,
        "popularmechanics":0.1146748858,
        "scienmag":0.1136629843,
        "technologyreview":0.2207766359,
        "vox":0.1035556176,
        "newscientist":0.1256067585,
        "vice":0.1179176716,
        "statnews":0.1538967819,
        "nytimes":0.1119137198,
        "techcrunch":0.1293201183,
        "quartz":0.0966663021,
        "venturebeat":0.1959066538,
        "futurism":0.1394082443,
        "scientificamerican":0.1098887894,
        "wired":0.1343287006,
        "popsci":0.1420687555,
        "arstechnica":0.096853299,
        "salon":0.0853206221,
        "washingtonpost":0.1087183,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.09555v1",
        "predicted_newsworthiness":40.5943883056,
        "title":"On the expressive power of message-passing neural networks as global feature map transformers",
        "summary":"We investigate the power of message-passing neural networks (MPNNs) in their capacity to transform the numerical features stored in the nodes of their input graphs. Our focus is on global expressive power, uniformly over all input graphs, or over graphs of bounded degree with features from a bounded domain. Accordingly, we introduce the notion of a global feature map transformer (GFMT). As a yardstick for expressiveness, we use a basic language for GFMTs, which we call MPLang. Every MPNN can be expressed in MPLang, and our results clarify to which extent the converse inclusion holds. We consider exact versus approximate expressiveness; the use of arbitrary activation functions; and the case where only the ReLU activation function is allowed.",
        "published":1647542241000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.09555v1",
        "arxiv_primary_category":"cs.ai",
        "published_hr":"Mar 17, 2022",
        "arxiv_primary_category_hr":"Artificial Intelligence",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0893252554,
        "popularmechanics":0.1306734579,
        "scienmag":0.1288063184,
        "technologyreview":0.2536184456,
        "vox":0.1394638386,
        "newscientist":0.1443548135,
        "vice":0.0890246446,
        "statnews":0.1833725833,
        "nytimes":0.1349891905,
        "techcrunch":0.1495316345,
        "quartz":0.1111008433,
        "venturebeat":0.2280448855,
        "futurism":0.1776029413,
        "scientificamerican":0.1145936539,
        "wired":0.160144092,
        "popsci":0.172639571,
        "arstechnica":0.1218765741,
        "salon":0.0722976068,
        "washingtonpost":0.1639244578,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.07105v1",
        "predicted_newsworthiness":52.0828766324,
        "title":"A Survey on Model Compression for Natural Language Processing",
        "summary":"With recent developments in new architectures like Transformer and pretraining techniques, significant progress has been made in applications of natural language processing (NLP). However, the high energy cost and long inference delay of Transformer is preventing NLP from entering broader scenarios including edge and mobile computing. Efficient NLP research aims to comprehensively consider computation, time and carbon emission for the entire life-cycle of NLP, including data preparation, model training and inference. In this survey, we focus on the inference stage and review the current state of model compression for NLP, including the benchmarks, metrics and methodology. We outline the current obstacles and future research directions.",
        "published":1644884327000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.07105v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Feb 14, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1113011769,
        "popularmechanics":0.152624852,
        "scienmag":0.1421020314,
        "technologyreview":0.2517026748,
        "vox":0.1660552565,
        "newscientist":0.1499774051,
        "vice":0.1166010757,
        "statnews":0.2046270632,
        "nytimes":0.1519357086,
        "techcrunch":0.1902984533,
        "quartz":0.1414123622,
        "venturebeat":0.2616230574,
        "futurism":0.1877485648,
        "scientificamerican":0.1363530075,
        "wired":0.1945461241,
        "popsci":0.2000690754,
        "arstechnica":0.1551424032,
        "salon":0.1309833156,
        "washingtonpost":0.1632426496,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2208.01820v1",
        "predicted_newsworthiness":35.4744773561,
        "title":"Link Prediction on Heterophilic Graphs via Disentangled Representation Learning",
        "summary":"Link prediction is an important task that has wide applications in various domains. However, the majority of existing link prediction approaches assume the given graph follows homophily assumption, and designs similarity-based heuristics or representation learning approaches to predict links. However, many real-world graphs are heterophilic graphs, where the homophily assumption does not hold, which challenges existing link prediction methods. Generally, in heterophilic graphs, there are many latent factors causing the link formation, and two linked nodes tend to be similar in one or two factors but might be dissimilar in other factors, leading to low overall similarity. Thus, one way is to learn disentangled representation for each node with each vector capturing the latent representation of a node on one factor, which paves a way to model the link formation in heterophilic graphs, resulting in better node representation learning and link prediction performance. However, the work on this is rather limited. Therefore, in this paper, we study a novel problem of exploring disentangled representation learning for link prediction on heterophilic graphs. We propose a novel framework DisenLink which can learn disentangled representations by modeling the link formation and perform factor-aware message-passing to facilitate link prediction. Extensive experiments on 13 real-world datasets demonstrate the effectiveness of DisenLink for link prediction on both heterophilic and hemophiliac graphs. Our codes are available at https:\/\/github.com\/sjz5202\/DisenLink",
        "published":1659494906000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2208.01820v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Aug 02, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1003642637,
        "popularmechanics":0.0960158507,
        "scienmag":0.1576490828,
        "technologyreview":0.203066942,
        "vox":0.1461998126,
        "newscientist":0.1450890079,
        "vice":0.1022866727,
        "statnews":0.1744757409,
        "nytimes":0.1383714485,
        "techcrunch":0.1344160312,
        "quartz":0.1125150962,
        "venturebeat":0.1806262166,
        "futurism":0.141198834,
        "scientificamerican":0.1308714066,
        "wired":0.1550257736,
        "popsci":0.1499218162,
        "arstechnica":0.1221975292,
        "salon":0.0950433981,
        "washingtonpost":0.157483369,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.10662v2",
        "predicted_newsworthiness":52.2558651954,
        "title":"OPerA: Object-Centric Performance Analysis",
        "summary":"Performance analysis in process mining aims to provide insights on the performance of a business process by using a process model as a formal representation of the process. Such insights are reliably interpreted by process analysts in the context of a model with formal semantics. Existing techniques for performance analysis assume that a single case notion exists in a business process (e.g., a patient in healthcare process). However, in reality, different objects might interact (e.g., order, item, delivery, and invoice in an O2C process). In such a setting, traditional techniques may yield misleading or even incorrect insights on performance metrics such as waiting time. More importantly, by considering the interaction between objects, we can define object-centric performance metrics such as synchronization time, pooling time, and lagging time. In this work, we propose a novel approach to performance analysis considering multiple case notions by using object-centric Petri nets as formal representations of business processes. The proposed approach correctly computes existing performance metrics, while supporting the derivation of newly-introduced object-centric performance metrics. We have implemented the approach as a web application and conducted a case study based on a real-life loan application process.",
        "published":1650630186000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.10662v2",
        "arxiv_primary_category":"cs.ai",
        "published_hr":"Apr 22, 2022",
        "arxiv_primary_category_hr":"Artificial Intelligence",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0861605165,
        "popularmechanics":0.0899561946,
        "scienmag":0.1059505556,
        "technologyreview":0.1454215399,
        "vox":0.0894648381,
        "newscientist":0.0817128957,
        "vice":0.0825822976,
        "statnews":0.1434618049,
        "nytimes":0.0952018678,
        "techcrunch":0.1646750126,
        "quartz":0.0990694174,
        "venturebeat":0.1953446108,
        "futurism":0.0937124373,
        "scientificamerican":0.0793069102,
        "wired":0.1063528825,
        "popsci":0.1039073046,
        "arstechnica":0.0919379899,
        "salon":0.0730871715,
        "washingtonpost":0.0910997405,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.13915v1",
        "predicted_newsworthiness":48.2750643354,
        "title":"Czech Dataset for Cross-lingual Subjectivity Classification",
        "summary":"In this paper, we introduce a new Czech subjectivity dataset of 10k manually annotated subjective and objective sentences from movie reviews and descriptions. Our prime motivation is to provide a reliable dataset that can be used with the existing English dataset as a benchmark to test the ability of pre-trained multilingual models to transfer knowledge between Czech and English and vice versa. Two annotators annotated the dataset reaching 0.83 of the Cohen's \\k{appa} inter-annotator agreement. To the best of our knowledge, this is the first subjectivity dataset for the Czech language. We also created an additional dataset that consists of 200k automatically labeled sentences. Both datasets are freely available for research purposes. Furthermore, we fine-tune five pre-trained BERT-like models to set a monolingual baseline for the new dataset and we achieve 93.56% of accuracy. We fine-tune models on the existing English dataset for which we obtained results that are on par with the current state-of-the-art results. Finally, we perform zero-shot cross-lingual subjectivity classification between Czech and English to verify the usability of our dataset as the cross-lingual benchmark. We compare and discuss the cross-lingual and monolingual results and the ability of multilingual models to transfer knowledge between languages.",
        "published":1651217506000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.13915v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Apr 29, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1589829534,
        "popularmechanics":0.1015912028,
        "scienmag":0.1280776324,
        "technologyreview":0.2180222111,
        "vox":0.1803727848,
        "newscientist":0.1384145424,
        "vice":0.0853542117,
        "statnews":0.1622350863,
        "nytimes":0.1694811245,
        "techcrunch":0.1605967723,
        "quartz":0.1696487197,
        "venturebeat":0.2046214681,
        "futurism":0.1520408038,
        "scientificamerican":0.123653316,
        "wired":0.188180302,
        "popsci":0.1497241685,
        "arstechnica":0.1416060702,
        "salon":0.1307200984,
        "washingtonpost":0.1805104489,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.04353v2",
        "predicted_newsworthiness":70.4858241035,
        "title":"Should we tweet this? Generative response modeling for predicting reception of public health messaging on Twitter",
        "summary":"The way people respond to messaging from public health organizations on social media can provide insight into public perceptions on critical health issues, especially during a global crisis such as COVID-19. It could be valuable for high-impact organizations such as the US Centers for Disease Control and Prevention (CDC) or the World Health Organization (WHO) to understand how these perceptions impact reception of messaging on health policy recommendations. We collect two datasets of public health messages and their responses from Twitter relating to COVID-19 and Vaccines, and introduce a predictive method which can be used to explore the potential reception of such messages. Specifically, we harness a generative model (GPT-2) to directly predict probable future responses and demonstrate how it can be used to optimize expected reception of important health guidance. Finally, we introduce a novel evaluation scheme with extensive statistical testing which allows us to conclude that our models capture the semantics and sentiment found in actual public health responses.",
        "published":1649469406000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.04353v2",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Apr 08, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.3015421778,
        "popularmechanics":0.1740760745,
        "scienmag":0.2897749571,
        "technologyreview":0.340586517,
        "vox":0.3530649482,
        "newscientist":0.2816773027,
        "vice":0.2147036555,
        "statnews":0.3860862728,
        "nytimes":0.3317205635,
        "techcrunch":0.2671945211,
        "quartz":0.2771047712,
        "venturebeat":0.288584792,
        "futurism":0.2795534598,
        "scientificamerican":0.327786697,
        "wired":0.3053725526,
        "popsci":0.2760609112,
        "arstechnica":0.3158325634,
        "salon":0.3784420334,
        "washingtonpost":0.3383579174,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.10137v1",
        "predicted_newsworthiness":38.37980602,
        "title":"A Generalized & Robust Framework For Timestamp Supervision in Temporal Action Segmentation",
        "summary":"In temporal action segmentation, Timestamp supervision requires only a handful of labelled frames per video sequence. For unlabelled frames, previous works rely on assigning hard labels, and performance rapidly collapses under subtle violations of the annotation assumptions. We propose a novel Expectation-Maximization (EM) based approach that leverages the label uncertainty of unlabelled frames and is robust enough to accommodate possible annotation errors. With accurate timestamp annotations, our proposed method produces SOTA results and even exceeds the fully-supervised setup in several metrics and datasets. When applied to timestamp annotations with missing action segments, our method presents stable performance. To further test our formulation's robustness, we introduce the new challenging annotation setup of Skip-tag supervision. This setup relaxes constraints and requires annotations of any fixed number of random frames in a video, making it more flexible than Timestamp supervision while remaining competitive.",
        "published":1658341848000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.10137v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 20, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0771998182,
        "popularmechanics":0.0965357349,
        "scienmag":0.076249371,
        "technologyreview":0.117868212,
        "vox":0.0820017143,
        "newscientist":0.0965953129,
        "vice":0.0855988092,
        "statnews":0.08459977,
        "nytimes":0.0983926796,
        "techcrunch":0.1014979944,
        "quartz":0.0837725861,
        "venturebeat":0.1234625104,
        "futurism":0.0962278234,
        "scientificamerican":0.0805139199,
        "wired":0.1135233769,
        "popsci":0.1108626414,
        "arstechnica":0.078126656,
        "salon":0.0733671942,
        "washingtonpost":0.092013077,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.07920v1",
        "predicted_newsworthiness":39.7916939545,
        "title":"Physics Embedded Neural Network Vehicle Model and Applications in Risk-Aware Autonomous Driving Using Latent Features",
        "summary":"Non-holonomic vehicle motion has been studied extensively using physics-based models. Common approaches when using these models interpret the wheel\/ground interactions using a linear tire model and thus may not fully capture the nonlinear and complex dynamics under various environments. On the other hand, neural network models have been widely employed in this domain, demonstrating powerful function approximation capabilities. However, these black-box learning strategies completely abandon the existing knowledge of well-known physics. In this paper, we seamlessly combine deep learning with a fully differentiable physics model to endow the neural network with available prior knowledge. The proposed model shows better generalization performance than the vanilla neural network model by a large margin. We also show that the latent features of our model can accurately represent lateral tire forces without the need for any additional training. Lastly, We develop a risk-aware model predictive controller using proprioceptive information derived from the latent features. We validate our idea in two autonomous driving tasks under unknown friction, outperforming the baseline control framework.",
        "published":1657973215000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.07920v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Jul 16, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1036384528,
        "popularmechanics":0.195715795,
        "scienmag":0.1438985303,
        "technologyreview":0.2553710771,
        "vox":0.1311482117,
        "newscientist":0.1480750925,
        "vice":0.1410394536,
        "statnews":0.1425390926,
        "nytimes":0.1369362389,
        "techcrunch":0.1872079973,
        "quartz":0.1187872519,
        "venturebeat":0.2209940366,
        "futurism":0.2268160043,
        "scientificamerican":0.1338007047,
        "wired":0.2034997255,
        "popsci":0.2563011315,
        "arstechnica":0.123212251,
        "salon":0.1081414455,
        "washingtonpost":0.1522179939,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.09303v1",
        "predicted_newsworthiness":43.4452480972,
        "title":"DH-AUG: DH Forward Kinematics Model Driven Augmentation for 3D Human Pose Estimation",
        "summary":"Due to the lack of diversity of datasets, the generalization ability of the pose estimator is poor. To solve this problem, we propose a pose augmentation solution via DH forward kinematics model, which we call DH-AUG. We observe that the previous work is all based on single-frame pose augmentation, if it is directly applied to video pose estimator, there will be several previously ignored problems: (i) angle ambiguity in bone rotation (multiple solutions); (ii) the generated skeleton video lacks movement continuity. To solve these problems, we propose a special generator based on DH forward kinematics model, which is called DH-generator. Extensive experiments demonstrate that DH-AUG can greatly increase the generalization ability of the video pose estimator. In addition, when applied to a single-frame 3D pose estimator, our method outperforms the previous best pose augmentation method. The source code has been released at https:\/\/github.com\/hlz0606\/DH-AUG-DH-Forward-Kinematics-Model-Driven-Augmentation-for-3D-Human-Pose-Estimation.",
        "published":1658241466000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.09303v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 19, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0784689772,
        "popularmechanics":0.1473281595,
        "scienmag":0.1135077859,
        "technologyreview":0.1720641459,
        "vox":0.0940867759,
        "newscientist":0.1318088951,
        "vice":0.1075361092,
        "statnews":0.1164553662,
        "nytimes":0.1130596335,
        "techcrunch":0.1449811191,
        "quartz":0.0968625474,
        "venturebeat":0.1947014064,
        "futurism":0.163015454,
        "scientificamerican":0.105475571,
        "wired":0.1496557468,
        "popsci":0.1755206658,
        "arstechnica":0.1034204239,
        "salon":0.0838809427,
        "washingtonpost":0.1307217806,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.02526v1",
        "predicted_newsworthiness":46.3871929246,
        "title":"Learning Target-aware Representation for Visual Tracking via Informative Interactions",
        "summary":"We introduce a novel backbone architecture to improve target-perception ability of feature representation for tracking. Specifically, having observed that de facto frameworks perform feature matching simply using the outputs from backbone for target localization, there is no direct feedback from the matching module to the backbone network, especially the shallow layers. More concretely, only the matching module can directly access the target information (in the reference frame), while the representation learning of candidate frame is blind to the reference target. As a consequence, the accumulation effect of target-irrelevant interference in the shallow stages may degrade the feature quality of deeper layers. In this paper, we approach the problem from a different angle by conducting multiple branch-wise interactions inside the Siamese-like backbone networks (InBN). At the core of InBN is a general interaction modeler (GIM) that injects the prior knowledge of reference image to different stages of the backbone network, leading to better target-perception and robust distractor-resistance of candidate feature representation with negligible computation cost. The proposed GIM module and InBN mechanism are general and applicable to different backbone types including CNN and Transformer for improvements, as evidenced by our extensive experiments on multiple benchmarks. In particular, the CNN version (based on SiamCAR) improves the baseline with 3.2\/6.9 absolute gains of SUC on LaSOT\/TNL2K, respectively. The Transformer version obtains SUC scores of 65.7\/52.0 on LaSOT\/TNL2K, which are on par with recent state of the arts. Code and models will be released.",
        "published":1641572547000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.02526v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jan 07, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0859037414,
        "popularmechanics":0.1531770262,
        "scienmag":0.130284876,
        "technologyreview":0.2442006977,
        "vox":0.1215268588,
        "newscientist":0.1456854544,
        "vice":0.1019741387,
        "statnews":0.137617037,
        "nytimes":0.1345357015,
        "techcrunch":0.1651401426,
        "quartz":0.1124421014,
        "venturebeat":0.2193405557,
        "futurism":0.1833502404,
        "scientificamerican":0.1233366603,
        "wired":0.1706725014,
        "popsci":0.1904265604,
        "arstechnica":0.1115529569,
        "salon":0.080941326,
        "washingtonpost":0.1421295839,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.09287v1",
        "predicted_newsworthiness":33.9354911884,
        "title":"HybridCap: Inertia-aid Monocular Capture of Challenging Human Motions",
        "summary":"Monocular 3D motion capture (mocap) is beneficial to many applications. The use of a single camera, however, often fails to handle occlusions of different body parts and hence it is limited to capture relatively simple movements. We present a light-weight, hybrid mocap technique called HybridCap that augments the camera with only 4 Inertial Measurement Units (IMUs) in a learning-and-optimization framework. We first employ a weakly-supervised and hierarchical motion inference module based on cooperative Gated Recurrent Unit (GRU) blocks that serve as limb, body and root trackers as well as an inverse kinematics solver. Our network effectively narrows the search space of plausible motions via coarse-to-fine pose estimation and manages to tackle challenging movements with high efficiency. We further develop a hybrid optimization scheme that combines inertial feedback and visual cues to improve tracking accuracy. Extensive experiments on various datasets demonstrate HybridCap can robustly handle challenging movements ranging from fitness actions to Latin dance. It also achieves real-time performance up to 60 fps with state-of-the-art accuracy.",
        "published":1647520217000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.09287v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Mar 17, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0731447863,
        "popularmechanics":0.138111874,
        "scienmag":0.1055445298,
        "technologyreview":0.1730649797,
        "vox":0.087568154,
        "newscientist":0.1306771465,
        "vice":0.099726606,
        "statnews":0.1177140795,
        "nytimes":0.1107370254,
        "techcrunch":0.140917444,
        "quartz":0.0916980284,
        "venturebeat":0.1878135421,
        "futurism":0.1572597727,
        "scientificamerican":0.0989221024,
        "wired":0.1577431321,
        "popsci":0.1711805053,
        "arstechnica":0.0805082845,
        "salon":0.0669738489,
        "washingtonpost":0.1109715725,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.01987v1",
        "predicted_newsworthiness":42.7560685022,
        "title":"Open-Vocabulary 3D Detection via Image-level Class and Debiased Cross-modal Contrastive Learning",
        "summary":"Current point-cloud detection methods have difficulty detecting the open-vocabulary objects in the real world, due to their limited generalization capability. Moreover, it is extremely laborious and expensive to collect and fully annotate a point-cloud detection dataset with numerous classes of objects, leading to the limited classes of existing point-cloud datasets and hindering the model to learn general representations to achieve open-vocabulary point-cloud detection. As far as we know, we are the first to study the problem of open-vocabulary 3D point-cloud detection. Instead of seeking a point-cloud dataset with full labels, we resort to ImageNet1K to broaden the vocabulary of the point-cloud detector. We propose OV-3DETIC, an Open-Vocabulary 3D DETector using Image-level Class supervision. Specifically, we take advantage of two modalities, the image modality for recognition and the point-cloud modality for localization, to generate pseudo labels for unseen classes. Then we propose a novel debiased cross-modal contrastive learning method to transfer the knowledge from image modality to point-cloud modality during training. Without hurting the latency during inference, OV-3DETIC makes the point-cloud detector capable of achieving open-vocabulary detection. Extensive experiments demonstrate that the proposed OV-3DETIC achieves at least 10.77 % mAP improvement (absolute value) and 9.56 % mAP improvement (absolute value) by a wide range of baselines on the SUN-RGBD dataset and ScanNet dataset, respectively. Besides, we conduct sufficient experiments to shed light on why the proposed OV-3DETIC works.",
        "published":1657023232000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.01987v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 05, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0894882775,
        "popularmechanics":0.1589096993,
        "scienmag":0.1308488982,
        "technologyreview":0.2157604041,
        "vox":0.1238740238,
        "newscientist":0.1391284485,
        "vice":0.1448827626,
        "statnews":0.1149287259,
        "nytimes":0.1301822955,
        "techcrunch":0.1694848167,
        "quartz":0.1153859715,
        "venturebeat":0.2039319898,
        "futurism":0.1750384378,
        "scientificamerican":0.1178927008,
        "wired":0.1680475627,
        "popsci":0.1773533731,
        "arstechnica":0.1326980299,
        "salon":0.1008102425,
        "washingtonpost":0.1458347376,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.01993v2",
        "predicted_newsworthiness":37.2671734406,
        "title":"Polarity Sampling: Quality and Diversity Control of Pre-Trained Generative Networks via Singular Values",
        "summary":"We present Polarity Sampling, a theoretically justified plug-and-play method for controlling the generation quality and diversity of pre-trained deep generative networks DGNs). Leveraging the fact that DGNs are, or can be approximated by, continuous piecewise affine splines, we derive the analytical DGN output space distribution as a function of the product of the DGN's Jacobian singular values raised to a power $\\rho$. We dub $\\rho$ the $\\textbf{polarity}$ parameter and prove that $\\rho$ focuses the DGN sampling on the modes ($\\rho < 0$) or anti-modes ($\\rho > 0$) of the DGN output-space distribution. We demonstrate that nonzero polarity values achieve a better precision-recall (quality-diversity) Pareto frontier than standard methods, such as truncation, for a number of state-of-the-art DGNs. We also present quantitative and qualitative results on the improvement of overall generation quality (e.g., in terms of the Frechet Inception Distance) for a number of state-of-the-art DGNs, including StyleGAN3, BigGAN-deep, NVAE, for different conditional and unconditional image generation tasks. In particular, Polarity Sampling redefines the state-of-the-art for StyleGAN2 on the FFHQ Dataset to FID 2.57, StyleGAN2 on the LSUN Car Dataset to FID 2.27 and StyleGAN3 on the AFHQv2 Dataset to FID 3.95. Demo: bit.ly\/polarity-samp",
        "published":1646338609000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.01993v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Mar 03, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0929610665,
        "popularmechanics":0.1320321693,
        "scienmag":0.1132654338,
        "technologyreview":0.2011783286,
        "vox":0.1159790844,
        "newscientist":0.1224832665,
        "vice":0.105569812,
        "statnews":0.1275444716,
        "nytimes":0.1226025508,
        "techcrunch":0.1483095834,
        "quartz":0.1209865874,
        "venturebeat":0.1847352943,
        "futurism":0.1526521348,
        "scientificamerican":0.1028068171,
        "wired":0.1623868425,
        "popsci":0.1486189881,
        "arstechnica":0.1220348287,
        "salon":0.0939254434,
        "washingtonpost":0.1308642766,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.08232v1",
        "predicted_newsworthiness":37.596632928,
        "title":"LogicSolver: Towards Interpretable Math Word Problem Solving with Logical Prompt-enhanced Learning",
        "summary":"Recently, deep learning models have made great progress in MWP solving on answer accuracy. However, they are uninterpretable since they mainly rely on shallow heuristics to achieve high performance without understanding and reasoning the grounded math logic. To address this issue and make a step towards interpretable MWP solving, we first construct a high-quality MWP dataset named InterMWP which consists of 11,495 MWPs and annotates interpretable logical formulas based on algebraic knowledge as the grounded linguistic logic of each solution equation. Different from existing MWP datasets, our InterMWP benchmark asks for a solver to not only output the solution expressions but also predict the corresponding logical formulas. We further propose a novel approach with logical prompt and interpretation generation, called LogicSolver. For each MWP, our LogicSolver first retrieves some highly-correlated algebraic knowledge and then passes them to the backbone model as prompts to improve the semantic representations of MWPs. With these improved semantic representations, our LogicSolver generates corresponding solution expressions and interpretable knowledge formulas in accord with the generated solution expressions, simultaneously. Experimental results show that our LogicSolver has stronger logical formula-based interpretability than baselines while achieving higher answer accuracy with the help of logical prompts, simultaneously.",
        "published":1652785312000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.08232v1",
        "arxiv_primary_category":"cs.ai",
        "published_hr":"May 17, 2022",
        "arxiv_primary_category_hr":"Artificial Intelligence",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0994708346,
        "popularmechanics":0.1136582146,
        "scienmag":0.1147370926,
        "technologyreview":0.234816128,
        "vox":0.1186997713,
        "newscientist":0.1310162388,
        "vice":0.0966569177,
        "statnews":0.190137201,
        "nytimes":0.1328628278,
        "techcrunch":0.1568921982,
        "quartz":0.1114702791,
        "venturebeat":0.234791956,
        "futurism":0.1567324173,
        "scientificamerican":0.1102013188,
        "wired":0.1581235002,
        "popsci":0.1486140297,
        "arstechnica":0.1064900009,
        "salon":0.0975117144,
        "washingtonpost":0.1182888868,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.10392v1",
        "predicted_newsworthiness":39.4328538557,
        "title":"FADE: Fusing the Assets of Decoder and Encoder for Task-Agnostic Upsampling",
        "summary":"We consider the problem of task-agnostic feature upsampling in dense prediction where an upsampling operator is required to facilitate both region-sensitive tasks like semantic segmentation and detail-sensitive tasks such as image matting. Existing upsampling operators often can work well in either type of the tasks, but not both. In this work, we present FADE, a novel, plug-and-play, and task-agnostic upsampling operator. FADE benefits from three design choices: i) considering encoder and decoder features jointly in upsampling kernel generation; ii) an efficient semi-shift convolutional operator that enables granular control over how each feature point contributes to upsampling kernels; iii) a decoder-dependent gating mechanism for enhanced detail delineation. We first study the upsampling properties of FADE on toy data and then evaluate it on large-scale semantic segmentation and image matting. In particular, FADE reveals its effectiveness and task-agnostic characteristic by consistently outperforming recent dynamic upsampling operators in different tasks. It also generalizes well across convolutional and transformer architectures with little computational overhead. Our work additionally provides thoughtful insights on what makes for task-agnostic upsampling. Code is available at: http:\/\/lnkiy.in\/fade_in",
        "published":1658397961000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.10392v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 21, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0781072493,
        "popularmechanics":0.1127793223,
        "scienmag":0.0945004813,
        "technologyreview":0.17150602,
        "vox":0.1049779484,
        "newscientist":0.0968623185,
        "vice":0.0801653946,
        "statnews":0.0995858883,
        "nytimes":0.1031193939,
        "techcrunch":0.1283769211,
        "quartz":0.0959156168,
        "venturebeat":0.1693225714,
        "futurism":0.1224947609,
        "scientificamerican":0.0876948092,
        "wired":0.1413193915,
        "popsci":0.1439210606,
        "arstechnica":0.0733552764,
        "salon":0.0851079024,
        "washingtonpost":0.1043551628,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.16708v1",
        "predicted_newsworthiness":49.1784086125,
        "title":"Task Adaptive Parameter Sharing for Multi-Task Learning",
        "summary":"Adapting pre-trained models with broad capabilities has become standard practice for learning a wide range of downstream tasks. The typical approach of fine-tuning different models for each task is performant, but incurs a substantial memory cost. To efficiently learn multiple downstream tasks we introduce Task Adaptive Parameter Sharing (TAPS), a general method for tuning a base model to a new task by adaptively modifying a small, task-specific subset of layers. This enables multi-task learning while minimizing resources used and competition between tasks. TAPS solves a joint optimization problem which determines which layers to share with the base model and the value of the task-specific weights. Further, a sparsity penalty on the number of active layers encourages weight sharing with the base model. Compared to other methods, TAPS retains high accuracy on downstream tasks while introducing few task-specific parameters. Moreover, TAPS is agnostic to the model architecture and requires only minor changes to the training scheme. We evaluate our method on a suite of fine-tuning tasks and architectures (ResNet, DenseNet, ViT) and show that it achieves state-of-the-art performance while being simple to implement.",
        "published":1648682167000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.16708v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Mar 30, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0825674795,
        "popularmechanics":0.1220203562,
        "scienmag":0.1169525381,
        "technologyreview":0.2354177173,
        "vox":0.1114333527,
        "newscientist":0.1167593878,
        "vice":0.0773447917,
        "statnews":0.1532634936,
        "nytimes":0.1123396665,
        "techcrunch":0.1541489082,
        "quartz":0.103278621,
        "venturebeat":0.226487522,
        "futurism":0.1545726248,
        "scientificamerican":0.098278887,
        "wired":0.1481351319,
        "popsci":0.1628264558,
        "arstechnica":0.0902092556,
        "salon":0.0808821455,
        "washingtonpost":0.1244790655,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.09638v1",
        "predicted_newsworthiness":39.3915955192,
        "title":"Certified Error Control of Candidate Set Pruning for Two-Stage Relevance Ranking",
        "summary":"In information retrieval (IR), candidate set pruning has been commonly used to speed up two-stage relevance ranking. However, such an approach lacks accurate error control and often trades accuracy off against computational efficiency in an empirical fashion, lacking theoretical guarantees. In this paper, we propose the concept of certified error control of candidate set pruning for relevance ranking, which means that the test error after pruning is guaranteed to be controlled under a user-specified threshold with high probability. Both in-domain and out-of-domain experiments show that our method successfully prunes the first-stage retrieved candidate sets to improve the second-stage reranking speed while satisfying the pre-specified accuracy constraints in both settings. For example, on MS MARCO Passage v1, our method yields an average candidate set size of 27 out of 1,000 which increases the reranking speed by about 37 times, while the MRR@10 is greater than a pre-specified value of 0.38 with about 90% empirical coverage and the empirical baselines fail to provide such guarantee. Code and data are available at: https:\/\/github.com\/alexlimh\/CEC-Ranking.",
        "published":1652976013000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.09638v1",
        "arxiv_primary_category":"cs.ir",
        "published_hr":"May 19, 2022",
        "arxiv_primary_category_hr":"Information Retrieval",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0926429317,
        "popularmechanics":0.1096425939,
        "scienmag":0.1216269913,
        "technologyreview":0.1693986536,
        "vox":0.1305101357,
        "newscientist":0.0988618626,
        "vice":0.0869774359,
        "statnews":0.1522286601,
        "nytimes":0.1343954038,
        "techcrunch":0.1548902218,
        "quartz":0.1156047312,
        "venturebeat":0.1863598677,
        "futurism":0.1172509562,
        "scientificamerican":0.1068816806,
        "wired":0.1346114832,
        "popsci":0.1315875631,
        "arstechnica":0.1376833992,
        "salon":0.0899582381,
        "washingtonpost":0.1337807413,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.07723v1",
        "predicted_newsworthiness":71.4221316522,
        "title":"More Data Can Lead Us Astray: Active Data Acquisition in the Presence of Label Bias",
        "summary":"An increased awareness concerning risks of algorithmic bias has driven a surge of efforts around bias mitigation strategies. A vast majority of the proposed approaches fall under one of two categories: (1) imposing algorithmic fairness constraints on predictive models, and (2) collecting additional training samples. Most recently and at the intersection of these two categories, methods that propose active learning under fairness constraints have been developed. However, proposed bias mitigation strategies typically overlook the bias presented in the observed labels. In this work, we study fairness considerations of active data collection strategies in the presence of label bias. We first present an overview of different types of label bias in the context of supervised learning systems. We then empirically show that, when overlooking label bias, collecting more data can aggravate bias, and imposing fairness constraints that rely on the observed labels in the data collection process may not address the problem. Our results illustrate the unintended consequences of deploying a model that attempts to mitigate a single type of bias while neglecting others, emphasizing the importance of explicitly differentiating between the types of bias that fairness-aware algorithms aim to address, and highlighting the risks of neglecting label bias during data collection.",
        "published":1657913450000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.07723v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jul 15, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1859793995,
        "popularmechanics":0.1317535935,
        "scienmag":0.197386414,
        "technologyreview":0.3099156112,
        "vox":0.2340115482,
        "newscientist":0.1897145109,
        "vice":0.1251026299,
        "statnews":0.2948152253,
        "nytimes":0.2243708415,
        "techcrunch":0.2282280451,
        "quartz":0.1990630431,
        "venturebeat":0.278711767,
        "futurism":0.218625906,
        "scientificamerican":0.1979067229,
        "wired":0.2272975077,
        "popsci":0.2094124661,
        "arstechnica":0.2087445296,
        "salon":0.1817608963,
        "washingtonpost":0.2318874088,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.05151v1",
        "predicted_newsworthiness":47.375706214,
        "title":"Beyond Simple Meta-Learning: Multi-Purpose Models for Multi-Domain, Active and Continual Few-Shot Learning",
        "summary":"Modern deep learning requires large-scale extensively labelled datasets for training. Few-shot learning aims to alleviate this issue by learning effectively from few labelled examples. In previously proposed few-shot visual classifiers, it is assumed that the feature manifold, where classifier decisions are made, has uncorrelated feature dimensions and uniform feature variance. In this work, we focus on addressing the limitations arising from this assumption by proposing a variance-sensitive class of models that operates in a low-label regime. The first method, Simple CNAPS, employs a hierarchically regularized Mahalanobis-distance based classifier combined with a state of the art neural adaptive feature extractor to achieve strong performance on Meta-Dataset, mini-ImageNet and tiered-ImageNet benchmarks. We further extend this approach to a transductive learning setting, proposing Transductive CNAPS. This transductive method combines a soft k-means parameter refinement procedure with a two-step task encoder to achieve improved test-time classification accuracy using unlabelled data. Transductive CNAPS achieves state of the art performance on Meta-Dataset. Finally, we explore the use of our methods (Simple and Transductive) for \"out of the box\" continual and active learning. Extensive experiments on large scale benchmarks illustrate robustness and versatility of this, relatively speaking, simple class of models. All trained model checkpoints and corresponding source codes have been made publicly available.",
        "published":1642100342000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.05151v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jan 13, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0925108765,
        "popularmechanics":0.1355646256,
        "scienmag":0.1360325877,
        "technologyreview":0.2440044465,
        "vox":0.1095023889,
        "newscientist":0.1364584336,
        "vice":0.108560526,
        "statnews":0.1864419112,
        "nytimes":0.1336895852,
        "techcrunch":0.146546711,
        "quartz":0.1125228207,
        "venturebeat":0.2161303873,
        "futurism":0.1609722231,
        "scientificamerican":0.1159527358,
        "wired":0.1634924838,
        "popsci":0.1692391831,
        "arstechnica":0.1114684956,
        "salon":0.1023197404,
        "washingtonpost":0.1339173481,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.06089v1",
        "predicted_newsworthiness":42.655363337,
        "title":"An effective and efficient label initialization method based on similarity for community detection in networks",
        "summary":"Identifying clusters or community structures in networks has become an integral part of social network analysis. Though many methods were proposed, the label propagation algorithm (LPA) is a popular computationally efficient method with running time linear. However, the LPA provides different combination of communities on the same network due to the randomness in LPA. Many improvements have been proposed to tackle this stability problem by eliminating the randomness. This paper put forward an improvement to the standard LPA by proposing a label initialization method based on link similarity. The similarity is measured based on the connection strength between two nodes. The method is tested on real and synthetic measures to analyze the performance.",
        "published":1642352027000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.06089v1",
        "arxiv_primary_category":"cs.si",
        "published_hr":"Jan 16, 2022",
        "arxiv_primary_category_hr":"Social and Information Networks",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1128255362,
        "popularmechanics":0.094686978,
        "scienmag":0.1418834454,
        "technologyreview":0.1570568822,
        "vox":0.1283998915,
        "newscientist":0.1241984493,
        "vice":0.1081391822,
        "statnews":0.134942282,
        "nytimes":0.123193502,
        "techcrunch":0.1419854956,
        "quartz":0.1151953199,
        "venturebeat":0.1537339511,
        "futurism":0.1183353522,
        "scientificamerican":0.13484323,
        "wired":0.1289299155,
        "popsci":0.1379671879,
        "arstechnica":0.10720705,
        "salon":0.0962369293,
        "washingtonpost":0.1512686731,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.02397v1",
        "predicted_newsworthiness":48.1867754698,
        "title":"SALISA: Saliency-based Input Sampling for Efficient Video Object Detection",
        "summary":"High-resolution images are widely adopted for high-performance object detection in videos. However, processing high-resolution inputs comes with high computation costs, and naive down-sampling of the input to reduce the computation costs quickly degrades the detection performance. In this paper, we propose SALISA, a novel non-uniform SALiency-based Input SAmpling technique for video object detection that allows for heavy down-sampling of unimportant background regions while preserving the fine-grained details of a high-resolution image. The resulting image is spatially smaller, leading to reduced computational costs while enabling a performance comparable to a high-resolution input. To achieve this, we propose a differentiable resampling module based on a thin plate spline spatial transformer network (TPS-STN). This module is regularized by a novel loss to provide an explicit supervision signal to learn to \"magnify\" salient regions. We report state-of-the-art results in the low compute regime on the ImageNet-VID and UA-DETRAC video object detection datasets. We demonstrate that on both datasets, the mAP of an EfficientDet-D1 (EfficientDet-D2) gets on par with EfficientDet-D2 (EfficientDet-D3) at a much lower computational cost. We also show that SALISA significantly improves the detection of small objects. In particular, SALISA with an EfficientDet-D1 detector improves the detection of small objects by $77\\%$, and remarkably also outperforms EfficientDetD3 baseline.",
        "published":1649181591000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.02397v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Apr 05, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0829032533,
        "popularmechanics":0.1384738552,
        "scienmag":0.1032485974,
        "technologyreview":0.1846217766,
        "vox":0.0972422633,
        "newscientist":0.1237085163,
        "vice":0.0999166728,
        "statnews":0.0835654996,
        "nytimes":0.1088109668,
        "techcrunch":0.13701052,
        "quartz":0.1009936497,
        "venturebeat":0.16689388,
        "futurism":0.1460250787,
        "scientificamerican":0.1104361688,
        "wired":0.1508632178,
        "popsci":0.1606500855,
        "arstechnica":0.097288344,
        "salon":0.0786468112,
        "washingtonpost":0.1353259573,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.13309v1",
        "predicted_newsworthiness":41.0681091821,
        "title":"Federated Selective Aggregation for Knowledge Amalgamation",
        "summary":"In this paper, we explore a new knowledge-amalgamation problem, termed Federated Selective Aggregation (FedSA). The goal of FedSA is to train a student model for a new task with the help of several decentralized teachers, whose pre-training tasks and data are different and agnostic. Our motivation for investigating such a problem setup stems from a recent dilemma of model sharing. Many researchers or institutes have spent enormous resources on training large and competent networks. Due to the privacy, security, or intellectual property issues, they are, however, not able to share their own pre-trained models, even if they wish to contribute to the community. The proposed FedSA offers a solution to this dilemma and makes it one step further since, again, the learned student may specialize in a new task different from all of the teachers. To this end, we proposed a dedicated strategy for handling FedSA. Specifically, our student-training process is driven by a novel saliency-based approach that adaptively selects teachers as the participants and integrates their representative capabilities into the student. To evaluate the effectiveness of FedSA, we conduct experiments on both single-task and multi-task settings. Experimental results demonstrate that FedSA effectively amalgamates knowledge from decentralized models and achieves competitive performance to centralized baselines.",
        "published":1658900210000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.13309v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 27, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1456722567,
        "popularmechanics":0.1398971404,
        "scienmag":0.1876254614,
        "technologyreview":0.2904809134,
        "vox":0.1829292246,
        "newscientist":0.1779524548,
        "vice":0.1671987822,
        "statnews":0.2553704136,
        "nytimes":0.205861258,
        "techcrunch":0.218324934,
        "quartz":0.1496931838,
        "venturebeat":0.2770918708,
        "futurism":0.2060236338,
        "scientificamerican":0.175634164,
        "wired":0.2143993718,
        "popsci":0.2000590554,
        "arstechnica":0.1606927495,
        "salon":0.1391698756,
        "washingtonpost":0.1858456493,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.13887v1",
        "predicted_newsworthiness":42.8030948211,
        "title":"Adaptive Second Order Coresets for Data-efficient Machine Learning",
        "summary":"Training machine learning models on massive datasets incurs substantial computational costs. To alleviate such costs, there has been a sustained effort to develop data-efficient training methods that can carefully select subsets of the training examples that generalize on par with the full training data. However, existing methods are limited in providing theoretical guarantees for the quality of the models trained on the extracted subsets, and may perform poorly in practice. We propose AdaCore, a method that leverages the geometry of the data to extract subsets of the training examples for efficient machine learning. The key idea behind our method is to dynamically approximate the curvature of the loss function via an exponentially-averaged estimate of the Hessian to select weighted subsets (coresets) that provide a close approximation of the full gradient preconditioned with the Hessian. We prove rigorous guarantees for the convergence of various first and second-order methods applied to the subsets chosen by AdaCore. Our extensive experiments show that AdaCore extracts coresets with higher quality compared to baselines and speeds up training of convex and non-convex machine learning models, such as logistic regression and neural networks, by over 2.9x over the full data and 4.5x over random subsets.",
        "published":1658986989000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.13887v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jul 28, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0775841308,
        "popularmechanics":0.1261847865,
        "scienmag":0.1417132206,
        "technologyreview":0.2551346604,
        "vox":0.125808389,
        "newscientist":0.1254080291,
        "vice":0.0937129609,
        "statnews":0.2419010411,
        "nytimes":0.1286539663,
        "techcrunch":0.1716579109,
        "quartz":0.1040263428,
        "venturebeat":0.2520633627,
        "futurism":0.1692081283,
        "scientificamerican":0.0979957799,
        "wired":0.1614951774,
        "popsci":0.174365381,
        "arstechnica":0.109687344,
        "salon":0.0941063078,
        "washingtonpost":0.1438715734,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.12592v1",
        "predicted_newsworthiness":32.6189434907,
        "title":"Exact Decomposition of Joint Low Rankness and Local Smoothness Plus Sparse Matrices",
        "summary":"It is known that the decomposition in low-rank and sparse matrices (\\textbf{L+S} for short) can be achieved by several Robust PCA techniques. Besides the low rankness, the local smoothness (\\textbf{LSS}) is a vitally essential prior for many real-world matrix data such as hyperspectral images and surveillance videos, which makes such matrices have low-rankness and local smoothness properties at the same time. This poses an interesting question: Can we make a matrix decomposition in terms of \\textbf{L\\&LSS +S } form exactly? To address this issue, we propose in this paper a new RPCA model based on three-dimensional correlated total variation regularization (3DCTV-RPCA for short) by fully exploiting and encoding the prior expression underlying such joint low-rank and local smoothness matrices. Specifically, using a modification of Golfing scheme, we prove that under some mild assumptions, the proposed 3DCTV-RPCA model can decompose both components exactly, which should be the first theoretical guarantee among all such related methods combining low rankness and local smoothness. In addition, by utilizing Fast Fourier Transform (FFT), we propose an efficient ADMM algorithm with a solid convergence guarantee for solving the resulting optimization problem. Finally, a series of experiments on both simulations and real applications are carried out to demonstrate the general validity of the proposed 3DCTV-RPCA model.",
        "published":1643464683000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.12592v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jan 29, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0403941681,
        "popularmechanics":0.0763639142,
        "scienmag":0.0839832394,
        "technologyreview":0.0934322969,
        "vox":0.0454864035,
        "newscientist":0.0683963994,
        "vice":0.0739659622,
        "statnews":0.0679112358,
        "nytimes":0.0575413871,
        "techcrunch":0.0582280338,
        "quartz":0.0486294871,
        "venturebeat":0.0816008582,
        "futurism":0.0764784029,
        "scientificamerican":0.0593246175,
        "wired":0.0832599046,
        "popsci":0.0818253707,
        "arstechnica":0.0607468129,
        "salon":0.0501283755,
        "washingtonpost":0.0618711815,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.02795v1",
        "predicted_newsworthiness":45.2813780833,
        "title":"Controlling camera movement in VR colonography",
        "summary":"Immersive Colonography allows medical professionals to navigate inside the intricate tubular geometries of subject-specific 3D colon images using Virtual Reality displays. Typically, camera travel is performed via Fly-Through or Fly-Over techniques that enable semi-automatic traveling through a constrained, well-defined path at user-controlled speeds. However, Fly-Through is known to limit the visibility of lesions located behind or inside haustral folds. At the same time, Fly-Over requires splitting the entire colon visualization into two specific halves. In this paper, we study the effect of immersive Fly-Through and Fly-Over techniques on lesion detection and introduce a camera travel technique that maintains a fixed camera orientation throughout the entire medial axis path. While these techniques have been studied in non-VR desktop environments, their performance is not well understood in VR setups. We performed a comparative study to ascertain which camera travel technique is more appropriate for constrained path navigation in Immersive Colonography and validated our conclusions with two radiologists. To this end, we asked 18 participants to navigate inside a 3D colon to find specific marks. Our results suggest that the Fly-Over technique may lead to enhanced lesion detection at the cost of higher task completion times. Nevertheless, the Fly-Through method may offer a more balanced trade-off between speed and effectiveness, whereas the fixed camera orientation technique provided seemingly inferior performance results. Our study further provides design guidelines and informs future work.",
        "published":1641632859000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.02795v1",
        "arxiv_primary_category":"cs.hc",
        "published_hr":"Jan 08, 2022",
        "arxiv_primary_category_hr":"Human-Computer Interaction",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1420081084,
        "popularmechanics":0.2148869092,
        "scienmag":0.2209472863,
        "technologyreview":0.2386683119,
        "vox":0.1522129731,
        "newscientist":0.2109389959,
        "vice":0.1880136831,
        "statnews":0.2623626167,
        "nytimes":0.2061632228,
        "techcrunch":0.2158196363,
        "quartz":0.1479866171,
        "venturebeat":0.3061667179,
        "futurism":0.2359492044,
        "scientificamerican":0.1755103458,
        "wired":0.2380709101,
        "popsci":0.2640073373,
        "arstechnica":0.1619064586,
        "salon":0.1631220842,
        "washingtonpost":0.1936867808,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.03644v1",
        "predicted_newsworthiness":40.05323456,
        "title":"Calibrating Label Distribution for Class-Imbalanced Barely-Supervised Knee Segmentation",
        "summary":"Segmentation of 3D knee MR images is important for the assessment of osteoarthritis. Like other medical data, the volume-wise labeling of knee MR images is expertise-demanded and time-consuming; hence semi-supervised learning (SSL), particularly barely-supervised learning, is highly desirable for training with insufficient labeled data. We observed that the class imbalance problem is severe in the knee MR images as the cartilages only occupy 6% of foreground volumes, and the situation becomes worse without sufficient labeled data. To address the above problem, we present a novel framework for barely-supervised knee segmentation with noisy and imbalanced labels. Our framework leverages label distribution to encourage the network to put more effort into learning cartilage parts. Specifically, we utilize 1.) label quantity distribution for modifying the objective loss function to a class-aware weighted form and 2.) label position distribution for constructing a cropping probability mask to crop more sub-volumes in cartilage areas from both labeled and unlabeled inputs. In addition, we design dual uncertainty-aware sampling supervision to enhance the supervision of low-confident categories for efficient unsupervised learning. Experiments show that our proposed framework brings significant improvements by incorporating the unlabeled data and alleviating the problem of class imbalance. More importantly, our method outperforms the state-of-the-art SSL methods, demonstrating the potential of our framework for the more challenging SSL setting.",
        "published":1651927986000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.03644v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 07, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0858520726,
        "popularmechanics":0.1050722606,
        "scienmag":0.1512532939,
        "technologyreview":0.1845800844,
        "vox":0.0988924648,
        "newscientist":0.1202226588,
        "vice":0.1001928207,
        "statnews":0.2032578554,
        "nytimes":0.1137022558,
        "techcrunch":0.12132503,
        "quartz":0.0914511945,
        "venturebeat":0.1600143717,
        "futurism":0.1291798853,
        "scientificamerican":0.1139436217,
        "wired":0.1272347361,
        "popsci":0.1306017342,
        "arstechnica":0.0924307019,
        "salon":0.1025832425,
        "washingtonpost":0.1102786097,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.01513v1",
        "predicted_newsworthiness":77.9512580532,
        "title":"Mitigating Sovereign Data Exchange Challenges: A Mapping to Apply Privacy- and Authenticity-Enhancing Technologies",
        "summary":"Harmful repercussions from sharing sensitive or personal data can hamper institutions' willingness to engage in data exchange. Thus, institutions consider Authenticity Enhancing Technologies (AETs) and Privacy-Enhancing Technologies (PETs) to engage in Sovereign Data Exchange (SDE), i.e., sharing data with third parties without compromising their own or their users' data sovereignty. However, these technologies are often technically complex, which impedes their adoption. To support practitioners select PETs and AETs for SDE use cases and highlight SDE challenges researchers and practitioners should address, this study empirically constructs a challenge-oriented technology mapping. First, we compile challenges of SDE by conducting a systematic literature review and expert interviews. Second, we map PETs and AETs to the SDE challenges and identify which technologies can mitigate which challenges. We validate the mapping through investigator triangulation. Although the most critical challenge concerns data usage and access control, we find that the majority of PETs and AETs focus on data processing issues.",
        "published":1655713002000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.01513v1",
        "arxiv_primary_category":"cs.cy",
        "published_hr":"Jun 20, 2022",
        "arxiv_primary_category_hr":"Computers and Society",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2477495063,
        "popularmechanics":0.1874241348,
        "scienmag":0.2032311555,
        "technologyreview":0.3877056402,
        "vox":0.3080990982,
        "newscientist":0.2163426072,
        "vice":0.1672815055,
        "statnews":0.3284791151,
        "nytimes":0.2933516288,
        "techcrunch":0.3555631351,
        "quartz":0.27253621,
        "venturebeat":0.3672940725,
        "futurism":0.2836232772,
        "scientificamerican":0.2059580259,
        "wired":0.325612453,
        "popsci":0.2857133044,
        "arstechnica":0.3149596597,
        "salon":0.2071307901,
        "washingtonpost":0.322270533,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.12520v1",
        "predicted_newsworthiness":40.1739556819,
        "title":"3D Lidar Reconstruction with Probabilistic Depth Completion for Robotic Navigation",
        "summary":"Safe motion planning in robotics requires planning into space which has been verified to be free of obstacles. However, obtaining such environment representations using lidars is challenging by virtue of the sparsity of their depth measurements. We present a learning-aided 3D lidar reconstruction framework that upsamples sparse lidar depth measurements with the aid of overlapping camera images so as to generate denser reconstructions with more definitively free space than can be achieved with the raw lidar measurements alone. We use a neural network with an encoder-decoder structure to predict dense depth images along with depth uncertainty estimates which are fused using a volumetric mapping system. We conduct experiments on real-world outdoor datasets captured using a handheld sensing device and a legged robot. Using input data from a 16-beam lidar mapping a building network, our experiments showed that the amount of estimated free space was increased by more than 40% with our approach. We also show that our approach trained on a synthetic dataset generalises well to real-world outdoor scenes without additional fine-tuning. Finally, we demonstrate how motion planning tasks can benefit from these denser reconstructions.",
        "published":1658781270000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.12520v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Jul 25, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1036931096,
        "popularmechanics":0.1923638383,
        "scienmag":0.1374047236,
        "technologyreview":0.244337259,
        "vox":0.1297697678,
        "newscientist":0.1686474301,
        "vice":0.1953429413,
        "statnews":0.1232806142,
        "nytimes":0.1509286102,
        "techcrunch":0.1835777678,
        "quartz":0.1154030133,
        "venturebeat":0.2173762596,
        "futurism":0.2148825216,
        "scientificamerican":0.1302671932,
        "wired":0.203955461,
        "popsci":0.2245120966,
        "arstechnica":0.1480413728,
        "salon":0.1183806721,
        "washingtonpost":0.1638229177,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.06304v1",
        "predicted_newsworthiness":40.9948482587,
        "title":"Overparameterization Improves StyleGAN Inversion",
        "summary":"Deep generative models like StyleGAN hold the promise of semantic image editing: modifying images by their content, rather than their pixel values. Unfortunately, working with arbitrary images requires inverting the StyleGAN generator, which has remained challenging so far. Existing inversion approaches obtain promising yet imperfect results, having to trade-off between reconstruction quality and downstream editability. To improve quality, these approaches must resort to various techniques that extend the model latent space after training. Taking a step back, we observe that these methods essentially all propose, in one way or another, to increase the number of free parameters. This suggests that inversion might be difficult because it is underconstrained. In this work, we address this directly and dramatically overparameterize the latent space, before training, with simple changes to the original StyleGAN architecture. Our overparameterization increases the available degrees of freedom, which in turn facilitates inversion. We show that this allows us to obtain near-perfect image reconstruction without the need for encoders nor for altering the latent space after training. Our approach also retains editability, which we demonstrate by realistically interpolating between images.",
        "published":1652380963000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.06304v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 12, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0830211785,
        "popularmechanics":0.1140259829,
        "scienmag":0.0984141044,
        "technologyreview":0.1976367157,
        "vox":0.1000921698,
        "newscientist":0.1110129739,
        "vice":0.1053909197,
        "statnews":0.1114264409,
        "nytimes":0.1180930765,
        "techcrunch":0.1122882267,
        "quartz":0.1117424726,
        "venturebeat":0.165805461,
        "futurism":0.1338657752,
        "scientificamerican":0.0916592099,
        "wired":0.1454150154,
        "popsci":0.1301151899,
        "arstechnica":0.091658218,
        "salon":0.0881061543,
        "washingtonpost":0.1097584696,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2208.01844v1",
        "predicted_newsworthiness":55.5925727112,
        "title":"Multiclass ASMA vs Targeted PGD Attack in Image Segmentation",
        "summary":"Deep learning networks have demonstrated high performance in a large variety of applications, such as image classification, speech recognition, and natural language processing. However, there exists a major vulnerability exploited by the use of adversarial attacks. An adversarial attack imputes images by altering the input image very slightly, making it nearly undetectable to the naked eye, but results in a very different classification by the network. This paper explores the projected gradient descent (PGD) attack and the Adaptive Mask Segmentation Attack (ASMA) on the image segmentation DeepLabV3 model using two types of architectures: MobileNetV3 and ResNet50, It was found that PGD was very consistent in changing the segmentation to be its target while the generalization of ASMA to a multiclass target was not as effective. The existence of such attack however puts all of image classification deep learning networks in danger of exploitation.",
        "published":1659503130000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2208.01844v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Aug 03, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1098043665,
        "popularmechanics":0.1831918887,
        "scienmag":0.1404120255,
        "technologyreview":0.2773074599,
        "vox":0.140144001,
        "newscientist":0.1498093868,
        "vice":0.1135709929,
        "statnews":0.1650791985,
        "nytimes":0.1474533324,
        "techcrunch":0.1670874273,
        "quartz":0.1287889152,
        "venturebeat":0.2344209816,
        "futurism":0.1960629279,
        "scientificamerican":0.122242819,
        "wired":0.1788754198,
        "popsci":0.1993660686,
        "arstechnica":0.1646796758,
        "salon":0.0980228263,
        "washingtonpost":0.1738315294,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.04411v1",
        "predicted_newsworthiness":60.517641336,
        "title":"A.I. and Data-Driven Mobility at Volkswagen Financial Services AG",
        "summary":"Machine learning is being widely adapted in industrial applications owing to the capabilities of commercially available hardware and rapidly advancing research. Volkswagen Financial Services (VWFS), as a market leader in vehicle leasing services, aims to leverage existing proprietary data and the latest research to enhance existing and derive new business processes. The collaboration between Information Systems and Machine Learning Lab (ISMLL) and VWFS serves to realize this goal. In this paper, we propose methods in the fields of recommender systems, object detection, and forecasting that enable data-driven decisions for the vehicle life-cycle at VWFS.",
        "published":1644407138000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.04411v1",
        "arxiv_primary_category":"cs.ai",
        "published_hr":"Feb 09, 2022",
        "arxiv_primary_category_hr":"Artificial Intelligence",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.151891988,
        "popularmechanics":0.2466022831,
        "scienmag":0.2021438335,
        "technologyreview":0.3685540691,
        "vox":0.2642496822,
        "newscientist":0.1963601486,
        "vice":0.1302434156,
        "statnews":0.2786752802,
        "nytimes":0.2426225003,
        "techcrunch":0.3617386571,
        "quartz":0.2404504739,
        "venturebeat":0.4005405621,
        "futurism":0.3145991046,
        "scientificamerican":0.1767695573,
        "wired":0.3149815622,
        "popsci":0.3341729658,
        "arstechnica":0.1892805407,
        "salon":0.1397526891,
        "washingtonpost":0.2511344425,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.03755v1",
        "predicted_newsworthiness":52.2212095812,
        "title":"DxFormer: A Decoupled Automatic Diagnostic System Based on Decoder-Encoder Transformer with Dense Symptom Representations",
        "summary":"Diagnosis-oriented dialogue system queries the patient's health condition and makes predictions about possible diseases through continuous interaction with the patient. A few studies use reinforcement learning (RL) to learn the optimal policy from the joint action space of symptoms and diseases. However, existing RL (or Non-RL) methods cannot achieve sufficiently good prediction accuracy, still far from its upper limit. To address the problem, we propose a decoupled automatic diagnostic framework DxFormer, which divides the diagnosis process into two steps: symptom inquiry and disease diagnosis, where the transition from symptom inquiry to disease diagnosis is explicitly determined by the stopping criteria. In DxFormer, we treat each symptom as a token, and formalize the symptom inquiry and disease diagnosis to a language generation model and a sequence classification model respectively. We use the inverted version of Transformer, i.e., the decoder-encoder structure, to learn the representation of symptoms by jointly optimizing the reinforce reward and cross entropy loss. Extensive experiments on three public real-world datasets prove that our proposed model can effectively learn doctors' clinical experience and achieve the state-of-the-art results in terms of symptom recall and diagnostic accuracy.",
        "published":1651974762000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.03755v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"May 07, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1784497604,
        "popularmechanics":0.1301340313,
        "scienmag":0.2380087733,
        "technologyreview":0.2710324874,
        "vox":0.1848949461,
        "newscientist":0.2010653414,
        "vice":0.1232546277,
        "statnews":0.3814994816,
        "nytimes":0.2014597841,
        "techcrunch":0.182675271,
        "quartz":0.1509326631,
        "venturebeat":0.2580264482,
        "futurism":0.2042208244,
        "scientificamerican":0.2016926342,
        "wired":0.1894228333,
        "popsci":0.187658265,
        "arstechnica":0.1727988484,
        "salon":0.2178375208,
        "washingtonpost":0.1757803154,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.07780v1",
        "predicted_newsworthiness":46.2537732151,
        "title":"Towards Lightweight Transformer via Group-wise Transformation for Vision-and-Language Tasks",
        "summary":"Despite the exciting performance, Transformer is criticized for its excessive parameters and computation cost. However, compressing Transformer remains as an open problem due to its internal complexity of the layer designs, i.e., Multi-Head Attention (MHA) and Feed-Forward Network (FFN). To address this issue, we introduce Group-wise Transformation towards a universal yet lightweight Transformer for vision-and-language tasks, termed as LW-Transformer. LW-Transformer applies Group-wise Transformation to reduce both the parameters and computations of Transformer, while also preserving its two main properties, i.e., the efficient attention modeling on diverse subspaces of MHA, and the expanding-scaling feature transformation of FFN. We apply LW-Transformer to a set of Transformer-based networks, and quantitatively measure them on three vision-and-language tasks and six benchmark datasets. Experimental results show that while saving a large number of parameters and computations, LW-Transformer achieves very competitive performance against the original Transformer networks for vision-and-language tasks. To examine the generalization ability, we also apply our optimization strategy to a recently proposed image Transformer called Swin-Transformer for image classification, where the effectiveness can be also confirmed",
        "published":1650108626000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.07780v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Apr 16, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0919716308,
        "popularmechanics":0.1325973719,
        "scienmag":0.1309851938,
        "technologyreview":0.2579498809,
        "vox":0.1280828287,
        "newscientist":0.1373074317,
        "vice":0.1102758641,
        "statnews":0.1585630446,
        "nytimes":0.1283966191,
        "techcrunch":0.1612158655,
        "quartz":0.1169285847,
        "venturebeat":0.2413333059,
        "futurism":0.173270823,
        "scientificamerican":0.1145876545,
        "wired":0.1669265958,
        "popsci":0.1762827648,
        "arstechnica":0.1144994231,
        "salon":0.0876928727,
        "washingtonpost":0.139687508,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.08903v1",
        "predicted_newsworthiness":62.8635757004,
        "title":"Using Internet Measurements to Map the 2022 Ukrainian Refugee Crisis",
        "summary":"The conflict in Ukraine, starting in February 2022, began the largest refugee crisis in decades, with millions of Ukrainian refugees crossing the border to neighboring countries and millions of others forced to move within the country. In this paper we present an insight into how Internet measurements can be used to analyze the refugee crisis. Based on preliminary data from the first two months of the war we analyze how measurement data indicates the trends in the flow of refugees from Ukraine to its neighboring countries, and onward to other countries. We believe that these insights can greatly contribute to the ongoing international effort to map the flow of refugees in order to aid and protect them.",
        "published":1652878535000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.08903v1",
        "arxiv_primary_category":"cs.ni",
        "published_hr":"May 18, 2022",
        "arxiv_primary_category_hr":"Networking and Internet Architecture",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.3235899999,
        "popularmechanics":0.2159515211,
        "scienmag":0.2498898668,
        "technologyreview":0.3466255558,
        "vox":0.3260837602,
        "newscientist":0.2563627054,
        "vice":0.2337702369,
        "statnews":0.2738036309,
        "nytimes":0.3140167972,
        "techcrunch":0.2922916891,
        "quartz":0.3104581701,
        "venturebeat":0.2832448302,
        "futurism":0.2630074357,
        "scientificamerican":0.2609354783,
        "wired":0.3240074575,
        "popsci":0.2829451329,
        "arstechnica":0.2964672349,
        "salon":0.2975960215,
        "washingtonpost":0.3384559175,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.06825v1",
        "predicted_newsworthiness":52.8999805053,
        "title":"Refign: Align and Refine for Adaptation of Semantic Segmentation to Adverse Conditions",
        "summary":"Due to the scarcity of dense pixel-level semantic annotations for images recorded in adverse visual conditions, there has been a keen interest in unsupervised domain adaptation (UDA) for the semantic segmentation of such images. UDA adapts models trained on normal conditions to the target adverse-condition domains. Meanwhile, multiple datasets with driving scenes provide corresponding images of the same scenes across multiple conditions, which can serve as a form of weak supervision for domain adaptation. We propose Refign, a generic extension to self-training-based UDA methods which leverages these cross-domain correspondences. Refign consists of two steps: (1) aligning the normal-condition image to the corresponding adverse-condition image using an uncertainty-aware dense matching network, and (2) refining the adverse prediction with the normal prediction using an adaptive label correction mechanism. We design custom modules to streamline both steps and set the new state of the art for domain-adaptive semantic segmentation on several adverse-condition benchmarks, including ACDC and Dark Zurich. The approach introduces no extra training parameters, minimal computational overhead -- during training only -- and can be used as a drop-in extension to improve any given self-training-based UDA method. Code is available at https:\/\/github.com\/brdav\/refign.",
        "published":1657798238000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.06825v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 14, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0823364363,
        "popularmechanics":0.1158663775,
        "scienmag":0.1062727913,
        "technologyreview":0.1919619933,
        "vox":0.1002538876,
        "newscientist":0.1099232575,
        "vice":0.0945008321,
        "statnews":0.1168116143,
        "nytimes":0.0932869877,
        "techcrunch":0.122372239,
        "quartz":0.0897543386,
        "venturebeat":0.1748832786,
        "futurism":0.1422212831,
        "scientificamerican":0.0865529286,
        "wired":0.1302474831,
        "popsci":0.1480535455,
        "arstechnica":0.0881844309,
        "salon":0.094995713,
        "washingtonpost":0.1071793663,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.07131v2",
        "predicted_newsworthiness":57.7264954624,
        "title":"Leveraging Real Talking Faces via Self-Supervision for Robust Forgery Detection",
        "summary":"One of the most pressing challenges for the detection of face-manipulated videos is generalising to forgery methods not seen during training while remaining effective under common corruptions such as compression. In this paper, we examine whether we can tackle this issue by harnessing videos of real talking faces, which contain rich information on natural facial appearance and behaviour and are readily available in large quantities online. Our method, termed RealForensics, consists of two stages. First, we exploit the natural correspondence between the visual and auditory modalities in real videos to learn, in a self-supervised cross-modal manner, temporally dense video representations that capture factors such as facial movements, expression, and identity. Second, we use these learned representations as targets to be predicted by our forgery detector along with the usual binary forgery classification task; this encourages it to base its real\/fake decision on said factors. We show that our method achieves state-of-the-art performance on cross-manipulation generalisation and robustness experiments, and examine the factors that contribute to its performance. Our results suggest that leveraging natural and unlabelled videos is a promising direction for the development of more robust face forgery detectors.",
        "published":1642526094000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.07131v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jan 18, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1228518749,
        "popularmechanics":0.14763303,
        "scienmag":0.1088976488,
        "technologyreview":0.2688174134,
        "vox":0.1658401972,
        "newscientist":0.170742435,
        "vice":0.0933930886,
        "statnews":0.1198504732,
        "nytimes":0.1626337328,
        "techcrunch":0.1717643202,
        "quartz":0.1491554667,
        "venturebeat":0.2304144622,
        "futurism":0.1982834112,
        "scientificamerican":0.1410159587,
        "wired":0.1976030453,
        "popsci":0.2024462065,
        "arstechnica":0.1553990305,
        "salon":0.0996122544,
        "washingtonpost":0.2025003243,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.09601v1",
        "predicted_newsworthiness":60.0576854279,
        "title":"Extraction of Sleep Information from Clinical Notes of Alzheimer's Disease Patients Using Natural Language Processing",
        "summary":"Alzheimer's Disease (AD) is the most common form of dementia in the United States. Sleep is one of the lifestyle-related factors that has been shown critical for optimal cognitive function in old age. . However, there is a lack of research studying the association between sleep and AD incidence. A major bottleneck for conducting such research is that the traditional way to acquire sleep information is time-consuming, inefficient, non-scalable, and limited to patients' subjective experience. In this study, we developed a rule-based NLP algorithm and machine learning models to automate the extraction of sleep-related concepts, including snoring, napping, sleep problem, bad sleep quality, daytime sleepiness, night wakings, and sleep duration, from the clinical notes of patients diagnosed with AD. We trained and validated the proposed models on the clinical notes retrieved from the University of Pittsburgh of Medical Center (UPMC). The results show that the rule-based NLP algorithm consistently achieved the best performance for all sleep concepts.",
        "published":1646774419000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.09601v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Mar 08, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1540057941,
        "popularmechanics":0.1108809843,
        "scienmag":0.2526048814,
        "technologyreview":0.2489702803,
        "vox":0.1517999564,
        "newscientist":0.1896725087,
        "vice":0.1001910803,
        "statnews":0.3531145056,
        "nytimes":0.1782792287,
        "techcrunch":0.1739656443,
        "quartz":0.1436531523,
        "venturebeat":0.2411283144,
        "futurism":0.1987372337,
        "scientificamerican":0.1774432095,
        "wired":0.1696127057,
        "popsci":0.1750486701,
        "arstechnica":0.1363743711,
        "salon":0.18928095,
        "washingtonpost":0.15275902,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.14177v3",
        "predicted_newsworthiness":43.5554440433,
        "title":"Benchmarking Deep AUROC Optimization: Loss Functions and Algorithmic Choices",
        "summary":"The area under the ROC curve (AUROC) has been vigorously applied for imbalanced classification and moreover combined with deep learning techniques. However, there is no existing work that provides sound information for peers to choose appropriate deep AUROC maximization techniques. In this work, we fill this gap from three aspects. (i) We benchmark a variety of loss functions with different algorithmic choices for deep AUROC optimization problem. We study the loss functions in two categories: pairwise loss and composite loss, which includes a total of 10 loss functions. Interestingly, we find composite loss, as an innovative loss function class, shows more competitive performance than pairwise loss from both training convergence and testing generalization perspectives. Nevertheless, data with more corrupted labels favors a pairwise symmetric loss. (ii) Moreover, we benchmark and highlight the essential algorithmic choices such as positive sampling rate, regularization, normalization\/activation, and optimizers. Key findings include: higher positive sampling rate is likely to be beneficial for deep AUROC maximization; different datasets favors different weights of regularizations; appropriate normalization techniques, such as sigmoid and $\\ell_2$ score normalization, could improve model performance. (iii) For optimization aspect, we benchmark SGD-type, Momentum-type, and Adam-type optimizers for both pairwise and composite loss. Our findings show that although Adam-type method is more competitive from training perspective, but it does not outperform others from testing perspective.",
        "published":1648342020000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.14177v3",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Mar 26, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1013471901,
        "popularmechanics":0.1281332283,
        "scienmag":0.1428659946,
        "technologyreview":0.2682767073,
        "vox":0.1344704246,
        "newscientist":0.1376586465,
        "vice":0.1015670928,
        "statnews":0.2279187924,
        "nytimes":0.1317828264,
        "techcrunch":0.1766122975,
        "quartz":0.1210122798,
        "venturebeat":0.2527044824,
        "futurism":0.1770494397,
        "scientificamerican":0.1145712321,
        "wired":0.162863716,
        "popsci":0.1703507553,
        "arstechnica":0.1239362009,
        "salon":0.101121957,
        "washingtonpost":0.1445796153,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.01858v1",
        "predicted_newsworthiness":39.4301259203,
        "title":"Towards realistic symmetry-based completion of previously unseen point clouds",
        "summary":"3D scanning is a complex multistage process that generates a point cloud of an object typically containing damaged parts due to occlusions, reflections, shadows, scanner motion, specific properties of the object surface, imperfect reconstruction algorithms, etc. Point cloud completion is specifically designed to fill in the missing parts of the object and obtain its high-quality 3D representation. The existing completion approaches perform well on the academic datasets with a predefined set of object classes and very specific types of defects; however, their performance drops significantly in the real-world settings and degrades even further on previously unseen object classes. We propose a novel framework that performs well on symmetric objects, which are ubiquitous in man-made environments. Unlike learning-based approaches, the proposed framework does not require training data and is capable of completing non-critical damages occurring in customer 3D scanning process using e.g. Kinect, time-of-flight, or structured light scanners. With thorough experiments, we demonstrate that the proposed framework achieves state-of-the-art efficiency in point cloud completion of real-world customer scans. We benchmark the framework performance on two types of datasets: properly augmented existing academic dataset and the actual 3D scans of various objects.",
        "published":1641423913000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.01858v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jan 05, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0879666656,
        "popularmechanics":0.1719526311,
        "scienmag":0.1379033753,
        "technologyreview":0.2219041753,
        "vox":0.1116691466,
        "newscientist":0.1485405806,
        "vice":0.149778025,
        "statnews":0.1391367879,
        "nytimes":0.1328873011,
        "techcrunch":0.164944045,
        "quartz":0.107901573,
        "venturebeat":0.1991666547,
        "futurism":0.182197745,
        "scientificamerican":0.1187108241,
        "wired":0.1683557975,
        "popsci":0.1953242628,
        "arstechnica":0.1257583571,
        "salon":0.0956391457,
        "washingtonpost":0.1495204954,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.07749v1",
        "predicted_newsworthiness":44.7392909214,
        "title":"Bootstrap State Representation using Style Transfer for Better Generalization in Deep Reinforcement Learning",
        "summary":"Deep Reinforcement Learning (RL) agents often overfit the training environment, leading to poor generalization performance. In this paper, we propose Thinker, a bootstrapping method to remove adversarial effects of confounding features from the observation in an unsupervised way, and thus, it improves RL agents' generalization. Thinker first clusters experience trajectories into several clusters. These trajectories are then bootstrapped by applying a style transfer generator, which translates the trajectories from one cluster's style to another while maintaining the content of the observations. The bootstrapped trajectories are then used for policy learning. Thinker has wide applicability among many RL settings. Experimental results reveal that Thinker leads to better generalization capability in the Procgen benchmark environments compared to base algorithms and several data augmentation techniques.",
        "published":1657918185000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.07749v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jul 15, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1184234821,
        "popularmechanics":0.1401009912,
        "scienmag":0.141662906,
        "technologyreview":0.3113858121,
        "vox":0.1465664159,
        "newscientist":0.1608722559,
        "vice":0.1282195673,
        "statnews":0.2119460895,
        "nytimes":0.1586218632,
        "techcrunch":0.1822307995,
        "quartz":0.1385940095,
        "venturebeat":0.2655797855,
        "futurism":0.2091996232,
        "scientificamerican":0.1435712606,
        "wired":0.1895350826,
        "popsci":0.1850296519,
        "arstechnica":0.1299526016,
        "salon":0.1110277355,
        "washingtonpost":0.1506092347,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2208.02068v1",
        "predicted_newsworthiness":29.8450921749,
        "title":"HybridGNN: Learning Hybrid Representation in Multiplex Heterogeneous Networks",
        "summary":"Recently, graph neural networks have shown the superiority of modeling the complex topological structures in heterogeneous network-based recommender systems. Due to the diverse interactions among nodes and abundant semantics emerging from diverse types of nodes and edges, there is a bursting research interest in learning expressive node representations in multiplex heterogeneous networks. One of the most important tasks in recommender systems is to predict the potential connection between two nodes under a specific edge type (i.e., relationship). Although existing studies utilize explicit metapaths to aggregate neighbors, practically they only consider intra-relationship metapaths and thus fail to leverage the potential uplift by inter-relationship information. Moreover, it is not always straightforward to exploit inter-relationship metapaths comprehensively under diverse relationships, especially with the increasing number of node and edge types. In addition, contributions of different relationships between two nodes are difficult to measure. To address the challenges, we propose HybridGNN, an end-to-end GNN model with hybrid aggregation flows and hierarchical attentions to fully utilize the heterogeneity in the multiplex scenarios. Specifically, HybridGNN applies a randomized inter-relationship exploration module to exploit the multiplexity property among different relationships. Then, our model leverages hybrid aggregation flows under intra-relationship metapaths and randomized exploration to learn the rich semantics. To explore the importance of different aggregation flow and take advantage of the multiplexity property, we bring forward a novel hierarchical attention module which leverages both metapath-level attention and relationship-level attention. Extensive experimental results suggest that HybridGNN achieves the best performance compared to several state-of-the-art baselines.",
        "published":1659533987000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2208.02068v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Aug 03, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0892372968,
        "popularmechanics":0.0879738177,
        "scienmag":0.1197095912,
        "technologyreview":0.1859152502,
        "vox":0.1474366922,
        "newscientist":0.1103041615,
        "vice":0.082099382,
        "statnews":0.1642470493,
        "nytimes":0.117651943,
        "techcrunch":0.1430360269,
        "quartz":0.1126064467,
        "venturebeat":0.1918329778,
        "futurism":0.1251989426,
        "scientificamerican":0.1008345118,
        "wired":0.1511510165,
        "popsci":0.1423649114,
        "arstechnica":0.1065487212,
        "salon":0.0889959921,
        "washingtonpost":0.1509100131,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.00433v1",
        "predicted_newsworthiness":45.2322768104,
        "title":"PROTOtypical Logic Tensor Networks (PROTO-LTN) for Zero Shot Learning",
        "summary":"Semantic image interpretation can vastly benefit from approaches that combine sub-symbolic distributed representation learning with the capability to reason at a higher level of abstraction. Logic Tensor Networks (LTNs) are a class of neuro-symbolic systems based on a differentiable, first-order logic grounded into a deep neural network. LTNs replace the classical concept of training set with a knowledge base of fuzzy logical axioms. By defining a set of differentiable operators to approximate the role of connectives, predicates, functions and quantifiers, a loss function is automatically specified so that LTNs can learn to satisfy the knowledge base. We focus here on the subsumption or \\texttt{isOfClass} predicate, which is fundamental to encode most semantic image interpretation tasks. Unlike conventional LTNs, which rely on a separate predicate for each class (e.g., dog, cat), each with its own set of learnable weights, we propose a common \\texttt{isOfClass} predicate, whose level of truth is a function of the distance between an object embedding and the corresponding class prototype. The PROTOtypical Logic Tensor Networks (PROTO-LTN) extend the current formulation by grounding abstract concepts as parametrized class prototypes in a high-dimensional embedding space, while reducing the number of parameters required to ground the knowledge base. We show how this architecture can be effectively trained in the few and zero-shot learning scenarios. Experiments on Generalized Zero Shot Learning benchmarks validate the proposed implementation as a competitive alternative to traditional embedding-based approaches. The proposed formulation opens up new opportunities in zero shot learning settings, as the LTN formalism allows to integrate background knowledge in the form of logical axioms to compensate for the lack of labelled examples.",
        "published":1656268447000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.00433v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jun 26, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0885272269,
        "popularmechanics":0.1355726979,
        "scienmag":0.1210590703,
        "technologyreview":0.2482479039,
        "vox":0.1069027652,
        "newscientist":0.1353760692,
        "vice":0.0974760349,
        "statnews":0.1588706005,
        "nytimes":0.1148460868,
        "techcrunch":0.1370500527,
        "quartz":0.1026724118,
        "venturebeat":0.2188649631,
        "futurism":0.1645835908,
        "scientificamerican":0.1108626356,
        "wired":0.1472917979,
        "popsci":0.1627399742,
        "arstechnica":0.1137481515,
        "salon":0.0744582884,
        "washingtonpost":0.127870372,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.04977v1",
        "predicted_newsworthiness":42.3136430535,
        "title":"Regularization-based Pruning of Irrelevant Weights in Deep Neural Architectures",
        "summary":"Deep neural networks exploiting millions of parameters are nowadays the norm in deep learning applications. This is a potential issue because of the great amount of computational resources needed for training, and of the possible loss of generalization performance of overparametrized networks. We propose in this paper a method for learning sparse neural topologies via a regularization technique which identifies non relevant weights and selectively shrinks their norm, while performing a classic update for relevant ones. This technique, which is an improvement of classical weight decay, is based on the definition of a regularization term which can be added to any loss functional regardless of its form, resulting in a unified general framework exploitable in many different contexts. The actual elimination of parameters identified as irrelevant is handled by an iterative pruning algorithm. We tested the proposed technique on different image classification and Natural language generation tasks, obtaining results on par or better then competitors in terms of sparsity and metrics, while achieving strong models compression.",
        "published":1649670256000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.04977v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Apr 11, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0793544919,
        "popularmechanics":0.1081253749,
        "scienmag":0.1109383331,
        "technologyreview":0.2245028946,
        "vox":0.1034023494,
        "newscientist":0.1164876557,
        "vice":0.0851270558,
        "statnews":0.157027161,
        "nytimes":0.1071553069,
        "techcrunch":0.1169477729,
        "quartz":0.0946614581,
        "venturebeat":0.1995613374,
        "futurism":0.1416465695,
        "scientificamerican":0.0999649297,
        "wired":0.1375910451,
        "popsci":0.1356773049,
        "arstechnica":0.0945226308,
        "salon":0.0717679216,
        "washingtonpost":0.1180584984,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.01095v1",
        "predicted_newsworthiness":47.3452890696,
        "title":"A Generalized Approach for Cancellable Template and Its Realization for Minutia Cylinder-Code",
        "summary":"Hashing technology gains much attention in protecting the biometric template lately. For instance, Index-of-Max (IoM), a recent reported hashing technique, is a ranking-based locality sensitive hashing technique, which illustrates the feasibility to protect the ordered and fixed-length biometric template. However, biometric templates are not always in the form of ordered and fixed-length, rather it may be an unordered and variable size point set e.g. fingerprint minutiae, which restricts the usage of the traditional hashing technology. In this paper, we proposed a generalized version of IoM hashing namely gIoM, and therefore the unordered and variable size biometric template can be used. We demonstrate a realization using a well-known variable size feature vector, fingerprint Minutia Cylinder-Code (MCC). The gIoM transforms MCC into index domain to form indexing-based feature representation. Consequently, the inversion of MCC from the transformed representation is computational infeasible, thus to achieve non-invertibility while the performance is preserved. Public fingerprint databases FVC2002 and FVC2004 are employed for experiment as benchmark to demonstrate a fair comparison with other methods. Moreover, the security and privacy analysis suggest that gIoM meets the criteria of template protection: non-invertibility, revocability, and non-linkability.",
        "published":1646227846000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.01095v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Mar 02, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0938302224,
        "popularmechanics":0.1339553302,
        "scienmag":0.1251024688,
        "technologyreview":0.1682080418,
        "vox":0.0907089771,
        "newscientist":0.1288558404,
        "vice":0.1003001549,
        "statnews":0.1093293281,
        "nytimes":0.1284840028,
        "techcrunch":0.1275288787,
        "quartz":0.106519872,
        "venturebeat":0.1483001542,
        "futurism":0.1384528869,
        "scientificamerican":0.1015511836,
        "wired":0.1302811837,
        "popsci":0.1528705334,
        "arstechnica":0.123337667,
        "salon":0.0801307274,
        "washingtonpost":0.1363295151,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.04921v1",
        "predicted_newsworthiness":50.578854423,
        "title":"The Severity Prediction of The Binary And Multi-Class Cardiovascular Disease -- A Machine Learning-Based Fusion Approach",
        "summary":"In today's world, a massive amount of data is available in almost every sector. This data has become an asset as we can use this enormous amount of data to find information. Mainly health care industry contains many data consisting of patient and disease-related information. By using the machine learning technique, we can look for hidden data patterns to predict various diseases. Recently CVDs, or cardiovascular disease, have become a leading cause of death around the world. The number of death due to CVDs is frightening. That is why many researchers are trying their best to design a predictive model that can save many lives using the data mining model. In this research, some fusion models have been constructed to diagnose CVDs along with its severity. Machine learning(ML) algorithms like artificial neural network, SVM, logistic regression, decision tree, random forest, and AdaBoost have been applied to the heart disease dataset to predict disease. Randomoversampler was implemented because of the class imbalance in multiclass classification. To improve the performance of classification, a weighted score fusion approach was taken. At first, the models were trained. After training, two algorithms' decision was combined using a weighted sum rule. A total of three fusion models have been developed from the six ML algorithms. The results were promising in the performance parameter. The proposed approach has been experimented with different test training ratios for binary and multiclass classification problems, and for both of them, the fusion models performed well. The highest accuracy for multiclass classification was found as 75%, and it was 95% for binary. The code can be found in : https:\/\/github.com\/hafsa-kibria\/Weighted_score_fusion_model_heart_disease_prediction",
        "published":1646849184000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.04921v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Mar 09, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1331101709,
        "popularmechanics":0.1192558543,
        "scienmag":0.2442420302,
        "technologyreview":0.2213701912,
        "vox":0.1335859544,
        "newscientist":0.168687594,
        "vice":0.097912779,
        "statnews":0.3374816558,
        "nytimes":0.1569050267,
        "techcrunch":0.1551151573,
        "quartz":0.1281232602,
        "venturebeat":0.2173424479,
        "futurism":0.16799877,
        "scientificamerican":0.1448850458,
        "wired":0.1210979454,
        "popsci":0.1477718022,
        "arstechnica":0.1314530578,
        "salon":0.1550384632,
        "washingtonpost":0.1424197647,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.09446v1",
        "predicted_newsworthiness":41.9843939434,
        "title":"ShapeCrafter: A Recursive Text-Conditioned 3D Shape Generation Model",
        "summary":"We present ShapeCrafter, a neural network for recursive text-conditioned 3D shape generation. Existing methods to generate text-conditioned 3D shapes consume an entire text prompt to generate a 3D shape in a single step. However, humans tend to describe shapes recursively-we may start with an initial description and progressively add details based on intermediate results. To capture this recursive process, we introduce a method to generate a 3D shape distribution, conditioned on an initial phrase, that gradually evolves as more phrases are added. Since existing datasets are insufficient for training this approach, we present Text2Shape++, a large dataset of 369K shape-text pairs that supports recursive shape generation. To capture local details that are often used to refine shape descriptions, we build on top of vector-quantized deep implicit functions that generate a distribution of high-quality shapes. Results show that our method can generate shapes consistent with text descriptions, and shapes evolve gradually as more phrases are added. Our method supports shape editing, extrapolation, and can enable new applications in human-machine collaboration for creative design.",
        "published":1658253541000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.09446v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 19, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1293771942,
        "popularmechanics":0.1784263789,
        "scienmag":0.1634003743,
        "technologyreview":0.2700066619,
        "vox":0.1457103253,
        "newscientist":0.1946410176,
        "vice":0.1452566379,
        "statnews":0.1965068589,
        "nytimes":0.1850037684,
        "techcrunch":0.1968685374,
        "quartz":0.1534778208,
        "venturebeat":0.2555189951,
        "futurism":0.2120033142,
        "scientificamerican":0.159378208,
        "wired":0.2355968168,
        "popsci":0.2178066579,
        "arstechnica":0.1224793958,
        "salon":0.1211525609,
        "washingtonpost":0.1639221447,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.07023v1",
        "predicted_newsworthiness":56.323307945,
        "title":"Exhaustivity and anti-exhaustivity in the RSA framework: Testing the effect of prior beliefs",
        "summary":"During communication, the interpretation of utterances is sensitive to a listener's probabilistic prior beliefs, something which is captured by one currently influential model of pragmatics, the Rational Speech Act (RSA) framework. In this paper we focus on cases when this sensitivity to priors leads to counterintuitive predictions of the framework. Our domain of interest is exhaustivity effects, whereby a sentence such as \"Mary came\" is understood to mean that only Mary came. We show that in the baseline RSA model, under certain conditions, anti-exhaustive readings are predicted (e.g., \"Mary came\" would be used to convey that both Mary and Peter came). The specific question we ask is the following: should exhaustive interpretations be derived as purely pragmatic inferences (as in the classical Gricean view, endorsed in the baseline RSA model), or should they rather be generated by an encapsulated semantic mechanism (as argued in some of the recent formal literature)? To answer this question, we provide a detailed theoretical analysis of different RSA models and evaluate them against data obtained in a new study which tested the effects of prior beliefs on both production and comprehension, improving on previous empirical work. We found no anti-exhaustivity effects, but observed that message choice is sensitive to priors, as predicted by the RSA framework overall. The best models turn out to be those which include an encapsulated exhaustivity mechanism (as other studies concluded on the basis of very different data). We conclude that, on the one hand, in the division of labor between semantics and pragmatics, semantics plays a larger role than is often thought, but, on the other hand, the tradeoff between informativity and cost which characterizes all RSA models does play a central role for genuine pragmatic effects.",
        "published":1644870903000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.07023v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Feb 14, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1891133855,
        "popularmechanics":0.124539117,
        "scienmag":0.1375163415,
        "technologyreview":0.2155378175,
        "vox":0.1746504221,
        "newscientist":0.1842727199,
        "vice":0.131429842,
        "statnews":0.1440203572,
        "nytimes":0.179555966,
        "techcrunch":0.1538028344,
        "quartz":0.1648004183,
        "venturebeat":0.1922835082,
        "futurism":0.1598496921,
        "scientificamerican":0.2042500229,
        "wired":0.1947508227,
        "popsci":0.1570974094,
        "arstechnica":0.1545142991,
        "salon":0.1518142178,
        "washingtonpost":0.1581510798,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.03271v1",
        "predicted_newsworthiness":47.961871536,
        "title":"On the Effectiveness of Fine-tuning Versus Meta-reinforcement Learning",
        "summary":"Intelligent agents should have the ability to leverage knowledge from previously learned tasks in order to learn new ones quickly and efficiently. Meta-learning approaches have emerged as a popular solution to achieve this. However, meta-reinforcement learning (meta-RL) algorithms have thus far been restricted to simple environments with narrow task distributions. Moreover, the paradigm of pretraining followed by fine-tuning to adapt to new tasks has emerged as a simple yet effective solution in supervised and self-supervised learning. This calls into question the benefits of meta-learning approaches also in reinforcement learning, which typically come at the cost of high complexity. We hence investigate meta-RL approaches in a variety of vision-based benchmarks, including Procgen, RLBench, and Atari, where evaluations are made on completely novel tasks. Our findings show that when meta-learning approaches are evaluated on different tasks (rather than different variations of the same task), multi-task pretraining with fine-tuning on new tasks performs equally as well, or better, than meta-pretraining with meta test-time adaptation. This is encouraging for future research, as multi-task pretraining tends to be simpler and computationally cheaper than meta-RL. From these findings, we advocate for evaluating future meta-RL methods on more challenging tasks and including multi-task pretraining with fine-tuning as a simple, yet strong baseline.",
        "published":1654608240000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.03271v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jun 07, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0980417054,
        "popularmechanics":0.1563822813,
        "scienmag":0.156303262,
        "technologyreview":0.3042328672,
        "vox":0.1178868058,
        "newscientist":0.1789362876,
        "vice":0.1180540305,
        "statnews":0.2141294748,
        "nytimes":0.14419275,
        "techcrunch":0.1798399738,
        "quartz":0.1151075187,
        "venturebeat":0.261797145,
        "futurism":0.2205544378,
        "scientificamerican":0.1693294798,
        "wired":0.1968955415,
        "popsci":0.2154306694,
        "arstechnica":0.1170452995,
        "salon":0.1014213786,
        "washingtonpost":0.1509661604,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.08525v1",
        "predicted_newsworthiness":38.4829622846,
        "title":"Self-supervised Neural Articulated Shape and Appearance Models",
        "summary":"Learning geometry, motion, and appearance priors of object classes is important for the solution of a large variety of computer vision problems. While the majority of approaches has focused on static objects, dynamic objects, especially with controllable articulation, are less explored. We propose a novel approach for learning a representation of the geometry, appearance, and motion of a class of articulated objects given only a set of color images as input. In a self-supervised manner, our novel representation learns shape, appearance, and articulation codes that enable independent control of these semantic dimensions. Our model is trained end-to-end without requiring any articulation annotations. Experiments show that our approach performs well for different joint types, such as revolute and prismatic joints, as well as different combinations of these joints. Compared to state of the art that uses direct 3D supervision and does not output appearance, we recover more faithful geometry and appearance from 2D observations only. In addition, our representation enables a large variety of applications, such as few-shot reconstruction, the generation of novel articulations, and novel view-synthesis.",
        "published":1652809847000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.08525v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 17, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0853882294,
        "popularmechanics":0.1525571781,
        "scienmag":0.1141343728,
        "technologyreview":0.2211412288,
        "vox":0.0927861973,
        "newscientist":0.1486700847,
        "vice":0.1001802851,
        "statnews":0.1076939541,
        "nytimes":0.1249591025,
        "techcrunch":0.1501603903,
        "quartz":0.1011174447,
        "venturebeat":0.2024141769,
        "futurism":0.1792943182,
        "scientificamerican":0.11157851,
        "wired":0.1733484318,
        "popsci":0.1801813246,
        "arstechnica":0.0851442647,
        "salon":0.0676700717,
        "washingtonpost":0.127680189,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.03569v3",
        "predicted_newsworthiness":41.9165626761,
        "title":"Representation Learning for Compressed Video Action Recognition via Attentive Cross-modal Interaction with Motion Enhancement",
        "summary":"Compressed video action recognition has recently drawn growing attention, since it remarkably reduces the storage and computational cost via replacing raw videos by sparsely sampled RGB frames and compressed motion cues (e.g., motion vectors and residuals). However, this task severely suffers from the coarse and noisy dynamics and the insufficient fusion of the heterogeneous RGB and motion modalities. To address the two issues above, this paper proposes a novel framework, namely Attentive Cross-modal Interaction Network with Motion Enhancement (MEACI-Net). It follows the two-stream architecture, i.e. one for the RGB modality and the other for the motion modality. Particularly, the motion stream employs a multi-scale block embedded with a denoising module to enhance representation learning. The interaction between the two streams is then strengthened by introducing the Selective Motion Complement (SMC) and Cross-Modality Augment (CMA) modules, where SMC complements the RGB modality with spatio-temporally attentive local motion features and CMA further combines the two modalities with selective feature augmentation. Extensive experiments on the UCF-101, HMDB-51 and Kinetics-400 benchmarks demonstrate the effectiveness and efficiency of MEACI-Net.",
        "published":1651904809000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.03569v3",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"May 07, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0811466221,
        "popularmechanics":0.1069913047,
        "scienmag":0.1004837836,
        "technologyreview":0.1503398086,
        "vox":0.0807882922,
        "newscientist":0.1003789163,
        "vice":0.0824576572,
        "statnews":0.0668948096,
        "nytimes":0.0936507263,
        "techcrunch":0.1068448537,
        "quartz":0.090244268,
        "venturebeat":0.1412185759,
        "futurism":0.1110233575,
        "scientificamerican":0.0773740991,
        "wired":0.117258911,
        "popsci":0.1223475327,
        "arstechnica":0.0894415062,
        "salon":0.0686936153,
        "washingtonpost":0.1048048079,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.02877v1",
        "predicted_newsworthiness":63.0935844432,
        "title":"MIRROR: Differentiable Deep Social Projection for Assistive Human-Robot Communication",
        "summary":"Communication is a hallmark of intelligence. In this work, we present MIRROR, an approach to (i) quickly learn human models from human demonstrations, and (ii) use the models for subsequent communication planning in assistive shared-control settings. MIRROR is inspired by social projection theory, which hypothesizes that humans use self-models to understand others. Likewise, MIRROR leverages self-models learned using reinforcement learning to bootstrap human modeling. Experiments with simulated humans show that this approach leads to rapid learning and more robust models compared to existing behavioral cloning and state-of-the-art imitation learning methods. We also present a human-subject study using the CARLA simulator which shows that (i) MIRROR is able to scale to complex domains with high-dimensional observations and complicated world physics and (ii) provides effective assistive communication that enabled participants to drive more safely in adverse weather conditions.",
        "published":1646542860000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.02877v1",
        "arxiv_primary_category":"cs.ai",
        "published_hr":"Mar 05, 2022",
        "arxiv_primary_category_hr":"Artificial Intelligence",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.138029422,
        "popularmechanics":0.2123277172,
        "scienmag":0.1892003753,
        "technologyreview":0.3379165582,
        "vox":0.1738997219,
        "newscientist":0.221957874,
        "vice":0.1675590787,
        "statnews":0.2269401886,
        "nytimes":0.2004862181,
        "techcrunch":0.2372358077,
        "quartz":0.1536704381,
        "venturebeat":0.2968476358,
        "futurism":0.2892935356,
        "scientificamerican":0.1898872575,
        "wired":0.2645069946,
        "popsci":0.2862905934,
        "arstechnica":0.1525778455,
        "salon":0.1413350262,
        "washingtonpost":0.2173490921,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.04810v1",
        "predicted_newsworthiness":53.2063776582,
        "title":"The Importance of Context in Very Low Resource Language Modeling",
        "summary":"This paper investigates very low resource language model pretraining, when less than 100 thousand sentences are available. We find that, in very low resource scenarios, statistical n-gram language models outperform state-of-the-art neural models. Our experiments show that this is mainly due to the focus of the former on a local context. As such, we introduce three methods to improve a neural model's performance in the low-resource setting, finding that limiting the model's self-attention is the most effective one, improving on downstream tasks such as NLI and POS tagging by up to 5% for the languages we test on: English, Hindi, and Turkish.",
        "published":1652181596000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.04810v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"May 10, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0991171994,
        "popularmechanics":0.1059659517,
        "scienmag":0.0919040851,
        "technologyreview":0.2170154913,
        "vox":0.1313608029,
        "newscientist":0.1150414337,
        "vice":0.0752550484,
        "statnews":0.1404842314,
        "nytimes":0.1233298575,
        "techcrunch":0.1492208284,
        "quartz":0.1280353084,
        "venturebeat":0.2182552682,
        "futurism":0.1344726822,
        "scientificamerican":0.1031369861,
        "wired":0.162059238,
        "popsci":0.1552672903,
        "arstechnica":0.1068847039,
        "salon":0.0837436395,
        "washingtonpost":0.1335107834,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.11159v2",
        "predicted_newsworthiness":56.1545698434,
        "title":"Explainable Fairness in Recommendation",
        "summary":"Existing research on fairness-aware recommendation has mainly focused on the quantification of fairness and the development of fair recommendation models, neither of which studies a more substantial problem--identifying the underlying reason of model disparity in recommendation. This information is critical for recommender system designers to understand the intrinsic recommendation mechanism and provides insights on how to improve model fairness to decision makers. Fortunately, with the rapid development of Explainable AI, we can use model explainability to gain insights into model (un)fairness. In this paper, we study the problem of explainable fairness, which helps to gain insights about why a system is fair or unfair, and guides the design of fair recommender systems with a more informed and unified methodology. Particularly, we focus on a common setting with feature-aware recommendation and exposure unfairness, but the proposed explainable fairness framework is general and can be applied to other recommendation settings and fairness definitions. We propose a Counterfactual Explainable Fairness framework, called CEF, which generates explanations about model fairness that can improve the fairness without significantly hurting the performance.The CEF framework formulates an optimization problem to learn the \"minimal\" change of the input features that changes the recommendation results to a certain level of fairness. Based on the counterfactual recommendation result of each feature, we calculate an explainability score in terms of the fairness-utility trade-off to rank all the feature-based explanations, and select the top ones as fairness explanations.",
        "published":1650762729000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.11159v2",
        "arxiv_primary_category":"cs.ir",
        "published_hr":"Apr 23, 2022",
        "arxiv_primary_category_hr":"Information Retrieval",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1596990653,
        "popularmechanics":0.1175784486,
        "scienmag":0.156778381,
        "technologyreview":0.2773630066,
        "vox":0.206528718,
        "newscientist":0.1623890267,
        "vice":0.1183320467,
        "statnews":0.2390906487,
        "nytimes":0.1817267145,
        "techcrunch":0.21325137,
        "quartz":0.1828956144,
        "venturebeat":0.2648401451,
        "futurism":0.1907641246,
        "scientificamerican":0.1582665033,
        "wired":0.2107243074,
        "popsci":0.1908332392,
        "arstechnica":0.1693994929,
        "salon":0.1381652566,
        "washingtonpost":0.196725047,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.14074v1",
        "predicted_newsworthiness":39.9345293316,
        "title":"PEA: Improving the Performance of ReLU Networks for Free by Using Progressive Ensemble Activations",
        "summary":"In recent years novel activation functions have been proposed to improve the performance of neural networks, and they show superior performance compared to the ReLU counterpart. However, there are environments, where the availability of complex activations is limited, and usually only the ReLU is supported. In this paper we propose methods that can be used to improve the performance of ReLU networks by using these efficient novel activations during model training. More specifically, we propose ensemble activations that are composed of the ReLU and one of these novel activations. Furthermore, the coefficients of the ensemble are neither fixed nor learned, but are progressively updated during the training process in a way that by the end of the training only the ReLU activations remain active in the network and the other activations can be removed. This means that in inference time the network contains ReLU activations only. We perform extensive evaluations on the ImageNet classification task using various compact network architectures and various novel activation functions. Results show 0.2-0.8% top-1 accuracy gain, which confirms the applicability of the proposed methods. Furthermore, we demonstrate the proposed methods on semantic segmentation and we boost the performance of a compact segmentation network by 0.34% mIOU on the Cityscapes dataset.",
        "published":1659014947000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.14074v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 28, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.086693328,
        "popularmechanics":0.1266369266,
        "scienmag":0.1189580673,
        "technologyreview":0.2288048104,
        "vox":0.1028235897,
        "newscientist":0.1208509896,
        "vice":0.0868160005,
        "statnews":0.1369130877,
        "nytimes":0.1080575385,
        "techcrunch":0.1504726754,
        "quartz":0.1011336194,
        "venturebeat":0.2203861522,
        "futurism":0.1487729391,
        "scientificamerican":0.0963224547,
        "wired":0.1363571329,
        "popsci":0.1557074986,
        "arstechnica":0.0985804538,
        "salon":0.0771380378,
        "washingtonpost":0.1270179612,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.15349v2",
        "predicted_newsworthiness":46.0939517536,
        "title":"LDKP: A Dataset for Identifying Keyphrases from Long Scientific Documents",
        "summary":"Identifying keyphrases (KPs) from text documents is a fundamental task in natural language processing and information retrieval. Vast majority of the benchmark datasets for this task are from the scientific domain containing only the document title and abstract information. This limits keyphrase extraction (KPE) and keyphrase generation (KPG) algorithms to identify keyphrases from human-written summaries that are often very short (approx 8 sentences). This presents three challenges for real-world applications: human-written summaries are unavailable for most documents, the documents are almost always long, and a high percentage of KPs are directly found beyond the limited context of title and abstract. Therefore, we release two extensive corpora mapping KPs of ~1.3M and ~100K scientific articles with their fully extracted text and additional metadata including publication venue, year, author, field of study, and citations for facilitating research on this real-world problem.",
        "published":1648543497000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.15349v2",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Mar 29, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1594813867,
        "popularmechanics":0.1444797432,
        "scienmag":0.210105253,
        "technologyreview":0.2223575468,
        "vox":0.1847228518,
        "newscientist":0.1836099428,
        "vice":0.1824590071,
        "statnews":0.2591685722,
        "nytimes":0.2031132183,
        "techcrunch":0.1742172398,
        "quartz":0.152270825,
        "venturebeat":0.2083262523,
        "futurism":0.1819324847,
        "scientificamerican":0.2301844016,
        "wired":0.20036846,
        "popsci":0.1860822975,
        "arstechnica":0.1747131945,
        "salon":0.204334174,
        "washingtonpost":0.1763165308,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.03730v2",
        "predicted_newsworthiness":34.8035418174,
        "title":"Provably Accurate and Scalable Linear Classifiers in Hyperbolic Spaces",
        "summary":"Many high-dimensional practical data sets have hierarchical structures induced by graphs or time series. Such data sets are hard to process in Euclidean spaces and one often seeks low-dimensional embeddings in other space forms to perform the required learning tasks. For hierarchical data, the space of choice is a hyperbolic space because it guarantees low-distortion embeddings for tree-like structures. The geometry of hyperbolic spaces has properties not encountered in Euclidean spaces that pose challenges when trying to rigorously analyze algorithmic solutions. We propose a unified framework for learning scalable and simple hyperbolic linear classifiers with provable performance guarantees. The gist of our approach is to focus on Poincar\\'e ball models and formulate the classification problems using tangent space formalisms. Our results include a new hyperbolic perceptron algorithm as well as an efficient and highly accurate convex optimization setup for hyperbolic support vector machine classifiers. Furthermore, we adapt our approach to accommodate second-order perceptrons, where data is preprocessed based on second-order information (correlation) to accelerate convergence, and strategic perceptrons, where potentially manipulated data arrives in an online manner and decisions are made sequentially. The excellent performance of the Poincar\\'e second-order and strategic perceptrons shows that the proposed framework can be extended to general machine learning problems in hyperbolic spaces. Our experimental results, pertaining to synthetic, single-cell RNA-seq expression measurements, CIFAR10, Fashion-MNIST and mini-ImageNet, establish that all algorithms provably converge and have complexity comparable to those of their Euclidean counterparts. Accompanying codes can be found at: https:\/\/github.com\/thupchnsky\/PoincareLinearClassification.",
        "published":1646688981000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.03730v2",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Mar 07, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0944239698,
        "popularmechanics":0.1300129101,
        "scienmag":0.1707677828,
        "technologyreview":0.2286467685,
        "vox":0.1083143811,
        "newscientist":0.1506639253,
        "vice":0.1278305287,
        "statnews":0.2204954066,
        "nytimes":0.1330937957,
        "techcrunch":0.1416226075,
        "quartz":0.0998791367,
        "venturebeat":0.2040567676,
        "futurism":0.1687474422,
        "scientificamerican":0.1327080953,
        "wired":0.1630007648,
        "popsci":0.1578812718,
        "arstechnica":0.1174465118,
        "salon":0.0879617825,
        "washingtonpost":0.1308897818,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.13820v1",
        "predicted_newsworthiness":41.54280744,
        "title":"Cross-Attention of Disentangled Modalities for 3D Human Mesh Recovery with Transformers",
        "summary":"Transformer encoder architectures have recently achieved state-of-the-art results on monocular 3D human mesh reconstruction, but they require a substantial number of parameters and expensive computations. Due to the large memory overhead and slow inference speed, it is difficult to deploy such models for practical use. In this paper, we propose a novel transformer encoder-decoder architecture for 3D human mesh reconstruction from a single image, called FastMETRO. We identify the performance bottleneck in the encoder-based transformers is caused by the token design which introduces high complexity interactions among input tokens. We disentangle the interactions via an encoder-decoder architecture, which allows our model to demand much fewer parameters and shorter inference time. In addition, we impose the prior knowledge of human body's morphological relationship via attention masking and mesh upsampling operations, which leads to faster convergence with higher accuracy. Our FastMETRO improves the Pareto-front of accuracy and efficiency, and clearly outperforms image-based methods on Human3.6M and 3DPW. Furthermore, we validate its generalizability on FreiHAND.",
        "published":1658962449000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.13820v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 27, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0769613738,
        "popularmechanics":0.136912396,
        "scienmag":0.1349290928,
        "technologyreview":0.1930702815,
        "vox":0.088611333,
        "newscientist":0.1369103246,
        "vice":0.1188047874,
        "statnews":0.1321053385,
        "nytimes":0.1178668104,
        "techcrunch":0.121282355,
        "quartz":0.0908168612,
        "venturebeat":0.1745214111,
        "futurism":0.1635348106,
        "scientificamerican":0.107346576,
        "wired":0.1422759586,
        "popsci":0.1552356566,
        "arstechnica":0.0960446854,
        "salon":0.0935844163,
        "washingtonpost":0.1159676158,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2205.06119v1",
        "predicted_newsworthiness":62.4255289688,
        "title":"Zero-shot Code-Mixed Offensive Span Identification through Rationale Extraction",
        "summary":"This paper investigates the effectiveness of sentence-level transformers for zero-shot offensive span identification on a code-mixed Tamil dataset. More specifically, we evaluate rationale extraction methods of Local Interpretable Model Agnostic Explanations (LIME) \\cite{DBLP:conf\/kdd\/Ribeiro0G16} and Integrated Gradients (IG) \\cite{DBLP:conf\/icml\/SundararajanTY17} for adapting transformer based offensive language classification models for zero-shot offensive span identification. To this end, we find that LIME and IG show baseline $F_{1}$ of 26.35\\% and 44.83\\%, respectively. Besides, we study the effect of data set size and training process on the overall accuracy of span identification. As a result, we find both LIME and IG to show significant improvement with Masked Data Augmentation and Multilabel Training, with $F_{1}$ of 50.23\\% and 47.38\\% respectively. \\textit{Disclaimer : This paper contains examples that may be considered profane, vulgar, or offensive. The examples do not represent the views of the authors or their employers\/graduate schools towards any person(s), group(s), practice(s), or entity\/entities. Instead they are used to emphasize only the linguistic research challenges.}",
        "published":1652365932000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2205.06119v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"May 12, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1888507738,
        "popularmechanics":0.1342599449,
        "scienmag":0.1328203764,
        "technologyreview":0.2546587199,
        "vox":0.1930782886,
        "newscientist":0.1532325559,
        "vice":0.1119422,
        "statnews":0.1811186173,
        "nytimes":0.1840309484,
        "techcrunch":0.1853288568,
        "quartz":0.206413353,
        "venturebeat":0.2337230103,
        "futurism":0.1814914099,
        "scientificamerican":0.1451854481,
        "wired":0.2159078136,
        "popsci":0.1810712877,
        "arstechnica":0.1866010527,
        "salon":0.1445054503,
        "washingtonpost":0.2208460841,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.05591v1",
        "predicted_newsworthiness":56.1387303477,
        "title":"Predicting Fuel Consumption in Power Generation Plants using Machine Learning and Neural Networks",
        "summary":"The instability of power generation from national grids has led industries (e.g., telecommunication) to rely on plant generators to run their businesses. However, these secondary generators create additional challenges such as fuel leakages in and out of the system and perturbations in the fuel level gauges. Consequently, telecommunication operators have been involved in a constant need for fuel to supply diesel generators. With the increase in fuel prices due to socio-economic factors, excessive fuel consumption and fuel pilferage become a problem, and this affects the smooth run of the network companies. In this work, we compared four machine learning algorithms (i.e. Gradient Boosting, Random Forest, Neural Network, and Lasso) to predict the amount of fuel consumed by a power generation plant. After evaluating the predictive accuracy of these models, the Gradient Boosting model out-perform the other three regressor models with the highest Nash efficiency value of 99.1%.",
        "published":1644585685000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.05591v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Feb 11, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1787299691,
        "popularmechanics":0.1944121118,
        "scienmag":0.2067637319,
        "technologyreview":0.2825884562,
        "vox":0.215688158,
        "newscientist":0.1964125032,
        "vice":0.1484188729,
        "statnews":0.2168297509,
        "nytimes":0.2245529428,
        "techcrunch":0.2116811452,
        "quartz":0.2038934195,
        "venturebeat":0.2611127847,
        "futurism":0.2424212401,
        "scientificamerican":0.1842228001,
        "wired":0.2038604222,
        "popsci":0.2151314385,
        "arstechnica":0.2082998619,
        "salon":0.210182817,
        "washingtonpost":0.1785633281,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.03017v1",
        "predicted_newsworthiness":41.8854954949,
        "title":"Model Agnostic Conformal Hyperparameter Optimization",
        "summary":"Several novel frameworks for hyperparameter search have emerged in the last decade, but most rely on strict, often normal, distributional assumptions, limiting search model flexibility. This paper proposes a novel optimization framework based on Conformal prediction, assuming only exchangeability, and allowing for a larger choice of search model architectures and variance estimators. Several such models are explored and benchmarked against random hyperparameter search on both dense and convolutional neural networks with consistent overperformance both in final loss achieved and time to achievement.",
        "published":1657151504000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.03017v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jul 06, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0541437769,
        "popularmechanics":0.1069959985,
        "scienmag":0.1091497325,
        "technologyreview":0.1911051541,
        "vox":0.0870980132,
        "newscientist":0.0946828319,
        "vice":0.0886943933,
        "statnews":0.1505323908,
        "nytimes":0.0879588478,
        "techcrunch":0.1088567523,
        "quartz":0.0790736622,
        "venturebeat":0.1716842982,
        "futurism":0.1201245049,
        "scientificamerican":0.0814916459,
        "wired":0.1249972739,
        "popsci":0.119532554,
        "arstechnica":0.0888046657,
        "salon":0.0628645206,
        "washingtonpost":0.0912581871,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2208.00493v1",
        "predicted_newsworthiness":47.1174916084,
        "title":"Scrutinizing Shipment Records To Thwart Illegal Timber Trade",
        "summary":"Timber and forest products made from wood, like furniture, are valuable commodities, and like the global trade of many highly-valued natural resources, face challenges of corruption, fraud, and illegal harvesting. These grey and black market activities in the wood and forest products sector are not limited to the countries where the wood was harvested, but extend throughout the global supply chain and have been tied to illicit financial flows, like trade-based money laundering, document fraud, species mislabeling, and other illegal activities. The task of finding such fraudulent activities using trade data, in the absence of ground truth, can be modelled as an unsupervised anomaly detection problem. However existing approaches suffer from certain shortcomings in their applicability towards large scale trade data. Trade data is heterogeneous, with both categorical and numerical attributes in a tabular format. The overall challenge lies in the complexity, volume and velocity of data, with large number of entities and lack of ground truth labels. To mitigate these, we propose a novel unsupervised anomaly detection -- Contrastive Learning based Heterogeneous Anomaly Detection (CHAD) that is generally applicable for large-scale heterogeneous tabular data. We demonstrate our model CHAD performs favorably against multiple comparable baselines for public benchmark datasets, and outperforms them in the case of trade data. More importantly we demonstrate our approach reduces assumptions and efforts required hyperparameter tuning, which is a key challenging aspect in an unsupervised training paradigm. Specifically, our overarching objective pertains to detecting suspicious timber shipments and patterns using Bill of Lading trade record data. Detecting anomalous transactions in shipment records can enable further investigation by government agencies and supply chain constituents.",
        "published":1659293692000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2208.00493v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jul 31, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1708884052,
        "popularmechanics":0.1710965442,
        "scienmag":0.1633323512,
        "technologyreview":0.262824051,
        "vox":0.1992226552,
        "newscientist":0.1667100482,
        "vice":0.162361522,
        "statnews":0.1996372908,
        "nytimes":0.1997111714,
        "techcrunch":0.2157447479,
        "quartz":0.202484337,
        "venturebeat":0.2533256933,
        "futurism":0.200631708,
        "scientificamerican":0.1701282471,
        "wired":0.2141334574,
        "popsci":0.1962958022,
        "arstechnica":0.2179784265,
        "salon":0.1766309232,
        "washingtonpost":0.2198574121,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.09049v1",
        "predicted_newsworthiness":51.2978801656,
        "title":"RepBNN: towards a precise Binary Neural Network with Enhanced Feature Map via Repeating",
        "summary":"Binary neural network (BNN) is an extreme quantization version of convolutional neural networks (CNNs) with all features and weights mapped to just 1-bit. Although BNN saves a lot of memory and computation demand to make CNN applicable on edge or mobile devices, BNN suffers the drop of network performance due to the reduced representation capability after binarization. In this paper, we propose a new replaceable and easy-to-use convolution module RepConv, which enhances feature maps through replicating input or output along channel dimension by $\\beta$ times without extra cost on the number of parameters and convolutional computation. We also define a set of RepTran rules to use RepConv throughout BNN modules like binary convolution, fully connected layer and batch normalization. Experiments demonstrate that after the RepTran transformation, a set of highly cited BNNs have achieved universally better performance than the original BNN versions. For example, the Top-1 accuracy of Rep-ReCU-ResNet-20, i.e., a RepBconv enhanced ReCU-ResNet-20, reaches 88.97% on CIFAR-10, which is 1.47% higher than that of the original network. And Rep-AdamBNN-ReActNet-A achieves 71.342% Top-1 accuracy on ImageNet, a fresh state-of-the-art result of BNNs. Code and models are available at:https:\/\/github.com\/imfinethanks\/Rep_AdamBNN.",
        "published":1658201914000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.09049v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 18, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0954170252,
        "popularmechanics":0.1496383582,
        "scienmag":0.1501880664,
        "technologyreview":0.2398444977,
        "vox":0.122469556,
        "newscientist":0.1480180448,
        "vice":0.112525554,
        "statnews":0.1433981178,
        "nytimes":0.1364162112,
        "techcrunch":0.1699008457,
        "quartz":0.1184091207,
        "venturebeat":0.2241457549,
        "futurism":0.1786023742,
        "scientificamerican":0.1201000666,
        "wired":0.1769167655,
        "popsci":0.2034353357,
        "arstechnica":0.131731677,
        "salon":0.0753057743,
        "washingtonpost":0.1564166018,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.02251v1",
        "predicted_newsworthiness":39.0185730554,
        "title":"RBGNet: Ray-based Grouping for 3D Object Detection",
        "summary":"As a fundamental problem in computer vision, 3D object detection is experiencing rapid growth. To extract the point-wise features from the irregularly and sparsely distributed points, previous methods usually take a feature grouping module to aggregate the point features to an object candidate. However, these methods have not yet leveraged the surface geometry of foreground objects to enhance grouping and 3D box generation. In this paper, we propose the RBGNet framework, a voting-based 3D detector for accurate 3D object detection from point clouds. In order to learn better representations of object shape to enhance cluster features for predicting 3D boxes, we propose a ray-based feature grouping module, which aggregates the point-wise features on object surfaces using a group of determined rays uniformly emitted from cluster centers. Considering the fact that foreground points are more meaningful for box estimation, we design a novel foreground biased sampling strategy in downsample process to sample more points on object surfaces and further boost the detection performance. Our model achieves state-of-the-art 3D detection performance on ScanNet V2 and SUN RGB-D with remarkable performance gains. Code will be available at https:\/\/github.com\/Haiyang-W\/RBGNet.",
        "published":1649169777000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.02251v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Apr 05, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0873133807,
        "popularmechanics":0.1832062485,
        "scienmag":0.145382681,
        "technologyreview":0.2048383808,
        "vox":0.1223162624,
        "newscientist":0.150873077,
        "vice":0.1624250917,
        "statnews":0.0986167953,
        "nytimes":0.1318433912,
        "techcrunch":0.1843880127,
        "quartz":0.1139013413,
        "venturebeat":0.2020776144,
        "futurism":0.1837325604,
        "scientificamerican":0.1312239162,
        "wired":0.170149256,
        "popsci":0.1979434595,
        "arstechnica":0.1342171016,
        "salon":0.0934286655,
        "washingtonpost":0.1526445656,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.03331v1",
        "predicted_newsworthiness":39.9069767086,
        "title":"Improving the Diagnosis of Psychiatric Disorders with Self-Supervised Graph State Space Models",
        "summary":"Single subject prediction of brain disorders from neuroimaging data has gained increasing attention in recent years. Yet, for some heterogeneous disorders such as major depression disorder (MDD) and autism spectrum disorder (ASD), the performance of prediction models on large-scale multi-site datasets remains poor. We present a two-stage framework to improve the diagnosis of heterogeneous psychiatric disorders from resting-state functional magnetic resonance imaging (rs-fMRI). First, we propose a self-supervised mask prediction task on data from healthy individuals that can exploit differences between healthy controls and patients in clinical datasets. Next, we train a supervised classifier on the learned discriminative representations. To model rs-fMRI data, we develop Graph-S4; an extension to the recently proposed state-space model S4 to graph settings where the underlying graph structure is not known in advance. We show that combining the framework and Graph-S4 can significantly improve the diagnostic performance of neuroimaging-based single subject prediction models of MDD and ASD on three open-source multi-center rs-fMRI clinical datasets.",
        "published":1654611343000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.03331v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jun 07, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1283818664,
        "popularmechanics":0.101544811,
        "scienmag":0.2258842795,
        "technologyreview":0.2171546712,
        "vox":0.1396729529,
        "newscientist":0.1713158627,
        "vice":0.1035031333,
        "statnews":0.2582562885,
        "nytimes":0.1432170449,
        "techcrunch":0.1217096709,
        "quartz":0.1159116571,
        "venturebeat":0.188718486,
        "futurism":0.1705659916,
        "scientificamerican":0.1630401287,
        "wired":0.1465316938,
        "popsci":0.1397116342,
        "arstechnica":0.1268149567,
        "salon":0.1699521277,
        "washingtonpost":0.1456344159,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.04737v1",
        "predicted_newsworthiness":83.3965556372,
        "title":"Outsider Oversight: Designing a Third Party Audit Ecosystem for AI Governance",
        "summary":"Much attention has focused on algorithmic audits and impact assessments to hold developers and users of algorithmic systems accountable. But existing algorithmic accountability policy approaches have neglected the lessons from non-algorithmic domains: notably, the importance of interventions that allow for the effective participation of third parties. Our paper synthesizes lessons from other fields on how to craft effective systems of external oversight for algorithmic deployments. First, we discuss the challenges of third party oversight in the current AI landscape. Second, we survey audit systems across domains - e.g., financial, environmental, and health regulation - and show that the institutional design of such audits are far from monolithic. Finally, we survey the evidence base around these design components and spell out the implications for algorithmic auditing. We conclude that the turn toward audits alone is unlikely to achieve actual algorithmic accountability, and sustained focus on institutional design will be required for meaningful third party involvement.",
        "published":1654802327000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.04737v1",
        "arxiv_primary_category":"cs.cy",
        "published_hr":"Jun 09, 2022",
        "arxiv_primary_category_hr":"Computers and Society",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2690245873,
        "popularmechanics":0.2204361696,
        "scienmag":0.2228666614,
        "technologyreview":0.4509742133,
        "vox":0.3842032937,
        "newscientist":0.2659675044,
        "vice":0.1990709971,
        "statnews":0.404490026,
        "nytimes":0.3481971803,
        "techcrunch":0.385129107,
        "quartz":0.3088567816,
        "venturebeat":0.4141039479,
        "futurism":0.3469573286,
        "scientificamerican":0.2386307122,
        "wired":0.3801296822,
        "popsci":0.3131182945,
        "arstechnica":0.3337511221,
        "salon":0.2637017412,
        "washingtonpost":0.3776718811,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.09416v2",
        "predicted_newsworthiness":39.0824510684,
        "title":"Bi-directional Object-context Prioritization Learning for Saliency Ranking",
        "summary":"The saliency ranking task is recently proposed to study the visual behavior that humans would typically shift their attention over different objects of a scene based on their degrees of saliency. Existing approaches focus on learning either object-object or object-scene relations. Such a strategy follows the idea of object-based attention in Psychology, but it tends to favor those objects with strong semantics (e.g., humans), resulting in unrealistic saliency ranking. We observe that spatial attention works concurrently with object-based attention in the human visual recognition system. During the recognition process, the human spatial attention mechanism would move, engage, and disengage from region to region (i.e., context to context). This inspires us to model the region-level interactions, in addition to the object-level reasoning, for saliency ranking. To this end, we propose a novel bi-directional method to unify spatial attention and object-based attention for saliency ranking. Our model includes two novel modules: (1) a selective object saliency (SOS) module that models objectbased attention via inferring the semantic representation of the salient object, and (2) an object-context-object relation (OCOR) module that allocates saliency ranks to objects by jointly modeling the object-context and context-object interactions of the salient objects. Extensive experiments show that our approach outperforms existing state-of-theart methods. Our code and pretrained model are available at https:\/\/github.com\/GrassBro\/OCOR.",
        "published":1647533763000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.09416v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Mar 17, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0927724623,
        "popularmechanics":0.1100764528,
        "scienmag":0.117563266,
        "technologyreview":0.1833096636,
        "vox":0.0984532963,
        "newscientist":0.1403037203,
        "vice":0.1125020112,
        "statnews":0.125321219,
        "nytimes":0.1231130728,
        "techcrunch":0.1232137216,
        "quartz":0.1060617523,
        "venturebeat":0.1695440228,
        "futurism":0.1293970853,
        "scientificamerican":0.1240857976,
        "wired":0.1636121201,
        "popsci":0.1514265226,
        "arstechnica":0.0794585929,
        "salon":0.093762086,
        "washingtonpost":0.1146699642,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.06953v1",
        "predicted_newsworthiness":47.0939601167,
        "title":"Forward Compatible Few-Shot Class-Incremental Learning",
        "summary":"Novel classes frequently arise in our dynamically changing world, e.g., new users in the authentication system, and a machine learning model should recognize new classes without forgetting old ones. This scenario becomes more challenging when new class instances are insufficient, which is called few-shot class-incremental learning (FSCIL). Current methods handle incremental learning retrospectively by making the updated model similar to the old one. By contrast, we suggest learning prospectively to prepare for future updates, and propose ForwArd Compatible Training (FACT) for FSCIL. Forward compatibility requires future new classes to be easily incorporated into the current model based on the current stage data, and we seek to realize it by reserving embedding space for future new classes. In detail, we assign virtual prototypes to squeeze the embedding of known classes and reserve for new ones. Besides, we forecast possible new classes and prepare for the updating process. The virtual prototypes allow the model to accept possible updates in the future, which act as proxies scattered among embedding space to build a stronger classifier during inference. FACT efficiently incorporates new classes with forward compatibility and meanwhile resists forgetting of old ones. Extensive experiments validate FACT's state-of-the-art performance. Code is available at: https:\/\/github.com\/zhoudw-zdw\/CVPR22-Fact",
        "published":1647250595000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.06953v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Mar 14, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1084350475,
        "popularmechanics":0.1717905248,
        "scienmag":0.1351019166,
        "technologyreview":0.2422067848,
        "vox":0.1462289331,
        "newscientist":0.1488380843,
        "vice":0.1168353747,
        "statnews":0.1787916109,
        "nytimes":0.1599844451,
        "techcrunch":0.1895089869,
        "quartz":0.1332832377,
        "venturebeat":0.2456122899,
        "futurism":0.177613818,
        "scientificamerican":0.12834864,
        "wired":0.1865949751,
        "popsci":0.206077726,
        "arstechnica":0.1503897368,
        "salon":0.1058128602,
        "washingtonpost":0.1663022457,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.08365v1",
        "predicted_newsworthiness":40.1042924161,
        "title":"CausNet : Generational orderings based search for optimal Bayesian networks via dynamic programming with parent set constraints",
        "summary":"Finding a globally optimal Bayesian Network using exhaustive search is a problem with super-exponential complexity, which severely restricts the number of variables that it can work for. We implement a dynamic programming based algorithm with built-in dimensionality reduction and parent set identification. This reduces the search space drastically and can be applied to large-dimensional data. We use what we call generational orderings based search for optimal networks, which is a novel way to efficiently search the space of possible networks given the possible parent sets. The algorithm supports both continuous and categorical data, and categorical as well as survival outcomes. We demonstrate the efficacy of our algorithm on both synthetic and real data. In simulations, our algorithm performs better than three state-of-art algorithms that are currently used extensively. We then apply it to an Ovarian Cancer gene expression dataset with 513 genes and a survival outcome. Our algorithm is able to find an optimal network describing the disease pathway consisting of 6 genes leading to the outcome node in a few minutes on a basic computer. Our generational orderings based search for optimal networks, is both efficient and highly scalable approach to finding optimal Bayesian Networks, that can be applied to 1000s of variables. Using specifiable parameters - correlation, FDR cutoffs, and in-degree - one can increase or decrease the number of nodes and density of the networks. Availability of two scoring option-BIC and Bge-and implementation of survival outcomes and mixed data types makes our algorithm very suitable for many types of high dimensional biomedical data to find disease pathways.",
        "published":1658114801000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.08365v1",
        "arxiv_primary_category":"cs.ai",
        "published_hr":"Jul 17, 2022",
        "arxiv_primary_category_hr":"Artificial Intelligence",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1356606518,
        "popularmechanics":0.1245902197,
        "scienmag":0.2568321081,
        "technologyreview":0.2231487245,
        "vox":0.1464959567,
        "newscientist":0.1645952815,
        "vice":0.1417035992,
        "statnews":0.3043402124,
        "nytimes":0.1679137055,
        "techcrunch":0.1668945807,
        "quartz":0.1299669669,
        "venturebeat":0.2134382545,
        "futurism":0.1689886172,
        "scientificamerican":0.1669033002,
        "wired":0.1576254626,
        "popsci":0.1575302826,
        "arstechnica":0.1532383075,
        "salon":0.1692032262,
        "washingtonpost":0.1440026609,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.08904v4",
        "predicted_newsworthiness":35.4802094709,
        "title":"SGPT: GPT Sentence Embeddings for Semantic Search",
        "summary":"GPT transformers are the largest language models available, yet semantic search is dominated by BERT transformers. We present SGPT-BE and SGPT-CE for applying GPT models as Bi-Encoders or Cross-Encoders to symmetric or asymmetric search. SGPT-BE produces semantically meaningful sentence embeddings by contrastive fine-tuning of only bias tensors and a novel pooling method. A 5.8 billion parameter SGPT-BE outperforms the best available sentence embeddings by 6% setting a new state-of-the-art on BEIR. It outperforms the concurrently proposed OpenAI Embeddings of the 175B Davinci endpoint, which fine-tunes 250,000 times more parameters. SGPT-CE uses log probabilities from GPT models without any fine-tuning. A 6.1 billion parameter SGPT-CE sets an unsupervised state-of-the-art on BEIR. It beats the supervised state-of-the-art on 7 datasets, but significantly loses on other datasets. We show how this can be alleviated by adapting the prompt. SGPT-BE and SGPT-CE performance scales with model size. Yet, increased latency, storage and compute costs should be considered. Code, models and result files are freely available at https:\/\/github.com\/Muennighoff\/sgpt.",
        "published":1645133756000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.08904v4",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Feb 17, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0857796406,
        "popularmechanics":0.1088025908,
        "scienmag":0.1016316446,
        "technologyreview":0.2036380323,
        "vox":0.1307050546,
        "newscientist":0.1179129993,
        "vice":0.1041519074,
        "statnews":0.129370077,
        "nytimes":0.1154834735,
        "techcrunch":0.1472262984,
        "quartz":0.1109875037,
        "venturebeat":0.211640319,
        "futurism":0.1408595883,
        "scientificamerican":0.1004315879,
        "wired":0.1610386378,
        "popsci":0.1444250757,
        "arstechnica":0.1086734818,
        "salon":0.0854726325,
        "washingtonpost":0.1161582321,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.10581v1",
        "predicted_newsworthiness":32.4656553167,
        "title":"Unleashing the Power of Transformer for Graphs",
        "summary":"Despite recent successes in natural language processing and computer vision, Transformer suffers from the scalability problem when dealing with graphs. The computational complexity is unacceptable for large-scale graphs, e.g., knowledge graphs. One solution is to consider only the near neighbors, which, however, will lose the key merit of Transformer to attend to the elements at any distance. In this paper, we propose a new Transformer architecture, named dual-encoding Transformer (DET). DET has a structural encoder to aggregate information from connected neighbors and a semantic encoder to focus on semantically useful distant nodes. In comparison with resorting to multi-hop neighbors, DET seeks the desired distant neighbors via self-supervised training. We further find these two encoders can be incorporated to boost each others' performance. Our experiments demonstrate DET has achieved superior performance compared to the respective state-of-the-art methods in dealing with molecules, networks and knowledge graphs with various sizes.",
        "published":1645166451000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.10581v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Feb 18, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1009294085,
        "popularmechanics":0.1168322378,
        "scienmag":0.1819274834,
        "technologyreview":0.2282626628,
        "vox":0.1409257351,
        "newscientist":0.151301014,
        "vice":0.126135541,
        "statnews":0.196638983,
        "nytimes":0.1443046927,
        "techcrunch":0.1560740344,
        "quartz":0.1144015427,
        "venturebeat":0.2140978967,
        "futurism":0.1582127418,
        "scientificamerican":0.1461985663,
        "wired":0.1572802347,
        "popsci":0.1549382422,
        "arstechnica":0.1270268137,
        "salon":0.1110370739,
        "washingtonpost":0.1578457977,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.10241v1",
        "predicted_newsworthiness":38.2445552837,
        "title":"VRConvMF: Visual Recurrent Convolutional Matrix Factorization for Movie Recommendation",
        "summary":"Sparsity of user-to-item rating data becomes one of challenging issues in the recommender systems, which severely deteriorates the recommendation performance. Fortunately, context-aware recommender systems can alleviate the sparsity problem by making use of some auxiliary information, such as the information of both the users and items. In particular, the visual information of items, such as the movie poster, can be considered as the supplement for item description documents, which helps to obtain more item features. In this paper, we focus on movie recommender system and propose a probabilistic matrix factorization based recommendation scheme called visual recurrent convolutional matrix factorization (VRConvMF), which utilizes the textual and multi-level visual features extracted from the descriptive texts and posters respectively. We implement the proposed VRConvMF and conduct extensive experiments on three commonly used real world datasets to validate its effectiveness. The experimental results illustrate that the proposed VRConvMF outperforms the existing schemes.",
        "published":1644999663000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.10241v1",
        "arxiv_primary_category":"cs.ir",
        "published_hr":"Feb 16, 2022",
        "arxiv_primary_category_hr":"Information Retrieval",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1107098142,
        "popularmechanics":0.1182545591,
        "scienmag":0.1075902652,
        "technologyreview":0.2003795695,
        "vox":0.1641530949,
        "newscientist":0.1364869022,
        "vice":0.071703682,
        "statnews":0.1348143085,
        "nytimes":0.1560356496,
        "techcrunch":0.1804846094,
        "quartz":0.1523807651,
        "venturebeat":0.2153769394,
        "futurism":0.1446296231,
        "scientificamerican":0.0987043574,
        "wired":0.2116824001,
        "popsci":0.1782252918,
        "arstechnica":0.1066271345,
        "salon":0.0886218796,
        "washingtonpost":0.1582843809,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.15025v1",
        "predicted_newsworthiness":38.4021784684,
        "title":"Stochastic Bilevel Distributed Optimization over a Network",
        "summary":"Bilevel optimization has been applied to a wide variety of machine learning models. Numerous stochastic bilevel optimization algorithms have been developed in recent years. However, most of them restrict their focus on the single-machine setting so that they are incapable of handling the distributed data. To address this issue, under the setting where all participants compose a network and perform the peer-to-peer communication in this network, we developed two novel distributed stochastic bilevel optimization algorithms based on the gradient tracking communication mechanism and two different gradient estimators. Additionally, we show that they can achieve $O(\\frac{1}{\\epsilon^{2}(1-\\lambda)^2})$ and $O(\\frac{1}{\\epsilon^{3\/2}(1-\\lambda)^2})$ convergence rate respectively to obtain the $\\epsilon$-accuracy solution, where $1-\\lambda$ denotes the spectral gap of the communication network. To our knowledge, this is the first work achieving these theoretical results. Finally, we applied our algorithms to practical machine learning models, and the experimental results confirmed the efficacy of our algorithms.",
        "published":1656566992000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.15025v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jun 30, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0804107107,
        "popularmechanics":0.0986559255,
        "scienmag":0.1346965106,
        "technologyreview":0.1985041304,
        "vox":0.129096129,
        "newscientist":0.1214175263,
        "vice":0.1008520853,
        "statnews":0.1883404635,
        "nytimes":0.1286112317,
        "techcrunch":0.1659364692,
        "quartz":0.1093431746,
        "venturebeat":0.2094367394,
        "futurism":0.1376994829,
        "scientificamerican":0.1106328683,
        "wired":0.1503299736,
        "popsci":0.145904546,
        "arstechnica":0.1178988631,
        "salon":0.0825101857,
        "washingtonpost":0.1416676552,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.03718v1",
        "predicted_newsworthiness":78.9334097389,
        "title":"Towards User-Centered Metrics for Trustworthy AI in Immersive Cyberspace",
        "summary":"AI plays a key role in current cyberspace and future immersive ecosystems that pinpoint user experiences. Thus, the trustworthiness of such AI systems is vital as failures in these systems can cause serious user harm. Although there are related works on exploring trustworthy AI (TAI) metrics in the current cyberspace, ecosystems towards user-centered services, such as the metaverse, are much more complicated in terms of system performance and user experience assessment, thus posing challenges for the applicability of existing approaches. Thus, we give an overlook on fairness, privacy and robustness, across the historical path from existing approaches. Eventually, we propose a research agenda towards systematic yet user-centered TAI in immersive ecosystems.",
        "published":1645542778000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.03718v1",
        "arxiv_primary_category":"cs.cy",
        "published_hr":"Feb 22, 2022",
        "arxiv_primary_category_hr":"Computers and Society",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2180857739,
        "popularmechanics":0.2381534617,
        "scienmag":0.2116389704,
        "technologyreview":0.3980835185,
        "vox":0.3153572161,
        "newscientist":0.2661595604,
        "vice":0.2028167213,
        "statnews":0.3497049764,
        "nytimes":0.3064932899,
        "techcrunch":0.3429368726,
        "quartz":0.2601129648,
        "venturebeat":0.3976432778,
        "futurism":0.3324163084,
        "scientificamerican":0.2186335951,
        "wired":0.3608482675,
        "popsci":0.3467899922,
        "arstechnica":0.2703731209,
        "salon":0.2017106327,
        "washingtonpost":0.3119181753,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2207.09925v1",
        "predicted_newsworthiness":37.6374082207,
        "title":"An Efficient Framework for Few-shot Skeleton-based Temporal Action Segmentation",
        "summary":"Temporal action segmentation (TAS) aims to classify and locate actions in the long untrimmed action sequence. With the success of deep learning, many deep models for action segmentation have emerged. However, few-shot TAS is still a challenging problem. This study proposes an efficient framework for the few-shot skeleton-based TAS, including a data augmentation method and an improved model. The data augmentation approach based on motion interpolation is presented here to solve the problem of insufficient data, and can increase the number of samples significantly by synthesizing action sequences. Besides, we concatenate a Connectionist Temporal Classification (CTC) layer with a network designed for skeleton-based TAS to obtain an optimized model. Leveraging CTC can enhance the temporal alignment between prediction and ground truth and further improve the segment-wise metrics of segmentation results. Extensive experiments on both public and self-constructed datasets, including two small-scale datasets and one large-scale dataset, show the effectiveness of two proposed methods in improving the performance of the few-shot skeleton-based TAS task.",
        "published":1658326117000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2207.09925v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jul 20, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.08349105,
        "popularmechanics":0.1249141312,
        "scienmag":0.1041712133,
        "technologyreview":0.1620357957,
        "vox":0.0865481521,
        "newscientist":0.1206089622,
        "vice":0.1083247683,
        "statnews":0.0924944263,
        "nytimes":0.1123275957,
        "techcrunch":0.1161119192,
        "quartz":0.0960962916,
        "venturebeat":0.1564943862,
        "futurism":0.1228403114,
        "scientificamerican":0.1003921244,
        "wired":0.1336122366,
        "popsci":0.1283448766,
        "arstechnica":0.0939310333,
        "salon":0.0812703,
        "washingtonpost":0.1012067284,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.09139v1",
        "predicted_newsworthiness":37.4663986205,
        "title":"Dual-Flattening Transformers through Decomposed Row and Column Queries for Semantic Segmentation",
        "summary":"It is critical to obtain high resolution features with long range dependency for dense prediction tasks such as semantic segmentation. To generate high-resolution output of size $H\\times W$ from a low-resolution feature map of size $h\\times w$ ($hw\\ll HW$), a naive dense transformer incurs an intractable complexity of $\\mathcal{O}(hwHW)$, limiting its application on high-resolution dense prediction. We propose a Dual-Flattening Transformer (DFlatFormer) to enable high-resolution output by reducing complexity to $\\mathcal{O}(hw(H+W))$ that is multiple orders of magnitude smaller than the naive dense transformer. Decomposed queries are presented to retrieve row and column attentions tractably through separate transformers, and their outputs are combined to form a dense feature map at high resolution. To this end, the input sequence fed from an encoder is row-wise and column-wise flattened to align with decomposed queries by preserving their row and column structures, respectively. Row and column transformers also interact with each other to capture their mutual attentions with the spatial crossings between rows and columns. We also propose to perform attentions through efficient grouping and pooling to further reduce the model complexity. Extensive experiments on ADE20K and Cityscapes datasets demonstrate the superiority of the proposed dual-flattening transformer architecture with higher mIoUs.",
        "published":1642891095000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.09139v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jan 22, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0845053528,
        "popularmechanics":0.1312020531,
        "scienmag":0.1062583917,
        "technologyreview":0.1848835855,
        "vox":0.1129574341,
        "newscientist":0.1105267642,
        "vice":0.1094553474,
        "statnews":0.0997221996,
        "nytimes":0.1026364293,
        "techcrunch":0.1469515018,
        "quartz":0.1033069247,
        "venturebeat":0.1861081083,
        "futurism":0.1487554977,
        "scientificamerican":0.0945402549,
        "wired":0.1410294318,
        "popsci":0.1477331313,
        "arstechnica":0.1065998871,
        "salon":0.0936622068,
        "washingtonpost":0.1216833239,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.00477v1",
        "predicted_newsworthiness":73.9811327744,
        "title":"Detection of Increased Time Intervals of Anti-Vaccine Tweets for COVID-19 Vaccine with BERT Model",
        "summary":"The most effective of the solutions against Covid-19 is the various vaccines developed. Distrust of vaccines can hinder the rapid and effective use of this remedy. One of the means of expressing the thoughts of society is social media. Determining the time intervals during which anti-vaccination increases in social media can help institutions determine the strategy to be used in combating anti-vaccination. Recording and tracking every tweet entered with human labor would be inefficient, so various automation solutions are needed. In this study, The Bidirectional Encoder Representations from Transformers (BERT) model, which is a deep learning-based natural language processing (NLP) model, was used. In a dataset of 1506 tweets divided into four different categories as news, irrelevant, anti-vaccine, and vaccine supporters, the model was trained with a learning rate of 5e-6 for 25 epochs. To determine the intervals in which anti-vaccine tweets are concentrated, the categories to which 652840 tweets belong were determined by using the trained model. The change of the determined categories overtime was visualized and the events that could cause the change were determined. As a result of model training, in the test dataset, the f-score of 0.81 and AUC values for different classes were obtained as 0.99,0.91, 0.92, 0.92, respectively. In this model, unlike the studies in the literature, an auxiliary system is designed that provides data that institutions can use when determining their strategy by measuring and visualizing the frequency of anti-vaccine tweets in a time interval, different from detecting and censoring such tweets.",
        "published":1642012223000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.00477v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Jan 12, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.3001616263,
        "popularmechanics":0.1871894064,
        "scienmag":0.2916407727,
        "technologyreview":0.3712578389,
        "vox":0.3444809034,
        "newscientist":0.2922809863,
        "vice":0.2008750026,
        "statnews":0.391222595,
        "nytimes":0.3284594601,
        "techcrunch":0.2840849609,
        "quartz":0.2788754085,
        "venturebeat":0.339091717,
        "futurism":0.2992630849,
        "scientificamerican":0.3217597557,
        "wired":0.3180591268,
        "popsci":0.2943014952,
        "arstechnica":0.3120871755,
        "salon":0.3533447289,
        "washingtonpost":0.3572180653,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.01735v2",
        "predicted_newsworthiness":40.7178565498,
        "title":"Modality-Adaptive Mixup and Invariant Decomposition for RGB-Infrared Person Re-Identification",
        "summary":"RGB-infrared person re-identification is an emerging cross-modality re-identification task, which is very challenging due to significant modality discrepancy between RGB and infrared images. In this work, we propose a novel modality-adaptive mixup and invariant decomposition (MID) approach for RGB-infrared person re-identification towards learning modality-invariant and discriminative representations. MID designs a modality-adaptive mixup scheme to generate suitable mixed modality images between RGB and infrared images for mitigating the inherent modality discrepancy at the pixel-level. It formulates modality mixup procedure as Markov decision process, where an actor-critic agent learns dynamical and local linear interpolation policy between different regions of cross-modality images under a deep reinforcement learning framework. Such policy guarantees modality-invariance in a more continuous latent space and avoids manifold intrusion by the corrupted mixed modality samples. Moreover, to further counter modality discrepancy and enforce invariant visual semantics at the feature-level, MID employs modality-adaptive convolution decomposition to disassemble a regular convolution layer into modality-specific basis layers and a modality-shared coefficient layer. Extensive experimental results on two challenging benchmarks demonstrate superior performance of MID over state-of-the-art methods.",
        "published":1646317609000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.01735v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Mar 03, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0936808829,
        "popularmechanics":0.1253926679,
        "scienmag":0.1087126288,
        "technologyreview":0.2136695707,
        "vox":0.1024302355,
        "newscientist":0.1259553469,
        "vice":0.1132413154,
        "statnews":0.1037111515,
        "nytimes":0.1126022235,
        "techcrunch":0.1278907395,
        "quartz":0.1111825201,
        "venturebeat":0.1865644471,
        "futurism":0.1489806131,
        "scientificamerican":0.0964353645,
        "wired":0.1465357767,
        "popsci":0.1634891841,
        "arstechnica":0.1025264044,
        "salon":0.0755422814,
        "washingtonpost":0.1267406067,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.01628v1",
        "predicted_newsworthiness":42.6595031731,
        "title":"Feasible Wrench Set Computation for Legged Robots",
        "summary":"During locomotion, legged robots interact with the ground by sequentially establishing and breaking contact. The interaction wrenches that arise from contact are used to steer the robot's Center of Mass (CoM) and reject perturbations that make the system deviate from the desired trajectory and often make them fall. The feasibility of a given control target (desired CoM wrench or acceleration) is conditioned by the contact point distribution, ground friction, and actuation limits. In this work, we develop an algorithm to compute the set of feasible wrenches that a legged robot can exert on its CoM through contact. The presented method can be used with any amount of non-coplanar contacts and takes into account actuation limits and limitations based on an inelastic contact model with Coulomb friction. This is exemplified with a planar biped model standing with the feet at different heights. Exploiting assumptions from the contact model, we explain how to compute the set of wrenches that are feasible on the CoM when the contacts remain in position as well as the ones that are feasible when some of the contacts are broken. Therefore, this algorithm can be used to assess whether a switch in contact configuration is feasible while achieving a given control task. Furthermore, the method can be used to identify the directions in which the system is not actuated (i.e. a wrench cannot be exerted in those directions). We show how having a joint be actuated or passive can change the non-actuated wrench directions of a robot at a given pose using a spatial model of a lower-extremity exoskeleton. Therefore, this algorithm is also a useful tool for the design phase of the system. This work presents a useful tool for the control and design of legged systems that extends on the current state of the art.",
        "published":1643900398000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.01628v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Feb 03, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0709527443,
        "popularmechanics":0.1919108448,
        "scienmag":0.1214326886,
        "technologyreview":0.1616760591,
        "vox":0.0671102571,
        "newscientist":0.1584176955,
        "vice":0.1570091773,
        "statnews":0.0558858036,
        "nytimes":0.1129019992,
        "techcrunch":0.1112411775,
        "quartz":0.0746383249,
        "venturebeat":0.113133539,
        "futurism":0.1911817313,
        "scientificamerican":0.1159155699,
        "wired":0.1354585267,
        "popsci":0.2189717719,
        "arstechnica":0.1009510032,
        "salon":0.0728181459,
        "washingtonpost":0.1288317941,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.01410v1",
        "predicted_newsworthiness":69.1893336195,
        "title":"Fair Classification via Transformer Neural Networks: Case Study of an Educational Domain",
        "summary":"Educational technologies nowadays increasingly use data and Machine Learning (ML) models. This gives the students, instructors, and administrators support and insights for the optimum policy. However, it is well acknowledged that ML models are subject to bias, which raises concern about the fairness, bias, and discrimination of using these automated ML algorithms in education and its unintended and unforeseen negative consequences. The contribution of bias during the decision-making comes from datasets used for training ML models and the model architecture. This paper presents a preliminary investigation of fairness constraint in transformer neural networks on Law School and Student-Mathematics datasets. The used transformer models transform these raw datasets into a richer representation space of natural language processing (NLP) while solving fairness classification. We have employed fairness metrics for evaluation and check the trade-off between fairness and accuracy. We have reported the various metrics of F1, SPD, EOD, and accuracy for different architectures from the transformer model class.",
        "published":1654238056000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.01410v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jun 03, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.2184551526,
        "popularmechanics":0.1284885274,
        "scienmag":0.1932248377,
        "technologyreview":0.334121349,
        "vox":0.2309415312,
        "newscientist":0.1949134268,
        "vice":0.1176469671,
        "statnews":0.2746742008,
        "nytimes":0.2356177012,
        "techcrunch":0.2193008602,
        "quartz":0.2160154748,
        "venturebeat":0.2890917028,
        "futurism":0.2344543496,
        "scientificamerican":0.1829736056,
        "wired":0.2448456706,
        "popsci":0.2011152046,
        "arstechnica":0.2136708704,
        "salon":0.1755441398,
        "washingtonpost":0.2346456121,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.01961v1",
        "predicted_newsworthiness":45.4192435294,
        "title":"Balancing Generalization and Specialization in Zero-shot Learning",
        "summary":"Zero-Shot Learning (ZSL) aims to transfer classification capability from seen to unseen classes. Recent methods have proved that generalization and specialization are two essential abilities to achieve good performance in ZSL. However, they all focus on only one of the abilities, resulting in models that are either too general with the degraded classifying ability or too specialized to generalize to unseen classes. In this paper, we propose an end-to-end network with balanced generalization and specialization abilities, termed as BGSNet, to take advantage of both abilities, and balance them at instance- and dataset-level. Specifically, BGSNet consists of two branches: the Generalization Network (GNet), which applies episodic meta-learning to learn generalized knowledge, and the Balanced Specialization Network (BSNet), which adopts multiple attentive extractors to extract discriminative features and fulfill the instance-level balance. A novel self-adjusting diversity loss is designed to optimize BSNet with less redundancy and more diversity. We further propose a differentiable dataset-level balance and update the weights in a linear annealing schedule to simulate network pruning and thus obtain the optimal structure for BSNet at a low cost with dataset-level balance achieved. Experiments on four benchmark datasets demonstrate our model's effectiveness. Sufficient component ablations prove the necessity of integrating generalization and specialization abilities.",
        "published":1641456267000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.01961v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jan 06, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0812246097,
        "popularmechanics":0.1169675678,
        "scienmag":0.1271367874,
        "technologyreview":0.2130207052,
        "vox":0.0858891094,
        "newscientist":0.1192502929,
        "vice":0.0809504102,
        "statnews":0.14786116,
        "nytimes":0.1079133098,
        "techcrunch":0.1191597095,
        "quartz":0.094497153,
        "venturebeat":0.1920373946,
        "futurism":0.1397687892,
        "scientificamerican":0.1034231785,
        "wired":0.1323540344,
        "popsci":0.1412786275,
        "arstechnica":0.0973448079,
        "salon":0.0777723003,
        "washingtonpost":0.1113052138,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.01468v1",
        "predicted_newsworthiness":72.7529938357,
        "title":"Cria\u00e7\u00e3o e aplica\u00e7\u00e3o de ferramenta para auxiliar no ensino de algoritmos e programa\u00e7\u00e3o de computadores",
        "summary":"Knowledge about programming is part of the knowledge matrix that will be required of the professionals of the future. Based on this, this work aims to report the development of a teaching tool developed during the monitoring program of the Algorithm and Computer Programming discipline of the University of Fortaleza. The tool combines the knowledge acquired in the books, with a language closer to the students, using video lessons and exercises proposed, with all the content available on the internet. The preliminary results were positive, with the students approving this new approach and believing that it could contribute to a better performance in the discipline.",
        "published":1648720129000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.01468v1",
        "arxiv_primary_category":"cs.cy",
        "published_hr":"Mar 31, 2022",
        "arxiv_primary_category_hr":"Computers and Society",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1667857667,
        "popularmechanics":0.1459904606,
        "scienmag":0.1597575214,
        "technologyreview":0.2338100295,
        "vox":0.1234719692,
        "newscientist":0.148631472,
        "vice":0.1056737939,
        "statnews":0.1606924646,
        "nytimes":0.2052684499,
        "techcrunch":0.1994534537,
        "quartz":0.1407478577,
        "venturebeat":0.2203107105,
        "futurism":0.174440746,
        "scientificamerican":0.1223030978,
        "wired":0.1886431382,
        "popsci":0.1809822122,
        "arstechnica":0.1158409885,
        "salon":0.0988907795,
        "washingtonpost":0.1335391171,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.06429v2",
        "predicted_newsworthiness":41.8440770623,
        "title":"DFTR: Depth-supervised Fusion Transformer for Salient Object Detection",
        "summary":"Automated salient object detection (SOD) plays an increasingly crucial role in many computer vision applications. By reformulating the depth information as supervision rather than as input, depth-supervised convolutional neural networks (CNN) have achieved promising results on both RGB and RGB-D SOD scenarios with the merits of no requirements for extra depth networks and depth inputs in the inference stage. This paper, for the first time, seeks to expand the applicability of depth supervision to the Transformer architecture. Specifically, we develop a Depth-supervised Fusion TRansformer (DFTR), to further improve the accuracy of both RGB and RGB-D SOD. The proposed DFTR involves three primary features: 1) DFTR, to the best of our knowledge, is the first pure Transformer-based model for depth-supervised SOD; 2) A multi-scale feature aggregation (MFA) module is proposed to fully exploit the multi-scale features encoded by the Swin Transformer in a coarse-to-fine manner; 3) To enable bidirectional information flow across different streams of features, a novel multi-stage feature fusion (MFF) module is further integrated into our DFTR with the emphasis on salient regions at different network learning stages. We extensively evaluate the proposed DFTR on ten benchmarking datasets. Experimental results show that our DFTR consistently outperforms the existing state-of-the-art methods for both RGB and RGB-D SOD tasks. The code and model will be made publicly available.",
        "published":1647089952000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.06429v2",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Mar 12, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0790366796,
        "popularmechanics":0.1495052815,
        "scienmag":0.1108373069,
        "technologyreview":0.2043251289,
        "vox":0.1201994461,
        "newscientist":0.1312343028,
        "vice":0.1227272508,
        "statnews":0.0993538054,
        "nytimes":0.1155481918,
        "techcrunch":0.1646482267,
        "quartz":0.1081676726,
        "venturebeat":0.2068911538,
        "futurism":0.1609933837,
        "scientificamerican":0.1072365211,
        "wired":0.1696244722,
        "popsci":0.1912496278,
        "arstechnica":0.1065489423,
        "salon":0.0815028839,
        "washingtonpost":0.1373211107,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.11924v2",
        "predicted_newsworthiness":44.2948562039,
        "title":"Close the Visual Domain Gap by Physics-Grounded Active Stereovision Depth Sensor Simulation",
        "summary":"In this paper, we focus on the simulation of active stereovision depth sensors, which are popular in both academic and industry communities. Inspired by the underlying mechanism of the sensors, we designed a fully physics-grounded simulation pipeline, which includes material acquisition, ray tracing based infrared (IR) image rendering, IR noise simulation, and depth estimation. The pipeline is able to generate depth maps with material-dependent error patterns similar to a real depth sensor. We conduct extensive experiments to show that perception algorithms and reinforcement learning policies trained in our simulation platform could transfer well to real world test cases without any fine-tuning. Furthermore, due to the high degree of realism of this simulation, our depth sensor simulator can be used as a convenient testbed to evaluate the algorithm performance in the real world, which will largely reduce the human effort in developing robotic algorithms. The entire pipeline has been integrated into the SAPIEN simulator and is open-sourced to promote the research of vision and robotics communities.",
        "published":1643343338000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.11924v2",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Jan 27, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0948356692,
        "popularmechanics":0.2119075288,
        "scienmag":0.1778050728,
        "technologyreview":0.2752559907,
        "vox":0.1318409631,
        "newscientist":0.1929991162,
        "vice":0.2081131418,
        "statnews":0.1382076325,
        "nytimes":0.1707011545,
        "techcrunch":0.2149339285,
        "quartz":0.118361335,
        "venturebeat":0.2726841609,
        "futurism":0.2401995303,
        "scientificamerican":0.157131992,
        "wired":0.2240939357,
        "popsci":0.2653161896,
        "arstechnica":0.1548608512,
        "salon":0.1090482528,
        "washingtonpost":0.1742854257,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.03759v1",
        "predicted_newsworthiness":61.7908165867,
        "title":"Time to Focus: A Comprehensive Benchmark Using Time Series Attribution Methods",
        "summary":"In the last decade neural network have made huge impact both in industry and research due to their ability to extract meaningful features from imprecise or complex data, and by achieving super human performance in several domains. However, due to the lack of transparency the use of these networks is hampered in the areas with safety critical areas. In safety-critical areas, this is necessary by law. Recently several methods have been proposed to uncover this black box by providing interpreation of predictions made by these models. The paper focuses on time series analysis and benchmark several state-of-the-art attribution methods which compute explanations for convolutional classifiers. The presented experiments involve gradient-based and perturbation-based attribution methods. A detailed analysis shows that perturbation-based approaches are superior concerning the Sensitivity and occlusion game. These methods tend to produce explanations with higher continuity. Contrarily, the gradient-based techniques are superb in runtime and Infidelity. In addition, a validation the dependence of the methods on the trained model, feasible application domains, and individual characteristics is attached. The findings accentuate that choosing the best-suited attribution method is strongly correlated with the desired use case. Neither category of attribution methods nor a single approach has shown outstanding performance across all aspects.",
        "published":1644314773000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.03759v1",
        "arxiv_primary_category":"cs.ai",
        "published_hr":"Feb 08, 2022",
        "arxiv_primary_category_hr":"Artificial Intelligence",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1653912805,
        "popularmechanics":0.1817194808,
        "scienmag":0.1999814473,
        "technologyreview":0.3376891829,
        "vox":0.2174190659,
        "newscientist":0.2104703397,
        "vice":0.163626058,
        "statnews":0.300137405,
        "nytimes":0.2144101868,
        "techcrunch":0.2401639059,
        "quartz":0.1838493721,
        "venturebeat":0.3219435159,
        "futurism":0.2490885942,
        "scientificamerican":0.1724624336,
        "wired":0.2497021101,
        "popsci":0.2446508122,
        "arstechnica":0.2014358781,
        "salon":0.1568825173,
        "washingtonpost":0.2221461427,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.05733v1",
        "predicted_newsworthiness":47.5009599871,
        "title":"Finite-Time Analysis of Fully Decentralized Single-Timescale Actor-Critic",
        "summary":"Decentralized Actor-Critic (AC) algorithms have been widely utilized for multi-agent reinforcement learning (MARL) and have achieved remarkable success. Apart from its empirical success, the theoretical convergence property of decentralized AC algorithms is largely unexplored. The existing finite-time convergence results are derived based on either double-loop update or two-timescale step sizes rule, which is not often adopted in real implementation. In this work, we introduce a fully decentralized AC algorithm, where actor, critic, and global reward estimator are updated in an alternating manner with step sizes being of the same order, namely, we adopt the \\emph{single-timescale} update. Theoretically, using linear approximation for value and reward estimation, we show that our algorithm has sample complexity of $\\tilde{\\mathcal{O}}(\\epsilon^{-2})$ under Markovian sampling, which matches the optimal complexity with double-loop implementation (here, $\\tilde{\\mathcal{O}}$ hides a log term). The sample complexity can be improved to ${\\mathcal{O}}(\\epsilon^{-2})$ under the i.i.d. sampling scheme. The central to establishing our complexity results is \\emph{the hidden smoothness of the optimal critic variable} we revealed. We also provide a local action privacy-preserving version of our algorithm and its analysis. Finally, we conduct experiments to show the superiority of our algorithm over the existing decentralized AC algorithms.",
        "published":1655039654000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.05733v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jun 12, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0896344017,
        "popularmechanics":0.1127221218,
        "scienmag":0.0882386939,
        "technologyreview":0.1842141498,
        "vox":0.1211459414,
        "newscientist":0.1055905359,
        "vice":0.0738413648,
        "statnews":0.1287998238,
        "nytimes":0.1224316462,
        "techcrunch":0.1338920774,
        "quartz":0.1091601209,
        "venturebeat":0.162618489,
        "futurism":0.1421494872,
        "scientificamerican":0.0884269844,
        "wired":0.1367348105,
        "popsci":0.13549856,
        "arstechnica":0.1136820771,
        "salon":0.0944833476,
        "washingtonpost":0.1220498685,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.12109v1",
        "predicted_newsworthiness":53.7732371609,
        "title":"Protum: A New Method For Prompt Tuning Based on \"[MASK]\"",
        "summary":"Recently, prompt tuning \\cite{lester2021power} has gradually become a new paradigm for NLP, which only depends on the representation of the words by freezing the parameters of pre-trained language models (PLMs) to obtain remarkable performance on downstream tasks. It maintains the consistency of Masked Language Model (MLM) \\cite{devlin2018bert} task in the process of pre-training, and avoids some issues that may happened during fine-tuning. Naturally, we consider that the \"[MASK]\" tokens carry more useful information than other tokens because the model combines with context to predict the masked tokens. Among the current prompt tuning methods, there will be a serious problem of random composition of the answer tokens in prediction when they predict multiple words so that they have to map tokens to labels with the help verbalizer. In response to the above issue, we propose a new \\textbf{Pro}mpt \\textbf{Tu}ning based on \"[\\textbf{M}ASK]\" (\\textbf{Protum}) method in this paper, which constructs a classification task through the information carried by the hidden layer of \"[MASK]\" tokens and then predicts the labels directly rather than the answer tokens. At the same time, we explore how different hidden layers under \"[MASK]\" impact on our classification model on many different data sets. Finally, we find that our \\textbf{Protum} can achieve much better performance than fine-tuning after continuous pre-training with less time consumption. Our model facilitates the practical application of large models in NLP.",
        "published":1643376870000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.12109v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Jan 28, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1001570548,
        "popularmechanics":0.1183476413,
        "scienmag":0.1116659461,
        "technologyreview":0.2411248812,
        "vox":0.1380799613,
        "newscientist":0.1311548849,
        "vice":0.0840838251,
        "statnews":0.1899083817,
        "nytimes":0.1393345243,
        "techcrunch":0.177314459,
        "quartz":0.1246442311,
        "venturebeat":0.2527276186,
        "futurism":0.1645972721,
        "scientificamerican":0.1058223358,
        "wired":0.1724867897,
        "popsci":0.1771833159,
        "arstechnica":0.1254601113,
        "salon":0.0987970245,
        "washingtonpost":0.1486292559,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.12231v2",
        "predicted_newsworthiness":38.4893161412,
        "title":"Overcoming Exploration: Deep Reinforcement Learning in Complex Environments from Temporal Logic Specifications",
        "summary":"We present a Deep Reinforcement Learning (DRL) algorithm for a task-guided robot with unknown continuous-time dynamics deployed in a large-scale complex environment. Linear Temporal Logic (LTL) is applied to express a rich robotic specification. To overcome the environmental challenge, we propose a novel path planning-guided reward scheme that is dense over the state space, and crucially, robust to infeasibility of computed geometric paths due to the unknown robot dynamics. To facilitate LTL satisfaction, our approach decomposes the LTL mission into sub-tasks that are solved using distributed DRL, where the sub-tasks are trained in parallel, using Deep Policy Gradient algorithms. Our framework is shown to significantly improve performance (effectiveness, efficiency) and exploration of robots tasked with complex missions in large-scale complex environments.",
        "published":1643387948000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.12231v2",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Jan 28, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0835814466,
        "popularmechanics":0.1950848672,
        "scienmag":0.1286408504,
        "technologyreview":0.2749694201,
        "vox":0.121313962,
        "newscientist":0.1664116649,
        "vice":0.1828319148,
        "statnews":0.1812449183,
        "nytimes":0.1727776024,
        "techcrunch":0.1959929897,
        "quartz":0.116972393,
        "venturebeat":0.2440081488,
        "futurism":0.2291572802,
        "scientificamerican":0.1307844623,
        "wired":0.2014798938,
        "popsci":0.2304339213,
        "arstechnica":0.1689231416,
        "salon":0.0984347539,
        "washingtonpost":0.1867637753,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.01046v1",
        "predicted_newsworthiness":52.7206974998,
        "title":"Towards High-Payload Admittance Control for Manual Guidance with Environmental Contact",
        "summary":"Force control enables hands-on teaching and physical collaboration, with the potential to improve ergonomics and flexibility of automation. Established methods for the design of compliance, impedance control, and \\rev{collision response} can achieve free-space stability and acceptable peak contact force on lightweight, lower payload robots. Scaling collaboration to higher payloads can allow new applications, but introduces challenges due to the more significant payload dynamics and the use of higher-payload industrial robots. To achieve high-payload manual guidance with contact, this paper proposes and validates new mechatronic design methods: standard admittance control is extended with damping feedback, compliant structures are integrated to the environment, and a contact response method which allows continuous admittance control is proposed. These methods are compared with respect to free-space stability, contact stability, and peak contact force. The resulting methods are then applied to realize two contact-rich tasks on a 16 kg payload (peg in hole and slot assembly) and free-space co-manipulation of a 50 kg payload.",
        "published":1643811717000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.01046v1",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Feb 02, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0703836598,
        "popularmechanics":0.1933996039,
        "scienmag":0.1165612582,
        "technologyreview":0.1763429478,
        "vox":0.0700850275,
        "newscientist":0.1349528432,
        "vice":0.1573052516,
        "statnews":0.0430087337,
        "nytimes":0.117825537,
        "techcrunch":0.1334048435,
        "quartz":0.0840871077,
        "venturebeat":0.1318155276,
        "futurism":0.1914595074,
        "scientificamerican":0.0960706722,
        "wired":0.1494368908,
        "popsci":0.2219218041,
        "arstechnica":0.1290036781,
        "salon":0.0612219787,
        "washingtonpost":0.1468868637,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.13461v2",
        "predicted_newsworthiness":44.1423746023,
        "title":"Configuration Control for Physical Coupling of Heterogeneous Robot Swarms",
        "summary":"In this paper, we present a heterogeneous robot swarm system that can physically couple with each other to form functional structures and dynamically decouple to perform individual tasks. The connection between robots can be formed with a passive coupling mechanism, ensuring minimum energy consumption during coupling and decoupling behavior. The heterogeneity of the system enables the robots to perform structural enhancement configurations based on specific environmental requirements. We propose a connection-pair oriented configuration control algorithm to form different assemblies. We show experiments of up to nine robots performing the coupling, gap-crossing, and decoupling behaviors.",
        "published":1645999068000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.13461v2",
        "arxiv_primary_category":"cs.ro",
        "published_hr":"Feb 27, 2022",
        "arxiv_primary_category_hr":"Robotics",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0737835205,
        "popularmechanics":0.1871364302,
        "scienmag":0.150041863,
        "technologyreview":0.1802635355,
        "vox":0.0785970939,
        "newscientist":0.1456549293,
        "vice":0.1446106104,
        "statnews":0.0500374124,
        "nytimes":0.1118887088,
        "techcrunch":0.1341932713,
        "quartz":0.0791797453,
        "venturebeat":0.1300313621,
        "futurism":0.1884022193,
        "scientificamerican":0.1383305863,
        "wired":0.1387740577,
        "popsci":0.2352247261,
        "arstechnica":0.1106003621,
        "salon":0.0785436884,
        "washingtonpost":0.1362120558,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.01543v1",
        "predicted_newsworthiness":49.1450313407,
        "title":"Beyond Opinion Mining: Summarizing Opinions of Customer Reviews",
        "summary":"Customer reviews are vital for making purchasing decisions in the Information Age. Such reviews can be automatically summarized to provide the user with an overview of opinions. In this tutorial, we present various aspects of opinion summarization that are useful for researchers and practitioners. First, we will introduce the task and major challenges. Then, we will present existing opinion summarization solutions, both pre-neural and neural. We will discuss how summarizers can be trained in the unsupervised, few-shot, and supervised regimes. Each regime has roots in different machine learning methods, such as auto-encoding, controllable text generation, and variational inference. Finally, we will discuss resources and evaluation methods and conclude with the future directions. This three-hour tutorial will provide a comprehensive overview over major advances in opinion summarization. The listeners will be well-equipped with the knowledge that is both useful for research and practical applications.",
        "published":1654260220000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.01543v1",
        "arxiv_primary_category":"cs.cl",
        "published_hr":"Jun 03, 2022",
        "arxiv_primary_category_hr":"Computation and Language",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1337210142,
        "popularmechanics":0.114586494,
        "scienmag":0.1421557683,
        "technologyreview":0.2398010663,
        "vox":0.2002457019,
        "newscientist":0.1473411257,
        "vice":0.0932524848,
        "statnews":0.2195248752,
        "nytimes":0.1678197675,
        "techcrunch":0.1990653353,
        "quartz":0.1642560168,
        "venturebeat":0.2595316603,
        "futurism":0.1703309897,
        "scientificamerican":0.1381487581,
        "wired":0.1986079508,
        "popsci":0.1827023225,
        "arstechnica":0.147437009,
        "salon":0.1357069541,
        "washingtonpost":0.1862827943,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.04416v3",
        "predicted_newsworthiness":50.1282947014,
        "title":"E^2TAD: An Energy-Efficient Tracking-based Action Detector",
        "summary":"Video action detection (spatio-temporal action localization) is usually the starting point for human-centric intelligent analysis of videos nowadays. It has high practical impacts for many applications across robotics, security, healthcare, etc. The two-stage paradigm of Faster R-CNN inspires a standard paradigm of video action detection in object detection, i.e., firstly generating person proposals and then classifying their actions. However, none of the existing solutions could provide fine-grained action detection to the \"who-when-where-what\" level. This paper presents a tracking-based solution to accurately and efficiently localize predefined key actions spatially (by predicting the associated target IDs and locations) and temporally (by predicting the time in exact frame indices). This solution won first place in the UAV-Video Track of 2021 Low-Power Computer Vision Challenge (LPCVC).",
        "published":1649490731000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.04416v3",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Apr 09, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1072857679,
        "popularmechanics":0.1835105946,
        "scienmag":0.1301909478,
        "technologyreview":0.2213188687,
        "vox":0.144312076,
        "newscientist":0.1495680376,
        "vice":0.1363133584,
        "statnews":0.1230398457,
        "nytimes":0.1469323588,
        "techcrunch":0.1973494318,
        "quartz":0.1380087018,
        "venturebeat":0.2134403125,
        "futurism":0.1905970893,
        "scientificamerican":0.1345998959,
        "wired":0.2031823287,
        "popsci":0.2203542559,
        "arstechnica":0.1425905412,
        "salon":0.106595599,
        "washingtonpost":0.1650171196,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2202.03936v2",
        "predicted_newsworthiness":61.7457668886,
        "title":"Accelerometer-based Bed Occupancy Detection for Automatic, Non-invasive Long-term Cough Monitoring",
        "summary":"We present a new machine learning based bed-occupancy detection system that uses the accelerometer signal captured by a bed-attached consumer smartphone. Automatic bed-occupancy detection is necessary for automatic long-term cough monitoring, since the time which the monitored patient occupies the bed is required to accurately calculate a cough rate. Accelerometer measurements are more cost effective and less intrusive than alternatives such as video monitoring or pressure sensors. A 249-hour dataset of manually-labelled acceleration signals gathered from seven patients undergoing treatment for tuberculosis (TB) was compiled for experimentation. These signals are characterised by brief activity bursts interspersed with long periods of little or no activity, even when the bed is occupied. To process them effectively, we propose an architecture consisting of three interconnected components. An occupancy-change detector locates instances at which bed occupancy is likely to have changed, an occupancy-interval detector classifies periods between detected occupancy changes and an occupancy-state detector corrects falsely-identified occupancy changes. Using long short-term memory (LSTM) networks, this architecture was demonstrated to achieve an AUC of 0.94. When integrated into a complete cough monitoring system, the daily cough rate of a patient undergoing TB treatment was determined over a period of 14 days. As the colony forming unit (CFU) counts decreased and the time to positivity (TPP) increased, the measured cough rate decreased, indicating effective TB treatment. This provides a first indication that automatic cough monitoring based on bed-mounted accelerometer measurements may present a non-invasive, non-intrusive and cost-effective means of monitoring long-term recovery of TB patients.",
        "published":1644334714000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2202.03936v2",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Feb 08, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.170336481,
        "popularmechanics":0.1887811924,
        "scienmag":0.2563939855,
        "technologyreview":0.2584499834,
        "vox":0.1695018746,
        "newscientist":0.2145724498,
        "vice":0.1442320848,
        "statnews":0.3642547172,
        "nytimes":0.2056609262,
        "techcrunch":0.2133726126,
        "quartz":0.1523376496,
        "venturebeat":0.2459098664,
        "futurism":0.2247196317,
        "scientificamerican":0.199144012,
        "wired":0.2086334876,
        "popsci":0.2515861178,
        "arstechnica":0.1679258343,
        "salon":0.1971681518,
        "washingtonpost":0.2012420109,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2206.05530v1",
        "predicted_newsworthiness":48.4936923118,
        "title":"Memorization-Dilation: Modeling Neural Collapse Under Noise",
        "summary":"The notion of neural collapse refers to several emergent phenomena that have been empirically observed across various canonical classification problems. During the terminal phase of training a deep neural network, the feature embedding of all examples of the same class tend to collapse to a single representation, and the features of different classes tend to separate as much as possible. Neural collapse is often studied through a simplified model, called the unconstrained feature representation, in which the model is assumed to have \"infinite expressivity\" and can map each data point to any arbitrary representation. In this work, we propose a more realistic variant of the unconstrained feature representation that takes the limited expressivity of the network into account. Empirical evidence suggests that the memorization of noisy data points leads to a degradation (dilation) of the neural collapse. Using a model of the memorization-dilation (M-D) phenomenon, we show one mechanism by which different losses lead to different performances of the trained network on noisy data. Our proofs reveal why label smoothing, a modification of cross-entropy empirically observed to produce a regularization effect, leads to improved generalization in classification tasks.",
        "published":1654954837000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2206.05530v1",
        "arxiv_primary_category":"cs.lg",
        "published_hr":"Jun 11, 2022",
        "arxiv_primary_category_hr":"Machine Learning",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1134708527,
        "popularmechanics":0.1418630658,
        "scienmag":0.1606839953,
        "technologyreview":0.2815712853,
        "vox":0.1340545145,
        "newscientist":0.1767790187,
        "vice":0.1490085082,
        "statnews":0.2235204617,
        "nytimes":0.1540557602,
        "techcrunch":0.1458516793,
        "quartz":0.1242308308,
        "venturebeat":0.2347587637,
        "futurism":0.1863503478,
        "scientificamerican":0.1702953935,
        "wired":0.1799388433,
        "popsci":0.1821046636,
        "arstechnica":0.1316587868,
        "salon":0.1149160169,
        "washingtonpost":0.1501410355,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2204.03802v1",
        "predicted_newsworthiness":43.5847948652,
        "title":"Stochastic Geometry-Based Low Latency Routing in Massive LEO Satellite Networks",
        "summary":"In this paper, the routing in massive low earth orbit (LEO) satellite networks is studied. When the satellite-to-satellite communication distance is limited, we choose different relay satellites to minimize the latency in a constellation at a constant altitude. Firstly, the global optimum solution is obtained in the ideal scenario when there are available satellites at all the ideal locations. Next, we propose a nearest neighbor search algorithm for realistic (non-ideal) scenarios with a limited number of satellites. The proposed algorithm can approach the global optimum solution under an ideal scenario through a finite number of iterations and a tiny range of searches. Compared with other routing strategies, the proposed algorithm shows significant advantages in terms of latency. Furthermore, we provide two approximation techniques that can give tight lower and upper bounds for the latency of the proposed algorithm, respectively. Finally, the relationships between latency and constellation height, satellites' number, and communication distance are investigated.",
        "published":1649381582000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2204.03802v1",
        "arxiv_primary_category":"cs.ni",
        "published_hr":"Apr 07, 2022",
        "arxiv_primary_category_hr":"Networking and Internet Architecture",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.0495635762,
        "popularmechanics":0.1518250891,
        "scienmag":0.0824215244,
        "technologyreview":0.1197549152,
        "vox":0.0688659637,
        "newscientist":0.0983359983,
        "vice":0.1670930632,
        "statnews":0.0269953631,
        "nytimes":0.0944067539,
        "techcrunch":0.10550351,
        "quartz":0.0799677079,
        "venturebeat":0.1074414763,
        "futurism":0.1328306124,
        "scientificamerican":0.1002402829,
        "wired":0.1011203209,
        "popsci":0.1241812746,
        "arstechnica":0.133621815,
        "salon":0.0443771929,
        "washingtonpost":0.1185698849,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2201.09077v1",
        "predicted_newsworthiness":48.8779392192,
        "title":"LTC-GIF: Attracting More Clicks on Feature-length Sports Videos",
        "summary":"This paper proposes a lightweight method to attract users and increase views of the video by presenting personalized artistic media -- i.e, static thumbnails and animated GIFs. This method analyzes lightweight thumbnail containers (LTC) using computational resources of the client device to recognize personalized events from full-length sports videos. In addition, instead of processing the entire video, small video segments are processed to generate artistic media. This makes the proposed approach more computationally efficient compared to the baseline approaches that create artistic media using the entire video. The proposed method retrieves and uses thumbnail containers and video segments, which reduces the required transmission bandwidth as well as the amount of locally stored data used during artistic media generation. When extensive experiments were conducted on the Nvidia Jetson TX2, the computational complexity of the proposed method was 3.57 times lower than that of the SoA method. In the qualitative assessment, GIFs generated using the proposed method received 1.02 higher overall ratings compared to the SoA method. To the best of our knowledge, this is the first technique that uses LTC to generate artistic media while providing lightweight and high-performance services even on resource-constrained devices.",
        "published":1642865650000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2201.09077v1",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Jan 22, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.148292648,
        "popularmechanics":0.1851457735,
        "scienmag":0.1318729688,
        "technologyreview":0.2207081235,
        "vox":0.2176844634,
        "newscientist":0.1663171333,
        "vice":0.1267652893,
        "statnews":0.137979098,
        "nytimes":0.1914449984,
        "techcrunch":0.2694033753,
        "quartz":0.1979464533,
        "venturebeat":0.3005171132,
        "futurism":0.1945129078,
        "scientificamerican":0.1390311784,
        "wired":0.2677245238,
        "popsci":0.2723135106,
        "arstechnica":0.1499337696,
        "salon":0.0996156428,
        "washingtonpost":0.2201886679,
        "outlet_relevance":"N\/A"
    },
    {
        "arxiv_id":"2203.01441v3",
        "predicted_newsworthiness":47.2891677901,
        "title":"3D Common Corruptions and Data Augmentation",
        "summary":"We introduce a set of image transformations that can be used as corruptions to evaluate the robustness of models as well as data augmentation mechanisms for training neural networks. The primary distinction of the proposed transformations is that, unlike existing approaches such as Common Corruptions, the geometry of the scene is incorporated in the transformations -- thus leading to corruptions that are more likely to occur in the real world. We also introduce a set of semantic corruptions (e.g. natural object occlusions). We show these transformations are `efficient' (can be computed on-the-fly), `extendable' (can be applied on most image datasets), expose vulnerability of existing models, and can effectively make models more robust when employed as `3D data augmentation' mechanisms. The evaluations on several tasks and datasets suggest incorporating 3D information into benchmarking and training opens up a promising direction for robustness research.",
        "published":1646260276000,
        "arxiv_url":"http:\/\/arxiv.org\/abs\/2203.01441v3",
        "arxiv_primary_category":"cs.cv",
        "published_hr":"Mar 02, 2022",
        "arxiv_primary_category_hr":"Computer Vision and Pattern Recognition",
        "completion1":"This is a test completion for latency checking.",
        "completion2":"This is a test completion for latency checking.",
        "completion3":"This is a test completion for latency checking.",
        "theconversation":0.1154023629,
        "popularmechanics":0.1822725908,
        "scienmag":0.1556774031,
        "technologyreview":0.2873080916,
        "vox":0.1533953749,
        "newscientist":0.1780935748,
        "vice":0.1446523252,
        "statnews":0.1917605528,
        "nytimes":0.1598615122,
        "techcrunch":0.1857063153,
        "quartz":0.1370645301,
        "venturebeat":0.2459645294,
        "futurism":0.2149604161,
        "scientificamerican":0.1396212871,
        "wired":0.2045430404,
        "popsci":0.2160575744,
        "arstechnica":0.1509327679,
        "salon":0.1199128088,
        "washingtonpost":0.1774745088,
        "outlet_relevance":"N\/A"
    }
]